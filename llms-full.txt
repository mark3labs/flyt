# Flyt

> A minimalist workflow framework for Go with zero dependencies

## Best Practices

Follow these guidelines to build robust, maintainable Flyt workflows.

### Node Design

#### Single Responsibility

Each node should do one thing well:

```go
// ❌ Bad: Node doing too much
node := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        // Fetch data
        data := fetchFromAPI()
        // Validate
        if !isValid(data) {
            return nil, errors.New("invalid")
        }
        // Transform
        transformed := transform(data)
        // Save
        saveToDatabase(transformed)
        return transformed, nil
    }),
)

// ✅ Good: Separate concerns
fetchNode := createFetchNode()
validateNode := createValidateNode()
transformNode := createTransformNode()
saveNode := createSaveNode()

flow := flyt.NewFlow(fetchNode)
flow.Connect(fetchNode, flyt.DefaultAction, validateNode)
flow.Connect(validateNode, "valid", transformNode)
flow.Connect(transformNode, flyt.DefaultAction, saveNode)
```

#### Idempotency

Design nodes to be safely retryable:

```go
// ✅ Good: Idempotent operation
func (n *SaveNode) Exec(ctx context.Context, prepResult any) (any, error) {
    data := prepResult.(Record)
    
    // Use upsert instead of insert
    _, err := db.Exec(`
        INSERT INTO records (id, data) VALUES (?, ?)
        ON CONFLICT (id) DO UPDATE SET data = ?
    `, data.ID, data.Data, data.Data)
    
    return data.ID, err
}
```

#### Error Handling

Return clear, actionable errors:

```go
// ❌ Bad: Generic error
return nil, errors.New("failed")

// ✅ Good: Descriptive error
return nil, fmt.Errorf("failed to fetch user %d: %w", userID, err)
```

#### Type-Safe SharedStore Access

Use type-safe helpers to avoid runtime panics:

```go
// ❌ Bad: Manual type assertion can panic
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    val, _ := shared.Get("count")
    count := val.(int)  // Panics if val is nil or not int
    return count, nil
}

// ✅ Good: Type-safe getter with default
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    count := shared.GetInt("count")  // Returns 0 if not found
    // Or with custom default
    count := shared.GetIntOr("count", -1)
    return count, nil
}

// ✅ Good: Bind complex types
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    var config Config
    if err := shared.Bind("config", &config); err != nil {
        return nil, fmt.Errorf("invalid config: %w", err)
    }
    return config, nil
}
```

### Flow Design

#### Modular Flows

Create reusable sub-flows:

```go
// Reusable validation flow
func createValidationFlow() *flyt.Flow {
    schemaCheck := createSchemaValidator()
    businessRules := createBusinessValidator()
    
    flow := flyt.NewFlow(schemaCheck)
    flow.Connect(schemaCheck, "valid", businessRules)
    return flow
}

// Use in multiple places
mainFlow.Connect(fetchNode, flyt.DefaultAction, createValidationFlow())
apiFlow.Connect(parseNode, flyt.DefaultAction, createValidationFlow())
```

#### Error Boundaries

Centralize error handling:

```go
func createFlowWithErrorHandling() *flyt.Flow {
    flow := flyt.NewFlow(startNode)
    errorHandler := createErrorHandler()
    
    // Connect all error paths to handler
    for _, node := range []flyt.Node{startNode, processNode, saveNode} {
        flow.Connect(node, "error", errorHandler)
    }
    
    return flow
}
```

### Context Handling

#### Respect Cancellation

Always check context in long-running operations:

```go
func (n *ProcessNode) Exec(ctx context.Context, prepResult any) (any, error) {
    items := prepResult.([]Item)
    results := []Result{}
    
    for _, item := range items {
        // Check context before each iteration
        select {
        case <-ctx.Done():
            return nil, ctx.Err()
        default:
        }
        
        result := processItem(ctx, item)
        results = append(results, result)
    }
    
    return results, nil
}
```

#### Timeout Management

Set appropriate timeouts:

```go
func (n *APINode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Create timeout context
    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)
    defer cancel()
    
    return callAPI(ctx, prepResult)
}
```

### Concurrency Safety

#### Thread-Safe Nodes

Protect shared state in nodes:

```go
type CounterNode struct {
    *flyt.BaseNode
    mu    sync.Mutex
    count int
}

func (n *CounterNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.mu.Lock()
    n.count++
    current := n.count
    n.mu.Unlock()
    
    return current, nil
}
```

#### Avoid Shared Node Instances

Create new instances for concurrent use:

```go
// ❌ Bad: Sharing node instance
node := createProcessNode()
for i := 0; i < 10; i++ {
    go flyt.Run(ctx, node, shared) // Race condition!
}

// ✅ Good: Create new instances
for i := 0; i < 10; i++ {
    go flyt.Run(ctx, createProcessNode(), shared)
}
```

### Resource Management

#### Clean Up Resources

Use defer for cleanup:

```go
func (n *FileNode) Exec(ctx context.Context, prepResult any) (any, error) {
    file, err := os.Open(prepResult.(string))
    if err != nil {
        return nil, err
    }
    defer file.Close() // Always cleanup
    
    // Process file...
    return processFile(file)
}
```

#### Connection Pooling

Reuse expensive resources:

```go
type DatabaseFlow struct {
    db *sql.DB
}

func NewDatabaseFlow(db *sql.DB) *DatabaseFlow {
    return &DatabaseFlow{db: db}
}

func (f *DatabaseFlow) CreateNode() flyt.Node {
    return &DatabaseNode{
        BaseNode: flyt.NewBaseNode(),
        db: f.db, // Reuse connection pool
    }
}
```

### Testing

#### Unit Test Nodes

Test nodes in isolation:

```go
func TestProcessNode(t *testing.T) {
    node := createProcessNode()
    ctx := context.Background()
    
    // Test successful case
    result, err := node.Exec(ctx, "test input")
    assert.NoError(t, err)
    assert.Equal(t, "expected output", result)
    
    // Test error case
    result, err = node.Exec(ctx, nil)
    assert.Error(t, err)
}
```

#### Integration Test Flows

Test complete workflows:

```go
func TestCompleteFlow(t *testing.T) {
    flow := createMainFlow()
    shared := flyt.NewSharedStore()
    shared.Set("input", testData)
    
    ctx := context.Background()
    err := flow.Run(ctx, shared)
    assert.NoError(t, err)
    
    // Use type-safe getter or Bind for results
    var result OutputData
    err = shared.Bind("output", &result)
    assert.NoError(t, err)
    assert.Equal(t, expectedResult, result)
}
```

### Documentation

#### Document Node Behavior

```go
// FetchUserNode fetches user data from the API.
// 
// Prep: Reads "user_id" from SharedStore
// Exec: Fetches user from API, retries on network errors
// Post: Stores user data in "user_data" key
// Actions:
//   - "success": User fetched successfully
//   - "not_found": User does not exist
//   - "error": Unrecoverable error occurred
type FetchUserNode struct {
    *flyt.BaseNode
    apiClient *APIClient
}
```

#### Document Flow Structure

```go
// CreateOrderFlow processes new orders:
// 1. Validates order data
// 2. Checks inventory
// 3. Processes payment
// 4. Creates shipment
// 5. Sends confirmation
//
// Required SharedStore keys:
//   - "order_data": OrderData struct
//   - "customer_id": string
//
// Sets SharedStore keys:
//   - "order_id": string
//   - "tracking_number": string
func CreateOrderFlow() *flyt.Flow {
    // ...
}
```

### Performance

#### Batch Operations

Process items in batches when possible:

```go
// Instead of processing one at a time
for _, item := range items {
    process(item)
}

// Process in batches
batchNode := flyt.NewBatchNode(processFunc, true)
shared.Set("items", items)
```

#### Lazy Loading

Load data only when needed:

```go
func (n *ProcessNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    // Only load the data this node needs
    if needsUserData(shared) {
        userData := loadUserData()
        return userData, nil
    }
    return nil, nil
}
```

### Monitoring

#### Add Observability

Log important events:

```go
func (n *ProcessNode) Exec(ctx context.Context, prepResult any) (any, error) {
    start := time.Now()
    defer func() {
        log.Printf("ProcessNode took %v", time.Since(start))
    }()
    
    result, err := process(prepResult)
    if err != nil {
        log.Printf("ProcessNode error: %v", err)
        return nil, err
    }
    
    log.Printf("ProcessNode success: processed %d items", len(result))
    return result, nil
}
```

### Next Steps

* [Examples](https://github.com/mark3labs/flyt/tree/main/cookbook) - See best practices in action
* [Advanced Usage](/advanced/custom-nodes) - Advanced patterns
* [Core Concepts](/concepts/nodes) - Review fundamentals


## Batch Flows

Run the same flow multiple times with different parameters, perfect for processing multiple entities or parallel workflows.

### Basic Batch Flow

Run a flow for each set of inputs:

```go
// Create a flow factory - returns a new flow instance for each iteration
flowFactory := func() *flyt.Flow {
    validateNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Each flow has its own SharedStore with merged FlowInputs
            userID := shared.GetInt("user_id")
            email := shared.GetString("email")
            return map[string]any{"user_id": userID, "email": email}, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            data := prepResult.(map[string]any)
            // Process user data
            return processUser(data), nil
        }),
    )
    return flyt.NewFlow(validateNode)
}

// Define input parameters for each flow iteration
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    // Could fetch from database, API, etc.
    return []flyt.FlowInputs{
        {"user_id": 1, "email": "user1@example.com"},
        {"user_id": 2, "email": "user2@example.com"},
        {"user_id": 3, "email": "user3@example.com"},
    }, nil
}

// Create and run batch flow
batchFlow := flyt.NewBatchFlow(flowFactory, batchFunc, true) // true for concurrent
shared := flyt.NewSharedStore()
err := batchFlow.Run(ctx, shared)
```

### Sequential vs Concurrent Execution

Control how flows are executed:

```go
// Sequential - one flow at a time
sequentialBatch := flyt.NewBatchFlow(flowFactory, batchFunc, false)

// Concurrent - multiple flows in parallel
concurrentBatch := flyt.NewBatchFlow(flowFactory, batchFunc, true)
```

### Dynamic Input Generation

Generate inputs based on runtime data:

```go
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    // Get configuration from parent shared store
    config := shared.GetMap("batch_config")
    batchSize := int(config["size"].(float64))  // JSON numbers are float64
    
    // Fetch data from database
    users, err := fetchUsers(batchSize)
    if err != nil {
        return nil, err
    }
    
    // Convert to FlowInputs
    inputs := make([]flyt.FlowInputs, len(users))
    for i, user := range users {
        inputs[i] = flyt.FlowInputs{
            "user_id":   user.ID,
            "user_name": user.Name,
            "user_data": user,
        }
    }
    
    return inputs, nil
}
```

### Complex Flow Factory

Create sophisticated flows for each batch:

```go
flowFactory := func() *flyt.Flow {
    // Create nodes
    fetchNode := createFetchNode()
    validateNode := createValidateNode()
    processNode := createProcessNode()
    saveNode := createSaveNode()
    errorNode := createErrorNode()
    
    // Build flow with error handling
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, validateNode)
    flow.Connect(validateNode, "valid", processNode)
    flow.Connect(validateNode, "invalid", errorNode)
    flow.Connect(processNode, flyt.DefaultAction, saveNode)
    flow.Connect(processNode, "error", errorNode)
    
    return flow
}
```

### Batch Flow with Configuration

Pass configuration to batch flows:

```go
func createConfiguredBatchFlow(config Config) *flyt.Flow {
    flowFactory := func() *flyt.Flow {
        // Each flow gets the same configuration
        node := flyt.NewNode(
            flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
                // Use config in processing
                return processWithConfig(prepResult, config), nil
            }),
        )
        return flyt.NewFlow(node)
    }
    
    batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
        items := shared.GetSlice("items")
        
        inputs := make([]flyt.FlowInputs, 0)
        for _, item := range items {
            inputs = append(inputs, flyt.FlowInputs{
                "item": item,
                "config": config,
            })
        }
        
        return inputs, nil
    }
    
    return flyt.NewBatchFlow(flowFactory, batchFunc, true)
}
```

### Result Aggregation

Collect results from all flows:

```go
type ResultCollector struct {
    mu      sync.Mutex
    results []any
    errors  []error
}

func createAggregatingBatchFlow(collector *ResultCollector) *flyt.Flow {
    flowFactory := func() *flyt.Flow {
        node := flyt.NewNode(
            flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
                result, err := process(prepResult)
                
                collector.mu.Lock()
                if err != nil {
                    collector.errors = append(collector.errors, err)
                } else {
                    collector.results = append(collector.results, result)
                }
                collector.mu.Unlock()
                
                return result, err
            }),
        )
        return flyt.NewFlow(node)
    }
    
    // ... rest of batch flow setup
}
```

### Batch Flow with Progress

Track progress across batch execution:

```go
type ProgressTracker struct {
    total     int
    completed int32
    failed    int32
}

func createProgressBatchFlow(tracker *ProgressTracker) *flyt.Flow {
    flowFactory := func() *flyt.Flow {
        node := flyt.NewNode(
            flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
                if execResult != nil {
                    atomic.AddInt32(&tracker.completed, 1)
                } else {
                    atomic.AddInt32(&tracker.failed, 1)
                }
                
                progress := atomic.LoadInt32(&tracker.completed) + atomic.LoadInt32(&tracker.failed)
                percentage := float64(progress) / float64(tracker.total) * 100
                
                log.Printf("Batch progress: %.1f%% (%d/%d)", percentage, progress, tracker.total)
                
                return flyt.DefaultAction, nil
            }),
        )
        return flyt.NewFlow(node)
    }
    
    batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
        inputs := generateInputs()
        tracker.total = len(inputs)
        return inputs, nil
    }
    
    return flyt.NewBatchFlow(flowFactory, batchFunc, true)
}
```

### Conditional Batch Processing

Process batches based on conditions:

```go
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    mode := shared.GetString("processing_mode")
    
    var inputs []flyt.FlowInputs
    
    switch mode {
    case "all":
        inputs = getAllInputs()
    case "pending":
        inputs = getPendingInputs()
    case "failed":
        inputs = getFailedInputs()
    default:
        return nil, fmt.Errorf("unknown mode: %s", mode)
    }
    
    // Filter based on additional criteria
    filtered := make([]flyt.FlowInputs, 0)
    for _, input := range inputs {
        if shouldProcess(input) {
            filtered = append(filtered, input)
        }
    }
    
    return filtered, nil
}
```

### Nested Batch Flows

Batch flows within batch flows:

```go
outerFlowFactory := func() *flyt.Flow {
    // Inner batch flow for processing items
    innerBatchFlow := flyt.NewBatchFlow(
        innerFlowFactory,
        innerBatchFunc,
        true,
    )
    
    // Outer flow that includes the batch
    fetchNode := createFetchNode()
    
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, innerBatchFlow)
    flow.Connect(innerBatchFlow, flyt.DefaultAction, aggregateNode)
    
    return flow
}

// Create outer batch flow
outerBatchFlow := flyt.NewBatchFlow(outerFlowFactory, outerBatchFunc, false)
```

### Error Recovery

Handle failures in batch flows:

```go
flowFactory := func() *flyt.Flow {
    node := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            result, err := riskyOperation(prepResult)
            if err != nil {
                // Store error for later analysis
                errorData := map[string]any{
                    "input": prepResult,
                    "error": err.Error(),
                    "time":  time.Now(),
                }
                storeError(errorData)
                
                // Return partial result
                return map[string]any{
                    "status": "failed",
                    "error":  err.Error(),
                }, nil  // Don't fail the entire batch
            }
            return result, nil
        }),
    )
    return flyt.NewFlow(node)
}
```

### Best Practices

1. **Isolate Flows**: Each flow instance should be independent
2. **Manage Resources**: Be mindful of resource usage with concurrent flows
3. **Handle Failures**: Decide whether one failure should stop the batch
4. **Track Progress**: Implement progress tracking for long-running batches
5. **Limit Concurrency**: Set reasonable concurrency limits
6. **Test Thoroughly**: Test with various batch sizes and failure scenarios

### Next Steps

* [Batch Processing](/advanced/batch-processing) - Process items within a single node
* [Nested Flows](/advanced/nested-flows) - Compose complex workflows
* [Worker Pool](/advanced/worker-pool) - Fine-grained concurrency control


## Batch Processing

Process collections of items efficiently with concurrent or sequential execution.

### Basic Batch Processing

Process items with a simple function:

```go
// Define processing function
processFunc := func(ctx context.Context, item any) (any, error) {
    // Process each item
    return fmt.Sprintf("processed: %v", item), nil
}

// Create batch node
batchNode := flyt.NewBatchNode(processFunc, true) // true for concurrent

// Set items in shared store
shared := flyt.NewSharedStore()
shared.Set("items", []string{"item1", "item2", "item3"})

// Run batch processing
ctx := context.Background()
action, err := flyt.Run(ctx, batchNode, shared)

// Get results using type-safe getter
results := shared.GetSlice("results")
fmt.Println(results) // ["processed: item1", "processed: item2", "processed: item3"]
```

### Sequential vs Concurrent

Choose the right execution mode:

```go
// Sequential processing - maintains order
sequentialNode := flyt.NewBatchNode(processFunc, false)

// Concurrent processing - faster but unordered
concurrentNode := flyt.NewBatchNode(processFunc, true)
```

### Custom Keys

Use custom keys for input and output:

```go
batchNode := flyt.NewBatchNodeWithKeys(
    processFunc,
    true,           // concurrent
    "input_data",   // custom input key
    "output_data",  // custom output key
)

shared.Set("input_data", items)
// Results will be in "output_data"
```

### Advanced Configuration

Fine-tune batch processing with BatchConfig:

```go
config := &flyt.BatchConfig{
    BatchSize:   10,        // Process 10 items at a time
    Concurrency: 5,         // Use 5 concurrent workers
    ItemsKey:    "data",    // Key for input items
    ResultsKey:  "output",  // Key for results
    CountKey:    "total",   // Key for processed count
}

processFunc := func(ctx context.Context, item any) (any, error) {
    // Heavy processing
    time.Sleep(100 * time.Millisecond)
    return processItem(item)
}

batchNode := flyt.NewBatchNodeWithConfig(processFunc, true, config)
```

### Error Handling

Handle errors in batch operations:

```go
processFunc := func(ctx context.Context, item any) (any, error) {
    if item.(int) < 0 {
        return nil, fmt.Errorf("negative value: %v", item)
    }
    return item.(int) * 2, nil
}

batchNode := flyt.NewBatchNode(processFunc, true)
shared.Set("items", []int{1, -2, 3, -4, 5})

action, err := flyt.Run(ctx, batchNode, shared)
if err != nil {
    if batchErr, ok := err.(*flyt.BatchError); ok {
        fmt.Printf("Batch processing failed: %s\n", batchErr.Message)
        
        // Access individual errors
        for i, e := range batchErr.Errors {
            if e != nil {
                fmt.Printf("Item %d failed: %v\n", i, e)
            }
        }
    }
}
```

### Batch Processing Patterns

#### Map Pattern

Transform each item:

```go
mapFunc := func(ctx context.Context, item any) (any, error) {
    user := item.(User)
    return UserDTO{
        ID:   user.ID,
        Name: user.Name,
        Age:  user.Age,
    }, nil
}

mapNode := flyt.NewBatchNode(mapFunc, true)
```

#### Filter Pattern

Process only matching items:

```go
filterFunc := func(ctx context.Context, item any) (any, error) {
    value := item.(int)
    if value > 10 {
        return value, nil
    }
    return nil, nil  // Skip this item
}

filterNode := flyt.NewBatchNode(filterFunc, true)
```

#### Reduce Pattern

Aggregate results:

```go
type SumNode struct {
    *flyt.BaseNode
    total int
    mu    sync.Mutex
}

func (n *SumNode) Exec(ctx context.Context, prepResult any) (any, error) {
    items := prepResult.([]int)
    
    for _, item := range items {
        n.mu.Lock()
        n.total += item
        n.mu.Unlock()
    }
    
    return n.total, nil
}
```

### Chunked Processing

Process large datasets in chunks:

```go
func createChunkedProcessor(chunkSize int) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            items := shared.GetSlice("items")
            return items, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            items := prepResult.([]any)
            results := make([]any, 0, len(items))
            
            // Process in chunks
            for i := 0; i < len(items); i += chunkSize {
                end := i + chunkSize
                if end > len(items) {
                    end = len(items)
                }
                
                chunk := items[i:end]
                chunkResults := processChunk(chunk)
                results = append(results, chunkResults...)
            }
            
            return results, nil
        }),
    )
}
```

### Progress Tracking

Monitor batch processing progress:

```go
type ProgressBatchNode struct {
    *flyt.BaseNode
    processed int32
    total     int32
}

func (n *ProgressBatchNode) processWithProgress(ctx context.Context, items []any) ([]any, error) {
    n.total = int32(len(items))
    results := make([]any, len(items))
    
    var wg sync.WaitGroup
    for i, item := range items {
        wg.Add(1)
        go func(idx int, data any) {
            defer wg.Done()
            
            result, _ := processItem(data)
            results[idx] = result
            
            // Update progress
            current := atomic.AddInt32(&n.processed, 1)
            progress := float64(current) / float64(n.total) * 100
            
            if current%10 == 0 || current == n.total {
                log.Printf("Progress: %.1f%% (%d/%d)", progress, current, n.total)
            }
        }(i, item)
    }
    
    wg.Wait()
    return results, nil
}
```

### Rate-Limited Batch Processing

Control processing rate:

```go
func createRateLimitedBatchNode(rps int) flyt.Node {
    limiter := rate.NewLimiter(rate.Limit(rps), 1)
    
    processFunc := func(ctx context.Context, item any) (any, error) {
        // Wait for rate limiter
        if err := limiter.Wait(ctx); err != nil {
            return nil, err
        }
        
        // Process item
        return callAPI(item)
    }
    
    return flyt.NewBatchNode(processFunc, true)
}
```

### Batch with Timeout

Set timeouts for batch operations:

```go
func createTimeoutBatchNode(timeout time.Duration) flyt.Node {
    processFunc := func(ctx context.Context, item any) (any, error) {
        // Create timeout context for this item
        itemCtx, cancel := context.WithTimeout(ctx, timeout)
        defer cancel()
        
        resultChan := make(chan any)
        errChan := make(chan error)
        
        go func() {
            result, err := processItem(item)
            if err != nil {
                errChan <- err
            } else {
                resultChan <- result
            }
        }()
        
        select {
        case result := <-resultChan:
            return result, nil
        case err := <-errChan:
            return nil, err
        case <-itemCtx.Done():
            return nil, fmt.Errorf("processing timeout for item: %v", item)
        }
    }
    
    return flyt.NewBatchNode(processFunc, true)
}
```

### Best Practices

1. **Choose Concurrency Wisely**: Use concurrent for I/O-bound, sequential for order-dependent
2. **Handle Errors Gracefully**: Decide whether to fail fast or collect all errors
3. **Monitor Progress**: Add logging for long-running batches
4. **Set Reasonable Limits**: Configure batch size and concurrency based on resources
5. **Test with Real Data**: Test with production-like data volumes
6. **Consider Memory Usage**: Be mindful of memory when processing large batches

### Next Steps

* [Batch Flows](/advanced/batch-flows) - Run flows with multiple inputs
* [Worker Pool](/advanced/worker-pool) - Custom concurrent processing
* [Error Handling](/patterns/error-handling) - Handle batch errors


## Custom Node Types

Create sophisticated nodes with custom behavior, state management, and advanced features.

### Basic Custom Node

Extend BaseNode for custom functionality:

```go
type CustomNode struct {
    *flyt.BaseNode
    config Config
    state  State
}

func NewCustomNode(config Config) *CustomNode {
    return &CustomNode{
        BaseNode: flyt.NewBaseNode(),
        config:   config,
        state:    NewState(),
    }
}

func (n *CustomNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    // Custom preparation logic
    input := shared.GetString("input")
    n.state.Prepare(input)
    return input, nil
}

func (n *CustomNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Custom execution logic
    result := n.processWithConfig(prepResult, n.config)
    n.state.Update(result)
    return result, nil
}

func (n *CustomNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    // Custom post-processing
    shared.Set("state", n.state)
    
    if n.state.IsComplete() {
        return "complete", nil
    }
    return "continue", nil
}
```

### Stateful Nodes

Maintain state across executions:

```go
type AccumulatorNode struct {
    *flyt.BaseNode
    mu       sync.Mutex
    values   []any
    maxSize  int
}

func NewAccumulatorNode(maxSize int) *AccumulatorNode {
    return &AccumulatorNode{
        BaseNode: flyt.NewBaseNode(),
        values:   make([]any, 0, maxSize),
        maxSize:  maxSize,
    }
}

func (n *AccumulatorNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.mu.Lock()
    defer n.mu.Unlock()
    
    // Add to accumulator
    n.values = append(n.values, prepResult)
    
    // Check if buffer is full
    if len(n.values) >= n.maxSize {
        // Process batch
        result := n.processBatch(n.values)
        n.values = n.values[:0] // Clear buffer
        return result, nil
    }
    
    return nil, nil
}

func (n *AccumulatorNode) processBatch(values []any) any {
    // Process accumulated values
    return map[string]any{
        "count": len(values),
        "data":  values,
    }
}
```

### Resource-Managing Nodes

Handle external resources:

```go
type DatabaseNode struct {
    *flyt.BaseNode
    pool     *sql.DB
    prepared map[string]*sql.Stmt
    mu       sync.RWMutex
}

func NewDatabaseNode(dsn string) (*DatabaseNode, error) {
    db, err := sql.Open("postgres", dsn)
    if err != nil {
        return nil, err
    }
    
    db.SetMaxOpenConns(25)
    db.SetMaxIdleConns(5)
    
    return &DatabaseNode{
        BaseNode: flyt.NewBaseNode(),
        pool:     db,
        prepared: make(map[string]*sql.Stmt),
    }, nil
}

func (n *DatabaseNode) Exec(ctx context.Context, prepResult any) (any, error) {
    query := prepResult.(QueryRequest)
    
    // Use prepared statement if available
    stmt, err := n.getOrPrepare(query.SQL)
    if err != nil {
        return nil, err
    }
    
    rows, err := stmt.QueryContext(ctx, query.Args...)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    return n.scanResults(rows)
}

func (n *DatabaseNode) getOrPrepare(sql string) (*sql.Stmt, error) {
    n.mu.RLock()
    stmt, exists := n.prepared[sql]
    n.mu.RUnlock()
    
    if exists {
        return stmt, nil
    }
    
    n.mu.Lock()
    defer n.mu.Unlock()
    
    // Double-check after acquiring write lock
    if stmt, exists := n.prepared[sql]; exists {
        return stmt, nil
    }
    
    stmt, err := n.pool.Prepare(sql)
    if err != nil {
        return nil, err
    }
    
    n.prepared[sql] = stmt
    return stmt, nil
}

func (n *DatabaseNode) Close() error {
    n.mu.Lock()
    defer n.mu.Unlock()
    
    for _, stmt := range n.prepared {
        stmt.Close()
    }
    
    return n.pool.Close()
}
```

### RetryableNode Implementation

Custom retry logic:

```go
type SmartRetryNode struct {
    *flyt.BaseNode
    attempts      int
    lastError     error
    backoffFactor float64
}

func NewSmartRetryNode() *SmartRetryNode {
    return &SmartRetryNode{
        BaseNode:      flyt.NewBaseNode(),
        backoffFactor: 1.5,
    }
}

func (n *SmartRetryNode) GetMaxRetries() int {
    // Dynamic retry count based on error type
    if n.lastError != nil {
        switch {
        case isNetworkError(n.lastError):
            return 5  // More retries for network issues
        case isRateLimitError(n.lastError):
            return 3  // Fewer retries for rate limits
        case isAuthError(n.lastError):
            return 0  // No retries for auth errors
        default:
            return 2
        }
    }
    return 3
}

func (n *SmartRetryNode) GetWait() time.Duration {
    if n.lastError != nil && isRateLimitError(n.lastError) {
        // Extract retry-after from error if available
        if retryAfter := extractRetryAfter(n.lastError); retryAfter > 0 {
            return retryAfter
        }
    }
    
    // Exponential backoff with jitter
    base := math.Pow(n.backoffFactor, float64(n.attempts))
    jitter := rand.Float64() * 0.3 * base  // 30% jitter
    return time.Duration((base + jitter) * float64(time.Second))
}

func (n *SmartRetryNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.attempts++
    
    result, err := n.performOperation(ctx, prepResult)
    if err != nil {
        n.lastError = err
        return nil, err
    }
    
    // Reset on success
    n.attempts = 0
    n.lastError = nil
    return result, nil
}
```

### Composite Nodes

Combine multiple operations:

```go
type PipelineNode struct {
    *flyt.BaseNode
    stages []func(context.Context, any) (any, error)
}

func NewPipelineNode(stages ...func(context.Context, any) (any, error)) *PipelineNode {
    return &PipelineNode{
        BaseNode: flyt.NewBaseNode(),
        stages:   stages,
    }
}

func (n *PipelineNode) Exec(ctx context.Context, prepResult any) (any, error) {
    result := prepResult
    
    for i, stage := range n.stages {
        select {
        case <-ctx.Done():
            return nil, ctx.Err()
        default:
        }
        
        var err error
        result, err = stage(ctx, result)
        if err != nil {
            return nil, fmt.Errorf("stage %d failed: %w", i, err)
        }
    }
    
    return result, nil
}
```

### Monitoring Nodes

Add observability:

```go
type MonitoredNode struct {
    *flyt.BaseNode
    name    string
    metrics *Metrics
}

type Metrics struct {
    executions   int64
    successes    int64
    failures     int64
    totalLatency int64
}

func NewMonitoredNode(name string, baseNode flyt.Node) *MonitoredNode {
    return &MonitoredNode{
        BaseNode: baseNode.(*flyt.BaseNode),
        name:     name,
        metrics:  &Metrics{},
    }
}

func (n *MonitoredNode) Exec(ctx context.Context, prepResult any) (any, error) {
    start := time.Now()
    atomic.AddInt64(&n.metrics.executions, 1)
    
    result, err := n.BaseNode.Exec(ctx, prepResult)
    
    latency := time.Since(start).Milliseconds()
    atomic.AddInt64(&n.metrics.totalLatency, latency)
    
    if err != nil {
        atomic.AddInt64(&n.metrics.failures, 1)
        log.Printf("[%s] Execution failed: %v (latency: %dms)", n.name, err, latency)
    } else {
        atomic.AddInt64(&n.metrics.successes, 1)
        log.Printf("[%s] Execution succeeded (latency: %dms)", n.name, latency)
    }
    
    return result, err
}

func (n *MonitoredNode) GetMetrics() map[string]any {
    return map[string]any{
        "executions":    atomic.LoadInt64(&n.metrics.executions),
        "successes":     atomic.LoadInt64(&n.metrics.successes),
        "failures":      atomic.LoadInt64(&n.metrics.failures),
        "avg_latency":   n.getAverageLatency(),
        "success_rate":  n.getSuccessRate(),
    }
}
```

### Async Nodes

Handle asynchronous operations:

```go
type AsyncNode struct {
    *flyt.BaseNode
    workers int
    queue   chan Task
    wg      sync.WaitGroup
}

func NewAsyncNode(workers int) *AsyncNode {
    n := &AsyncNode{
        BaseNode: flyt.NewBaseNode(),
        workers:  workers,
        queue:    make(chan Task, workers*2),
    }
    
    // Start workers
    for i := 0; i < workers; i++ {
        go n.worker()
    }
    
    return n
}

func (n *AsyncNode) worker() {
    for task := range n.queue {
        n.processTask(task)
        n.wg.Done()
    }
}

func (n *AsyncNode) Exec(ctx context.Context, prepResult any) (any, error) {
    tasks := prepResult.([]Task)
    results := make([]Result, len(tasks))
    
    // Submit all tasks
    for i, task := range tasks {
        n.wg.Add(1)
        task.Index = i
        task.Results = &results
        n.queue <- task
    }
    
    // Wait for completion
    done := make(chan struct{})
    go func() {
        n.wg.Wait()
        close(done)
    }()
    
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    case <-done:
        return results, nil
    }
}

func (n *AsyncNode) Close() {
    close(n.queue)
}
```

### Validation Nodes

Ensure data integrity:

```go
type ValidationNode struct {
    *flyt.BaseNode
    rules []ValidationRule
}

type ValidationRule interface {
    Validate(any) error
    Name() string
}

func NewValidationNode(rules ...ValidationRule) *ValidationNode {
    return &ValidationNode{
        BaseNode: flyt.NewBaseNode(),
        rules:    rules,
    }
}

func (n *ValidationNode) Exec(ctx context.Context, prepResult any) (any, error) {
    var errors []string
    
    for _, rule := range n.rules {
        if err := rule.Validate(prepResult); err != nil {
            errors = append(errors, fmt.Sprintf("%s: %v", rule.Name(), err))
        }
    }
    
    if len(errors) > 0 {
        return nil, fmt.Errorf("validation failed: %s", strings.Join(errors, "; "))
    }
    
    return prepResult, nil
}

func (n *ValidationNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if execResult == nil {
        return "invalid", nil
    }
    return "valid", nil
}
```

### Best Practices

1. **Clear Interfaces**: Define clear interfaces for custom nodes
2. **Thread Safety**: Ensure nodes are thread-safe for concurrent use
3. **Resource Management**: Properly manage external resources
4. **Error Handling**: Provide detailed error information
5. **Testing**: Write comprehensive tests for custom logic
6. **Documentation**: Document node behavior and requirements
7. **Monitoring**: Add metrics and logging for observability

### Next Steps

* [RetryableNode Interface](/concepts/nodes#retryablenode-interface) - Custom retry logic
* [FallbackNode Interface](/patterns/fallback) - Graceful degradation
* [Worker Pool](/advanced/worker-pool) - Concurrent task management


## Flow as Node

Flows implement the Node interface, allowing them to be used anywhere a node is expected. This enables powerful composition patterns.

### The Node Interface

Flows implement all Node methods:

```go
type Node interface {
    Prep(ctx context.Context, shared *SharedStore) (any, error)
    Exec(ctx context.Context, prepResult any) (any, error)
    Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error)
}

// Flow implements Node
var _ Node = (*Flow)(nil)
```

### Basic Usage

Use a flow wherever a node is expected:

```go
// Create a reusable flow
processingFlow := flyt.NewFlow(validateNode)
processingFlow.Connect(validateNode, "valid", transformNode)
processingFlow.Connect(transformNode, flyt.DefaultAction, enrichNode)

// Use the flow as a node
mainFlow := flyt.NewFlow(fetchNode)
mainFlow.Connect(fetchNode, flyt.DefaultAction, processingFlow) // Flow used as node
mainFlow.Connect(processingFlow, flyt.DefaultAction, saveNode)
```

### Flow Lifecycle as Node

Understanding how flows behave as nodes:

```go
// When a flow is used as a node:
// 1. Prep: Prepares the flow's start node
// 2. Exec: Runs the entire flow
// 3. Post: Returns the final action from the flow

func demonstrateFlowLifecycle() {
    subFlow := flyt.NewFlow(startNode)
    subFlow.Connect(startNode, flyt.DefaultAction, endNode)
    
    // When mainFlow executes subFlow:
    // - subFlow.Prep() calls startNode.Prep()
    // - subFlow.Exec() runs the entire sub-flow
    // - subFlow.Post() returns the final action
    
    mainFlow := flyt.NewFlow(initNode)
    mainFlow.Connect(initNode, flyt.DefaultAction, subFlow)
}
```

### Composable Workflows

Build complex workflows from simpler ones:

```go
// Level 1: Basic operations
func createValidationFlow() *flyt.Flow {
    schemaNode := createSchemaValidationNode()
    businessNode := createBusinessValidationNode()
    
    flow := flyt.NewFlow(schemaNode)
    flow.Connect(schemaNode, "valid", businessNode)
    return flow
}

func createEnrichmentFlow() *flyt.Flow {
    fetchNode := createDataFetchNode()
    mergeNode := createDataMergeNode()
    
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, mergeNode)
    return flow
}

// Level 2: Combine basic flows
func createProcessingPipeline() *flyt.Flow {
    validation := createValidationFlow()
    enrichment := createEnrichmentFlow()
    
    pipeline := flyt.NewFlow(validation)
    pipeline.Connect(validation, flyt.DefaultAction, enrichment)
    return pipeline
}

// Level 3: Use in application
func createApplicationFlow() *flyt.Flow {
    auth := createAuthFlow()
    pipeline := createProcessingPipeline()
    audit := createAuditFlow()
    
    app := flyt.NewFlow(auth)
    app.Connect(auth, flyt.DefaultAction, pipeline)
    app.Connect(pipeline, flyt.DefaultAction, audit)
    return app
}
```

### Dynamic Flow Selection

Choose flows at runtime:

```go
type FlowSelector struct {
    flows map[string]*flyt.Flow
}

func (fs *FlowSelector) CreateSelectorNode() flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            flowType := prepResult.(string)
            return flowType, nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            return flyt.Action(execResult.(string)), nil
        }),
    )
}

func (fs *FlowSelector) BuildDynamicFlow() *flyt.Flow {
    selector := fs.CreateSelectorNode()
    mainFlow := flyt.NewFlow(selector)
    
    // Connect different flows based on selection
    for name, flow := range fs.flows {
        mainFlow.Connect(selector, flyt.Action(name), flow)
    }
    
    return mainFlow
}

// Usage
selector := &FlowSelector{
    flows: map[string]*flyt.Flow{
        "simple":  createSimpleFlow(),
        "complex": createComplexFlow(),
        "custom":  createCustomFlow(),
    },
}

dynamicFlow := selector.BuildDynamicFlow()
```

### Flow Factories

Create flows on demand:

```go
type FlowFactory interface {
    CreateFlow(config FlowConfig) *flyt.Flow
}

type ProcessingFlowFactory struct{}

func (f *ProcessingFlowFactory) CreateFlow(config FlowConfig) *flyt.Flow {
    // Create nodes based on configuration
    var nodes []flyt.Node
    
    for _, nodeConfig := range config.Nodes {
        node := createNodeFromConfig(nodeConfig)
        nodes = append(nodes, node)
    }
    
    // Build flow
    flow := flyt.NewFlow(nodes[0])
    for i := 0; i < len(nodes)-1; i++ {
        flow.Connect(nodes[i], flyt.DefaultAction, nodes[i+1])
    }
    
    return flow
}

// Use factory-created flows as nodes
func createDynamicPipeline(factory FlowFactory, configs []FlowConfig) *flyt.Flow {
    pipeline := flyt.NewFlow(startNode)
    previous := flyt.Node(startNode)
    
    for _, config := range configs {
        flow := factory.CreateFlow(config)
        pipeline.Connect(previous, flyt.DefaultAction, flow)
        previous = flow
    }
    
    return pipeline
}
```

### Recursive Flow Patterns

Flows containing themselves:

```go
func createRecursiveProcessingFlow(maxDepth int) *flyt.Flow {
    var flow *flyt.Flow
    
    depthCheck := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            depth := shared.GetInt("recursion_depth")
            return depth, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            depth := prepResult.(int)
            if depth >= maxDepth {
                return "terminate", nil
            }
            return "recurse", nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            if execResult.(string) == "recurse" {
                depth := prepResult.(int)
                shared.Set("recursion_depth", depth+1)
            }
            return flyt.Action(execResult.(string)), nil
        }),
    )
    
    processNode := createProcessNode()
    
    flow = flyt.NewFlow(depthCheck)
    flow.Connect(depthCheck, "recurse", processNode)
    flow.Connect(processNode, flyt.DefaultAction, flow) // Recursive reference
    flow.Connect(depthCheck, "terminate", nil)
    
    return flow
}
```

### Flow Middleware

Wrap flows with additional behavior:

```go
func withLogging(name string, flow *flyt.Flow) *flyt.Flow {
    logStart := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            log.Printf("[%s] Flow starting", name)
            return prepResult, nil
        }),
    )
    
    logEnd := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            log.Printf("[%s] Flow completed", name)
            return prepResult, nil
        }),
    )
    
    wrapped := flyt.NewFlow(logStart)
    wrapped.Connect(logStart, flyt.DefaultAction, flow)
    wrapped.Connect(flow, flyt.DefaultAction, logEnd)
    
    return wrapped
}

// Usage
processFlow := createProcessingFlow()
loggedFlow := withLogging("ProcessingPipeline", processFlow)
```

### Testing Flows as Nodes

Test flow behavior when used as nodes:

```go
func TestFlowAsNode(t *testing.T) {
    // Create a simple flow
    innerFlow := flyt.NewFlow(
        flyt.NewNode(
            flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
                return "inner_result", nil
            }),
        ),
    )
    
    // Test the flow directly
    ctx := context.Background()
    shared := flyt.NewSharedStore()
    
    // Call flow methods as if it were a node
    prepResult, err := innerFlow.Prep(ctx, shared)
    assert.NoError(t, err)
    
    execResult, err := innerFlow.Exec(ctx, prepResult)
    assert.NoError(t, err)
    
    action, err := innerFlow.Post(ctx, shared, prepResult, execResult)
    assert.NoError(t, err)
    assert.Equal(t, flyt.DefaultAction, action)
}
```

### Performance Considerations

Using flows as nodes:

```go
// Lightweight flow - good as node
func createLightweightFlow() *flyt.Flow {
    node := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Simple operation
            return transform(prepResult), nil
        }),
    )
    return flyt.NewFlow(node)
}

// Heavy flow - consider alternatives
func createHeavyFlow() *flyt.Flow {
    // Many nodes, complex logic
    // Consider breaking into smaller flows
    // or using batch processing
}

// Alternative: Use node with embedded logic
func createOptimizedNode() flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Inline the flow logic for performance
            result := step1(prepResult)
            result = step2(result)
            result = step3(result)
            return result, nil
        }),
    )
}
```

### Best Practices

1. **Keep Flows Focused**: Flows used as nodes should have clear, single purposes
2. **Document Behavior**: Clearly document what the flow expects and returns
3. **Test Thoroughly**: Test flows both standalone and as nodes
4. **Consider Performance**: Be mindful of overhead when nesting many flows
5. **Use Meaningful Names**: Name flows to indicate they're used as nodes
6. **Handle Errors**: Ensure proper error propagation through nested flows

### Next Steps

* [Nested Flows](/advanced/nested-flows) - Complex flow composition
* [Nodes](/concepts/nodes) - Node interface details
* [Flows](/concepts/flows) - Flow fundamentals


## Nested Flows

Compose complex workflows by nesting flows within flows, creating modular and reusable workflow components.

### Basic Nested Flow

Use a flow as a node in another flow:

```go
// Create a sub-flow for validation
validationFlow := func() *flyt.Flow {
    schemaCheck := createSchemaCheckNode()
    businessRules := createBusinessRulesNode()
    
    flow := flyt.NewFlow(schemaCheck)
    flow.Connect(schemaCheck, "valid", businessRules)
    flow.Connect(schemaCheck, "invalid", nil)
    
    return flow
}()

// Use in main flow
mainFlow := flyt.NewFlow(fetchNode)
mainFlow.Connect(fetchNode, flyt.DefaultAction, validationFlow)
mainFlow.Connect(validationFlow, flyt.DefaultAction, processNode)
```

### Reusable Flow Components

Create modular flow components:

```go
// Reusable authentication flow
func createAuthFlow() *flyt.Flow {
    checkToken := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            token := prepResult.(string)
            return validateToken(token)
        }),
    )
    
    refreshToken := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            return refreshAuthToken()
        }),
    )
    
    flow := flyt.NewFlow(checkToken)
    flow.Connect(checkToken, "expired", refreshToken)
    flow.Connect(checkToken, "valid", nil)
    flow.Connect(refreshToken, flyt.DefaultAction, nil)
    
    return flow
}

// Use in multiple places
apiFlow := flyt.NewFlow(startNode)
apiFlow.Connect(startNode, flyt.DefaultAction, createAuthFlow())

adminFlow := flyt.NewFlow(adminNode)
adminFlow.Connect(adminNode, flyt.DefaultAction, createAuthFlow())
```

### Hierarchical Workflows

Build multi-level workflow hierarchies:

```go
// Level 3: Atomic operations
func createDatabaseOperation() *flyt.Flow {
    connect := createConnectNode()
    query := createQueryNode()
    disconnect := createDisconnectNode()
    
    flow := flyt.NewFlow(connect)
    flow.Connect(connect, flyt.DefaultAction, query)
    flow.Connect(query, flyt.DefaultAction, disconnect)
    
    return flow
}

// Level 2: Business operations
func createUserOperation() *flyt.Flow {
    validate := createValidateUserNode()
    dbOp := createDatabaseOperation()
    notify := createNotificationNode()
    
    flow := flyt.NewFlow(validate)
    flow.Connect(validate, "valid", dbOp)
    flow.Connect(dbOp, flyt.DefaultAction, notify)
    
    return flow
}

// Level 1: Application flow
func createApplicationFlow() *flyt.Flow {
    auth := createAuthFlow()
    userOp := createUserOperation()
    audit := createAuditFlow()
    
    flow := flyt.NewFlow(auth)
    flow.Connect(auth, flyt.DefaultAction, userOp)
    flow.Connect(userOp, flyt.DefaultAction, audit)
    
    return flow
}
```

### Conditional Nesting

Dynamically choose nested flows:

```go
routerNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        request := prepResult.(Request)
        return request.Type, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        return flyt.Action(execResult.(string)), nil
    }),
)

mainFlow := flyt.NewFlow(routerNode)
mainFlow.Connect(routerNode, "user", createUserFlow())
mainFlow.Connect(routerNode, "admin", createAdminFlow())
mainFlow.Connect(routerNode, "api", createAPIFlow())
```

### Shared Context in Nested Flows

Pass context through nested flows:

```go
func createNestedFlowWithContext(parentContext map[string]any) *flyt.Flow {
    node := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Access parent context
            for k, v := range parentContext {
                shared.Set(k, v)
            }
            
            // Get data from parent flow
            parentData := shared.GetMap("parent_data")
            return parentData, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Process with parent context
            return processWithContext(prepResult, parentContext), nil
        }),
    )
    
    return flyt.NewFlow(node)
}
```

### Error Propagation

Handle errors across nested flows:

```go
func createErrorHandlingFlow() *flyt.Flow {
    subFlow := createSubFlow()
    errorHandler := createErrorHandlerNode()
    
    mainFlow := flyt.NewFlow(startNode)
    mainFlow.Connect(startNode, flyt.DefaultAction, subFlow)
    mainFlow.Connect(subFlow, "error", errorHandler)
    mainFlow.Connect(subFlow, flyt.DefaultAction, successNode)
    
    // Error handler can retry or recover
    mainFlow.Connect(errorHandler, "retry", subFlow)
    mainFlow.Connect(errorHandler, "abort", nil)
    
    return mainFlow
}
```

### Recursive Flows

Create recursive workflow patterns:

```go
func createRecursiveFlow(maxDepth int) *flyt.Flow {
    checkDepth := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            depth := shared.GetInt("depth")
            return depth, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            depth := prepResult.(int)
            if depth >= maxDepth {
                return "max_depth", nil
            }
            return "continue", nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            if execResult.(string) == "continue" {
                depth := prepResult.(int)
                shared.Set("depth", depth+1)
            }
            return flyt.Action(execResult.(string)), nil
        }),
    )
    
    processNode := createProcessNode()
    
    flow := flyt.NewFlow(checkDepth)
    flow.Connect(checkDepth, "continue", processNode)
    flow.Connect(processNode, flyt.DefaultAction, flow) // Recursive connection
    flow.Connect(checkDepth, "max_depth", nil)
    
    return flow
}
```

### Parallel Nested Flows

Execute nested flows in parallel:

```go
func createParallelNestedFlow() *flyt.Flow {
    splitNode := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Split data for parallel processing
            data := prepResult.(Data)
            shared.Set("part1", data.Part1)
            shared.Set("part2", data.Part2)
            return nil, nil
        }),
    )
    
    // Create parallel sub-flows
    flow1 := createProcessingFlow1()
    flow2 := createProcessingFlow2()
    
    // Merge results
    mergeNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            result1 := shared.GetMap("result1")
            result2 := shared.GetMap("result2")
            return map[string]any{
                "result1": result1,
                "result2": result2,
            }, nil
        }),
    )
    
    // Connect with parallel execution
    mainFlow := flyt.NewFlow(splitNode)
    
    // Both flows execute after split
    mainFlow.Connect(splitNode, "flow1", flow1)
    mainFlow.Connect(splitNode, "flow2", flow2)
    
    // Both must complete before merge
    mainFlow.Connect(flow1, flyt.DefaultAction, mergeNode)
    mainFlow.Connect(flow2, flyt.DefaultAction, mergeNode)
    
    return mainFlow
}
```

### Dynamic Flow Composition

Build flows at runtime:

```go
func createDynamicFlow(config FlowConfig) *flyt.Flow {
    startNode := createStartNode()
    flow := flyt.NewFlow(startNode)
    
    previousNode := flyt.Node(startNode)
    
    for _, step := range config.Steps {
        var stepFlow *flyt.Flow
        
        switch step.Type {
        case "validate":
            stepFlow = createValidationFlow(step.Config)
        case "process":
            stepFlow = createProcessingFlow(step.Config)
        case "save":
            stepFlow = createSaveFlow(step.Config)
        }
        
        if stepFlow != nil {
            flow.Connect(previousNode, flyt.DefaultAction, stepFlow)
            previousNode = stepFlow
        }
    }
    
    return flow
}
```

### Testing Nested Flows

Test nested flows in isolation:

```go
func TestNestedFlow(t *testing.T) {
    // Test sub-flow independently
    subFlow := createSubFlow()
    subShared := flyt.NewSharedStore()
    subShared.Set("test_input", "data")
    
    err := subFlow.Run(context.Background(), subShared)
    assert.NoError(t, err)
    
    // Test main flow with mocked sub-flow
    mockSubFlow := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            return "mocked_result", nil
        }),
    )
    
    mainFlow := flyt.NewFlow(startNode)
    mainFlow.Connect(startNode, flyt.DefaultAction, mockSubFlow)
    
    err = mainFlow.Run(context.Background(), flyt.NewSharedStore())
    assert.NoError(t, err)
}
```

### Best Practices

1. **Keep Flows Focused**: Each flow should have a single, clear purpose
2. **Minimize Coupling**: Flows should communicate through well-defined interfaces
3. **Document Dependencies**: Clearly document what each nested flow expects
4. **Test in Isolation**: Test nested flows independently
5. **Avoid Deep Nesting**: Too many levels make debugging difficult
6. **Use Meaningful Names**: Name flows based on their business function

### Next Steps

* [Flow as Node](/advanced/flow-as-node) - Flows implementing Node interface
* [Batch Flows](/advanced/batch-flows) - Running flows in batches
* [Flows](/concepts/flows) - Flow fundamentals


## Utilities

Helper functions and utilities to simplify common tasks in Flyt workflows.

### ToSlice

Convert various types to slices for batch processing:

```go
// Convert different types to []any
stringSlice := flyt.ToSlice([]string{"a", "b", "c"})
intSlice := flyt.ToSlice([]int{1, 2, 3})
singleItem := flyt.ToSlice("single item") // Returns []any{"single item"}
nilValue := flyt.ToSlice(nil) // Returns empty []any{}

// Useful for batch processing
shared.Set("items", flyt.ToSlice(data))
```

#### Implementation Details

```go
func ToSlice(v any) []any {
    if v == nil {
        return []any{}
    }
    
    rv := reflect.ValueOf(v)
    if rv.Kind() == reflect.Slice {
        result := make([]any, rv.Len())
        for i := 0; i < rv.Len(); i++ {
            result[i] = rv.Index(i).Interface()
        }
        return result
    }
    
    // Single item
    return []any{v}
}
```

### Custom Utility Functions

Create your own utilities:

#### Retry Helper

```go
func RetryOperation(operation func() error, maxRetries int, backoff time.Duration) error {
    var lastErr error
    
    for i := 0; i < maxRetries; i++ {
        if err := operation(); err == nil {
            return nil
        } else {
            lastErr = err
            if i < maxRetries-1 {
                time.Sleep(backoff * time.Duration(i+1))
            }
        }
    }
    
    return fmt.Errorf("operation failed after %d retries: %w", maxRetries, lastErr)
}

// Usage in node
func (n *MyNode) Exec(ctx context.Context, prepResult any) (any, error) {
    var result any
    
    err := RetryOperation(func() error {
        var err error
        result, err = callAPI(prepResult)
        return err
    }, 3, time.Second)
    
    return result, err
}
```

#### Parallel Map

```go
func ParallelMap[T any, R any](items []T, fn func(T) R, workers int) []R {
    results := make([]R, len(items))
    
    var wg sync.WaitGroup
    semaphore := make(chan struct{}, workers)
    
    for i, item := range items {
        wg.Add(1)
        go func(index int, data T) {
            defer wg.Done()
            
            semaphore <- struct{}{}
            defer func() { <-semaphore }()
            
            results[index] = fn(data)
        }(i, item)
    }
    
    wg.Wait()
    return results
}

// Usage
results := ParallelMap(items, processItem, 10)
```

#### Type-Safe Getters

Flyt provides built-in type-safe getters:

```go
// Built-in type-safe getters
userID := shared.GetInt("user_id")           // Returns 0 if not found
name := shared.GetString("name")              // Returns "" if not found
enabled := shared.GetBool("enabled")          // Returns false if not found

// With custom defaults
userID = shared.GetIntOr("user_id", -1)
name = shared.GetStringOr("name", "anonymous")
enabled = shared.GetBoolOr("enabled", true)

// For complex types, use Bind
var config Config
err := shared.Bind("config", &config)
```

#### Chunk Slice

```go
func ChunkSlice[T any](slice []T, chunkSize int) [][]T {
    var chunks [][]T
    
    for i := 0; i < len(slice); i += chunkSize {
        end := i + chunkSize
        if end > len(slice) {
            end = len(slice)
        }
        chunks = append(chunks, slice[i:end])
    }
    
    return chunks
}

// Usage in batch processing
chunks := ChunkSlice(items, 100)
for _, chunk := range chunks {
    processChunk(chunk)
}
```

#### Merge Maps

```go
func MergeMaps(maps ...map[string]any) map[string]any {
    result := make(map[string]any)
    
    for _, m := range maps {
        for k, v := range m {
            result[k] = v
        }
    }
    
    return result
}

// Usage
config := MergeMaps(defaultConfig, userConfig, overrides)
```

#### Filter Slice

```go
func FilterSlice[T any](slice []T, predicate func(T) bool) []T {
    result := make([]T, 0)
    
    for _, item := range slice {
        if predicate(item) {
            result = append(result, item)
        }
    }
    
    return result
}

// Usage
validItems := FilterSlice(items, func(item Item) bool {
    return item.IsValid()
})
```

#### Timeout Wrapper

```go
func WithTimeout[T any](ctx context.Context, timeout time.Duration, fn func(context.Context) (T, error)) (T, error) {
    ctx, cancel := context.WithTimeout(ctx, timeout)
    defer cancel()
    
    type result struct {
        value T
        err   error
    }
    
    done := make(chan result, 1)
    
    go func() {
        value, err := fn(ctx)
        done <- result{value, err}
    }()
    
    select {
    case res := <-done:
        return res.value, res.err
    case <-ctx.Done():
        var zero T
        return zero, ctx.Err()
    }
}

// Usage
result, err := WithTimeout(ctx, 5*time.Second, func(ctx context.Context) (string, error) {
    return fetchData(ctx)
})
```

#### Pipeline Builder

```go
type Pipeline[T any] struct {
    stages []func(T) T
}

func NewPipeline[T any]() *Pipeline[T] {
    return &Pipeline[T]{
        stages: make([]func(T) T, 0),
    }
}

func (p *Pipeline[T]) Add(stage func(T) T) *Pipeline[T] {
    p.stages = append(p.stages, stage)
    return p
}

func (p *Pipeline[T]) Execute(input T) T {
    result := input
    for _, stage := range p.stages {
        result = stage(result)
    }
    return result
}

// Usage
pipeline := NewPipeline[string]().
    Add(strings.TrimSpace).
    Add(strings.ToLower).
    Add(func(s string) string {
        return strings.ReplaceAll(s, " ", "_")
    })

result := pipeline.Execute("  Hello World  ")
// Result: "hello_world"
```

#### Error Aggregator

```go
type ErrorAggregator struct {
    errors []error
    mu     sync.Mutex
}

func (e *ErrorAggregator) Add(err error) {
    if err == nil {
        return
    }
    
    e.mu.Lock()
    e.errors = append(e.errors, err)
    e.mu.Unlock()
}

func (e *ErrorAggregator) Error() error {
    e.mu.Lock()
    defer e.mu.Unlock()
    
    if len(e.errors) == 0 {
        return nil
    }
    
    if len(e.errors) == 1 {
        return e.errors[0]
    }
    
    return fmt.Errorf("multiple errors (%d): %v", len(e.errors), e.errors)
}

// Usage
aggregator := &ErrorAggregator{}

for _, item := range items {
    if err := processItem(item); err != nil {
        aggregator.Add(err)
    }
}

if err := aggregator.Error(); err != nil {
    return nil, err
}
```

#### Context Values Helper

```go
type ContextKey string

const (
    RequestIDKey ContextKey = "request_id"
    UserIDKey    ContextKey = "user_id"
)

func WithRequestID(ctx context.Context, requestID string) context.Context {
    return context.WithValue(ctx, RequestIDKey, requestID)
}

func GetRequestID(ctx context.Context) (string, bool) {
    id, ok := ctx.Value(RequestIDKey).(string)
    return id, ok
}

// Usage in nodes
func (n *LoggingNode) Exec(ctx context.Context, prepResult any) (any, error) {
    requestID, _ := GetRequestID(ctx)
    log.Printf("[%s] Processing: %v", requestID, prepResult)
    
    return process(prepResult)
}
```

#### Debounce Function

```go
func Debounce(fn func(), delay time.Duration) func() {
    var timer *time.Timer
    var mu sync.Mutex
    
    return func() {
        mu.Lock()
        defer mu.Unlock()
        
        if timer != nil {
            timer.Stop()
        }
        
        timer = time.AfterFunc(delay, fn)
    }
}

// Usage
saveDebounced := Debounce(func() {
    saveToDatabase()
}, 5*time.Second)

// Call multiple times, only last one executes
saveDebounced()
saveDebounced()
saveDebounced()
```

### Testing Utilities

#### Mock SharedStore

```go
type MockSharedStore struct {
    data map[string]any
    mu   sync.RWMutex
}

func NewMockSharedStore(initial map[string]any) *MockSharedStore {
    return &MockSharedStore{
        data: initial,
    }
}

func (m *MockSharedStore) Get(key string) (any, bool) {
    m.mu.RLock()
    defer m.mu.RUnlock()
    val, ok := m.data[key]
    return val, ok
}

func (m *MockSharedStore) Set(key string, value any) {
    m.mu.Lock()
    defer m.mu.Unlock()
    m.data[key] = value
}
```

#### Test Node Builder

```go
func TestNode(execFn func(context.Context, any) (any, error)) flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(execFn),
    )
}

// Usage in tests
node := TestNode(func(ctx context.Context, input any) (any, error) {
    return "test_result", nil
})
```

### Best Practices

1. **Keep Utilities Generic**: Make them reusable across projects
2. **Document Usage**: Provide clear examples
3. **Test Thoroughly**: Utilities should be well-tested
4. **Handle Edge Cases**: Consider nil values and empty inputs
5. **Use Type Parameters**: Leverage Go generics where appropriate
6. **Thread Safety**: Ensure utilities are safe for concurrent use

### Next Steps

* [Custom Nodes](/advanced/custom-nodes) - Build sophisticated nodes
* [Best Practices](/best-practices) - General guidelines
* [Examples](https://github.com/mark3labs/flyt/tree/main/cookbook) - See utilities in action


## Worker Pool

Manage concurrent task execution with fine-grained control using the WorkerPool utility.

### Basic Worker Pool

Create and use a worker pool:

```go
// Create a pool with 10 workers
pool := flyt.NewWorkerPool(10)

// Submit tasks
for i := 0; i < 100; i++ {
    taskID := i
    pool.Submit(func() {
        // Process task
        result := processTask(taskID)
        fmt.Printf("Task %d completed: %v\n", taskID, result)
    })
}

// Wait for all tasks to complete
pool.Wait()

// Clean up
pool.Close()
```

### Worker Pool with Results

Collect results from worker pool:

```go
type ResultCollector struct {
    mu      sync.Mutex
    results []Result
}

func processWithWorkerPool(items []Item) []Result {
    pool := flyt.NewWorkerPool(5)
    collector := &ResultCollector{
        results: make([]Result, len(items)),
    }
    
    for i, item := range items {
        index := i
        data := item
        
        pool.Submit(func() {
            result := processItem(data)
            
            collector.mu.Lock()
            collector.results[index] = result
            collector.mu.Unlock()
        })
    }
    
    pool.Wait()
    pool.Close()
    
    return collector.results
}
```

### Dynamic Worker Scaling

Adjust worker count based on load:

```go
type DynamicWorkerPool struct {
    minWorkers int
    maxWorkers int
    pool       *flyt.WorkerPool
    load       int32
    mu         sync.RWMutex
}

func NewDynamicWorkerPool(min, max int) *DynamicWorkerPool {
    return &DynamicWorkerPool{
        minWorkers: min,
        maxWorkers: max,
        pool:       flyt.NewWorkerPool(min),
    }
}

func (p *DynamicWorkerPool) Submit(task func()) {
    currentLoad := atomic.AddInt32(&p.load, 1)
    
    // Scale up if needed
    if currentLoad > int32(p.getCurrentWorkers()*2) {
        p.scaleUp()
    }
    
    p.pool.Submit(func() {
        task()
        
        newLoad := atomic.AddInt32(&p.load, -1)
        
        // Scale down if idle
        if newLoad < int32(p.getCurrentWorkers()/2) {
            p.scaleDown()
        }
    })
}

func (p *DynamicWorkerPool) scaleUp() {
    p.mu.Lock()
    defer p.mu.Unlock()
    
    current := p.getCurrentWorkers()
    if current < p.maxWorkers {
        // Create new pool with more workers
        newPool := flyt.NewWorkerPool(min(current*2, p.maxWorkers))
        p.pool.Close()
        p.pool = newPool
    }
}
```

### Rate-Limited Worker Pool

Control processing rate:

```go
func createRateLimitedPool(workers int, rps int) *RateLimitedPool {
    limiter := rate.NewLimiter(rate.Limit(rps), 1)
    pool := flyt.NewWorkerPool(workers)
    
    return &RateLimitedPool{
        pool:    pool,
        limiter: limiter,
    }
}

type RateLimitedPool struct {
    pool    *flyt.WorkerPool
    limiter *rate.Limiter
}

func (p *RateLimitedPool) Submit(ctx context.Context, task func()) error {
    // Wait for rate limit
    if err := p.limiter.Wait(ctx); err != nil {
        return err
    }
    
    p.pool.Submit(task)
    return nil
}
```

### Priority Queue Worker Pool

Process tasks by priority:

```go
type PriorityTask struct {
    Priority int
    Task     func()
    ID       string
}

type PriorityWorkerPool struct {
    workers int
    queue   *PriorityQueue
    pool    *flyt.WorkerPool
    running bool
    mu      sync.Mutex
}

func NewPriorityWorkerPool(workers int) *PriorityWorkerPool {
    p := &PriorityWorkerPool{
        workers: workers,
        queue:   NewPriorityQueue(),
        pool:    flyt.NewWorkerPool(workers),
        running: true,
    }
    
    // Start dispatcher
    go p.dispatch()
    
    return p
}

func (p *PriorityWorkerPool) Submit(priority int, task func()) {
    p.queue.Push(PriorityTask{
        Priority: priority,
        Task:     task,
        ID:       generateID(),
    })
}

func (p *PriorityWorkerPool) dispatch() {
    for p.running {
        task := p.queue.Pop() // Blocks until task available
        if task != nil {
            p.pool.Submit(task.Task)
        }
    }
}
```

### Worker Pool with Timeout

Handle task timeouts:

```go
func createTimeoutPool(workers int, timeout time.Duration) *TimeoutPool {
    return &TimeoutPool{
        pool:    flyt.NewWorkerPool(workers),
        timeout: timeout,
    }
}

type TimeoutPool struct {
    pool    *flyt.WorkerPool
    timeout time.Duration
}

func (p *TimeoutPool) Submit(task func() error) error {
    errChan := make(chan error, 1)
    
    p.pool.Submit(func() {
        done := make(chan error, 1)
        
        go func() {
            done <- task()
        }()
        
        select {
        case err := <-done:
            errChan <- err
        case <-time.After(p.timeout):
            errChan <- fmt.Errorf("task timeout after %v", p.timeout)
        }
    })
    
    return <-errChan
}
```

### Worker Pool in Nodes

Use worker pools within nodes:

```go
type ParallelProcessingNode struct {
    *flyt.BaseNode
    pool *flyt.WorkerPool
}

func NewParallelProcessingNode(workers int) *ParallelProcessingNode {
    return &ParallelProcessingNode{
        BaseNode: flyt.NewBaseNode(),
        pool:     flyt.NewWorkerPool(workers),
    }
}

func (n *ParallelProcessingNode) Exec(ctx context.Context, prepResult any) (any, error) {
    items := prepResult.([]Item)
    results := make([]Result, len(items))
    errors := make([]error, len(items))
    
    var wg sync.WaitGroup
    
    for i, item := range items {
        wg.Add(1)
        index := i
        data := item
        
        n.pool.Submit(func() {
            defer wg.Done()
            
            result, err := processItem(data)
            results[index] = result
            errors[index] = err
        })
    }
    
    // Wait with context
    done := make(chan struct{})
    go func() {
        wg.Wait()
        close(done)
    }()
    
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    case <-done:
        // Check for errors
        for _, err := range errors {
            if err != nil {
                return results, fmt.Errorf("processing failed: %w", err)
            }
        }
        return results, nil
    }
}

func (n *ParallelProcessingNode) Close() {
    n.pool.Close()
}
```

### Batch Processing with Worker Pool

Process batches efficiently:

```go
func processBatchesWithPool(items []Item, batchSize int, workers int) []Result {
    pool := flyt.NewWorkerPool(workers)
    results := make([]Result, len(items))
    
    // Process in batches
    for i := 0; i < len(items); i += batchSize {
        end := min(i+batchSize, len(items))
        batch := items[i:end]
        batchStart := i
        
        pool.Submit(func() {
            batchResults := processBatch(batch)
            
            // Store results
            for j, result := range batchResults {
                results[batchStart+j] = result
            }
        })
    }
    
    pool.Wait()
    pool.Close()
    
    return results
}
```

### Monitoring Worker Pool

Track pool performance:

```go
type MonitoredPool struct {
    pool      *flyt.WorkerPool
    submitted int64
    completed int64
    failed    int64
    totalTime int64
}

func (p *MonitoredPool) Submit(task func() error) {
    atomic.AddInt64(&p.submitted, 1)
    
    p.pool.Submit(func() {
        start := time.Now()
        
        err := task()
        
        duration := time.Since(start)
        atomic.AddInt64(&p.totalTime, int64(duration))
        
        if err != nil {
            atomic.AddInt64(&p.failed, 1)
        } else {
            atomic.AddInt64(&p.completed, 1)
        }
    })
}

func (p *MonitoredPool) GetStats() map[string]int64 {
    return map[string]int64{
        "submitted":     atomic.LoadInt64(&p.submitted),
        "completed":     atomic.LoadInt64(&p.completed),
        "failed":        atomic.LoadInt64(&p.failed),
        "avg_time_ms":   p.getAverageTime(),
        "pending":       p.getPendingCount(),
    }
}
```

### Circuit Breaker Pool

Prevent overload with circuit breaker:

```go
type CircuitBreakerPool struct {
    pool        *flyt.WorkerPool
    failures    int32
    threshold   int32
    resetTime   time.Duration
    lastFailure time.Time
    mu          sync.RWMutex
}

func (p *CircuitBreakerPool) Submit(task func() error) error {
    if p.isOpen() {
        return fmt.Errorf("circuit breaker open")
    }
    
    p.pool.Submit(func() {
        err := task()
        
        if err != nil {
            failures := atomic.AddInt32(&p.failures, 1)
            
            if failures >= p.threshold {
                p.mu.Lock()
                p.lastFailure = time.Now()
                p.mu.Unlock()
            }
        } else {
            // Reset on success
            atomic.StoreInt32(&p.failures, 0)
        }
    })
    
    return nil
}

func (p *CircuitBreakerPool) isOpen() bool {
    p.mu.RLock()
    defer p.mu.RUnlock()
    
    if atomic.LoadInt32(&p.failures) >= p.threshold {
        if time.Since(p.lastFailure) < p.resetTime {
            return true
        }
        // Reset after timeout
        atomic.StoreInt32(&p.failures, 0)
    }
    
    return false
}
```

### Best Practices

1. **Size Appropriately**: Set worker count based on workload and resources
2. **Handle Panics**: Recover from panics in worker goroutines
3. **Clean Up**: Always close pools when done
4. **Monitor Performance**: Track metrics for optimization
5. **Avoid Blocking**: Don't block workers with long waits
6. **Test Concurrency**: Test with various worker counts and loads

### Next Steps

* [Batch Processing](/advanced/batch-processing) - High-level batch operations
* [Custom Nodes](/advanced/custom-nodes) - Build nodes with worker pools
* [Best Practices](/best-practices) - General guidelines


## Actions

Actions are strings returned by a node's Post phase that determine the next step in a workflow. They provide dynamic, runtime control over flow execution.

### How Actions Work

When a node completes, its Post phase returns an action:

```go
func (n *MyNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if success {
        return "continue", nil
    }
    return "retry", nil
}
```

The flow then routes to the node connected with that action:

```go
flow := flyt.NewFlow(startNode)
flow.Connect(startNode, "continue", processNode)
flow.Connect(startNode, "retry", retryNode)
```

### Default Action

The most common action is `flyt.DefaultAction`:

```go
// Using the constant
return flyt.DefaultAction, nil  // Returns "default"

// In flow connections
flow.Connect(node1, flyt.DefaultAction, node2)
```

### Action-Based Routing

#### Simple Branching

```go
validationNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        data := prepResult.(string)
        return len(data) > 0, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        if execResult.(bool) {
            return "valid", nil
        }
        return "invalid", nil
    }),
)

flow := flyt.NewFlow(validationNode)
flow.Connect(validationNode, "valid", processNode)
flow.Connect(validationNode, "invalid", errorNode)
```

#### Multi-Way Branching

```go
categoryNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        value := prepResult.(int)
        if value < 10 {
            return "small", nil
        } else if value < 100 {
            return "medium", nil
        }
        return "large", nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        return flyt.Action(execResult.(string)), nil
    }),
)

flow := flyt.NewFlow(categoryNode)
flow.Connect(categoryNode, "small", smallHandler)
flow.Connect(categoryNode, "medium", mediumHandler)
flow.Connect(categoryNode, "large", largeHandler)
```

### Flow Termination

If no connection exists for an action, the flow terminates:

```go
flow := flyt.NewFlow(node1)
flow.Connect(node1, "continue", node2)
// If node1 returns "stop", flow ends (no connection for "stop")
```

Explicitly terminate by connecting to nil:

```go
flow.Connect(finalNode, "done", nil)
```

### Common Patterns

#### Success/Failure Pattern

```go
func makeDecisionPost(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if err := execResult.(error); err != nil {
        return "failure", nil
    }
    return "success", nil
}
```

#### Retry Pattern

```go
func retryablePost(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    count := shared.GetInt("attempts")
    
    if execResult == nil && count < 3 {
        shared.Set("attempts", count + 1)
        return "retry", nil
    }
    return "continue", nil
}
```

#### State Machine Pattern

```go
func statePost(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    currentState := shared.GetString("state")
    
    switch currentState {
    case "init":
        shared.Set("state", "processing")
        return "process", nil
    case "processing":
        shared.Set("state", "complete")
        return "finalize", nil
    default:
        return "done", nil
    }
}
```

### Dynamic Actions

Actions can be computed at runtime:

```go
func dynamicPost(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    result := execResult.(map[string]any)
    nextAction := result["next_action"].(string)
    return flyt.Action(nextAction), nil
}
```

### Best Practices

1. **Use Descriptive Names**: Actions should clearly indicate their purpose
2. **Document Actions**: List all possible actions a node can return
3. **Handle All Cases**: Ensure all possible actions have connections or intentionally terminate
4. **Consistent Naming**: Use a consistent naming scheme across your application
5. **Avoid Magic Strings**: Define action constants for reusability

```go
const (
    ActionValidate = flyt.Action("validate")
    ActionProcess  = flyt.Action("process")
    ActionComplete = flyt.Action("complete")
    ActionError    = flyt.Action("error")
)
```

### Next Steps

* [Flows](/concepts/flows) - Connect nodes with actions
* [Conditional Branching](/patterns/branching) - Advanced routing patterns
* [Nested Flows](/advanced/nested-flows) - Compose complex workflows


## Flows

Flows connect nodes together to create workflows. They define the execution path based on actions returned by nodes.

### Creating Flows

Start with a single node and build connections:

```go
// Create nodes
startNode := createStartNode()
processNode := createProcessNode()
endNode := createEndNode()

// Build flow
flow := flyt.NewFlow(startNode)
flow.Connect(startNode, flyt.DefaultAction, processNode)
flow.Connect(processNode, flyt.DefaultAction, endNode)
```

### Running Flows

Execute a flow with a context and SharedStore:

```go
ctx := context.Background()
shared := flyt.NewSharedStore()

// Add initial data
shared.Set("input", "data to process")

// Run the flow
err := flow.Run(ctx, shared)
if err != nil {
    log.Fatal(err)
}

// Get results
result := shared.GetString("output")
```

### Flow Connections

#### Linear Flow

Simple sequential execution:

```go
flow := flyt.NewFlow(node1)
flow.Connect(node1, flyt.DefaultAction, node2)
flow.Connect(node2, flyt.DefaultAction, node3)
flow.Connect(node3, flyt.DefaultAction, nil) // Terminate
```

#### Branching Flow

Multiple paths based on actions:

```go
flow := flyt.NewFlow(decisionNode)
flow.Connect(decisionNode, "path_a", nodeA)
flow.Connect(decisionNode, "path_b", nodeB)
flow.Connect(nodeA, flyt.DefaultAction, mergeNode)
flow.Connect(nodeB, flyt.DefaultAction, mergeNode)
```

#### Loop Flow

Create cycles for retry or iteration:

```go
flow := flyt.NewFlow(startNode)
flow.Connect(startNode, flyt.DefaultAction, processNode)
flow.Connect(processNode, "retry", startNode)    // Loop back
flow.Connect(processNode, "success", endNode)
```

### Flow as Node

Flows implement the Node interface and can be used as nodes:

```go
// Create a sub-flow
subFlow := flyt.NewFlow(validateNode)
subFlow.Connect(validateNode, flyt.DefaultAction, transformNode)

// Use sub-flow in main flow
mainFlow := flyt.NewFlow(fetchNode)
mainFlow.Connect(fetchNode, flyt.DefaultAction, subFlow)
mainFlow.Connect(subFlow, flyt.DefaultAction, saveNode)
```

### Complex Flow Patterns

#### Diamond Pattern

Split and merge execution paths:

```go
flow := flyt.NewFlow(splitNode)
flow.Connect(splitNode, "path1", process1)
flow.Connect(splitNode, "path2", process2)
flow.Connect(process1, flyt.DefaultAction, mergeNode)
flow.Connect(process2, flyt.DefaultAction, mergeNode)
```

#### Error Handling Flow

Centralized error handling:

```go
flow := flyt.NewFlow(startNode)
flow.Connect(startNode, "error", errorHandler)
flow.Connect(startNode, flyt.DefaultAction, processNode)
flow.Connect(processNode, "error", errorHandler)
flow.Connect(processNode, flyt.DefaultAction, saveNode)
flow.Connect(saveNode, "error", errorHandler)
```

#### Pipeline Pattern

Data transformation pipeline:

```go
flow := flyt.NewFlow(fetchNode)
flow.Connect(fetchNode, flyt.DefaultAction, validateNode)
flow.Connect(validateNode, "valid", transformNode)
flow.Connect(validateNode, "invalid", rejectNode)
flow.Connect(transformNode, flyt.DefaultAction, enrichNode)
flow.Connect(enrichNode, flyt.DefaultAction, saveNode)
```

### Flow Composition

Build complex flows from simpler ones:

```go
func createValidationFlow() *flyt.Flow {
    checkFormat := createFormatChecker()
    checkBusiness := createBusinessRules()
    
    flow := flyt.NewFlow(checkFormat)
    flow.Connect(checkFormat, "valid", checkBusiness)
    return flow
}

func createMainFlow() *flyt.Flow {
    fetch := createFetchNode()
    validation := createValidationFlow()
    process := createProcessNode()
    
    flow := flyt.NewFlow(fetch)
    flow.Connect(fetch, flyt.DefaultAction, validation)
    flow.Connect(validation, flyt.DefaultAction, process)
    return flow
}
```

### Debugging Flows

Add logging nodes for debugging:

```go
func createLoggingNode(name string) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            log.Printf("[%s] Prep: SharedStore keys: %v", name, shared.GetAll())
            return nil, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            log.Printf("[%s] Exec", name)
            return prepResult, nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            log.Printf("[%s] Post: Result: %v", name, execResult)
            return flyt.DefaultAction, nil
        }),
    )
}

// Insert between nodes for debugging
flow.Connect(node1, flyt.DefaultAction, createLoggingNode("debug"))
flow.Connect(createLoggingNode("debug"), flyt.DefaultAction, node2)
```

### Best Practices

1. **Start Simple**: Build flows incrementally, testing as you go
2. **Name Nodes**: Give nodes descriptive names for easier debugging
3. **Document Flows**: Create diagrams or comments explaining flow logic
4. **Reuse Flows**: Extract common patterns into reusable sub-flows
5. **Test Flows**: Write tests for different execution paths

### Visualizing Flows

Document your flows with clear structure:

```go
// Flow structure:
// Start -> Validate -> Process -> Save
//              └─> Error (on invalid)

flow := flyt.NewFlow(startNode)
flow.Connect(startNode, flyt.DefaultAction, validateNode)
flow.Connect(validateNode, "valid", processNode)
flow.Connect(validateNode, "invalid", errorNode)
flow.Connect(processNode, flyt.DefaultAction, saveNode)
```

### Next Steps

* [Shared Store](/concepts/shared-store) - Share data between nodes
* [Nested Flows](/advanced/nested-flows) - Advanced composition
* [Batch Flows](/advanced/batch-flows) - Process multiple inputs


## Nodes

Nodes are the fundamental building blocks of Flyt workflows. Each node represents a single unit of work with a well-defined lifecycle.

### Node Lifecycle

Every node has three phases that execute in order:

#### 1. Prep Phase

The preparation phase reads from the SharedStore and prepares data for execution.

```go
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    // Read data using type-safe getters
    userID := shared.GetInt("user_id")
    apiKey := shared.GetString("api_key")
    
    // Or bind complex types
    var config Config
    if err := shared.Bind("config", &config); err != nil {
        return nil, err
    }
    
    // Prepare and return data for Exec phase
    return map[string]any{
        "userID": userID,
        "apiKey": apiKey,
        "config": config,
    }, nil
}
```

#### 2. Exec Phase

The execution phase performs the main work. This phase can be retried on failure.

```go
func (n *MyNode) Exec(ctx context.Context, prepResult any) (any, error) {
    data := prepResult.(map[string]any)
    
    // Perform the main operation
    result, err := processData(data["input"])
    if err != nil {
        return nil, err // Will trigger retry if configured
    }
    
    return result, nil
}
```

#### 3. Post Phase

The post-processing phase handles results and determines the next action.

```go
func (n *MyNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    // Store results
    shared.Set("output", execResult)
    
    // Determine next action based on results
    if isValid(execResult) {
        return "success", nil
    }
    return "failure", nil
}
```

### Creating Nodes

#### Using Helper Functions

The simplest way to create a node:

```go
node := flyt.NewNode(
    flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
        // Use type-safe getters
        message := shared.GetString("message")
        retryCount := shared.GetIntOr("retry_count", 0)
        
        return map[string]any{
            "message": message,
            "retry": retryCount,
        }, nil
    }),
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        data := prepResult.(map[string]any)
        // Process the data
        return processMessage(data["message"].(string)), nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        // Store result and determine action
        shared.Set("result", execResult)
        
        if shared.GetInt("retry_count") > 3 {
            return "max_retries", nil
        }
        return flyt.DefaultAction, nil
    }),
)
```

#### Custom Node Types

For complex nodes with state:

```go
type DatabaseNode struct {
    *flyt.BaseNode
    db *sql.DB
}

func NewDatabaseNode(db *sql.DB) *DatabaseNode {
    return &DatabaseNode{
        BaseNode: flyt.NewBaseNode(),
        db: db,
    }
}

func (n *DatabaseNode) Exec(ctx context.Context, prepResult any) (any, error) {
    query := prepResult.(string)
    rows, err := n.db.QueryContext(ctx, query)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    // Process rows...
    return results, nil
}
```

### Node Options

Configure node behavior with options:

```go
node := flyt.NewNode(
    flyt.WithExecFunc(execFunc),
    flyt.WithMaxRetries(3),        // Retry up to 3 times
    flyt.WithWait(time.Second * 2), // Wait 2 seconds between retries
)
```

### BaseNode

The `BaseNode` provides default implementations:

```go
type MyNode struct {
    *flyt.BaseNode
    // Add custom fields
}

func NewMyNode() *MyNode {
    return &MyNode{
        BaseNode: flyt.NewBaseNode(
            flyt.WithMaxRetries(5),
            flyt.WithWait(time.Second),
        ),
    }
}

// Override only the methods you need
func (n *MyNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Custom exec logic
    return result, nil
}
```

### Thread Safety

Nodes should be thread-safe if used in concurrent batch operations:

```go
type SafeNode struct {
    *flyt.BaseNode
    mu      sync.Mutex
    counter int
}

func (n *SafeNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.mu.Lock()
    n.counter++
    count := n.counter
    n.mu.Unlock()
    
    return fmt.Sprintf("Execution #%d", count), nil
}
```

### Best Practices

1. **Single Responsibility**: Each node should do one thing well
2. **Idempotency**: Design nodes to be safely retryable
3. **Context Handling**: Always respect context cancellation
4. **Error Handling**: Return clear, actionable errors
5. **Resource Management**: Clean up resources in defer blocks

### Next Steps

* [Actions](/concepts/actions) - Control flow with actions
* [Flows](/concepts/flows) - Connect nodes into workflows
* [Custom Node Types](/advanced/custom-nodes) - Advanced node patterns


## Shared Store

The SharedStore provides thread-safe data sharing between nodes in a flow. It acts as a key-value store that persists throughout flow execution with type-safe helpers for common operations.

### Creating a SharedStore

```go
shared := flyt.NewSharedStore()
```

### Basic Operations

#### Set and Get

Store and retrieve individual values with the original API:

```go
// Set a value
shared.Set("user_id", 123)
shared.Set("config", map[string]any{"timeout": 30})

// Type-safe getter (recommended)
userID := shared.GetInt("user_id")
fmt.Printf("User ID: %d\n", userID)
```

#### Type-Safe Getters

Use type-specific getters to avoid manual type assertions:

```go
// Type-safe getters (return zero values if not found or wrong type)
userID := shared.GetInt("user_id")           // Returns 0 if not found
name := shared.GetString("name")              // Returns "" if not found
price := shared.GetFloat64("price")           // Returns 0.0 if not found
enabled := shared.GetBool("enabled")          // Returns false if not found
items := shared.GetSlice("items")             // Returns nil if not found
config := shared.GetMap("config")             // Returns nil if not found

// Type-safe getters with custom defaults
userID = shared.GetIntOr("user_id", -1)              // Returns -1 if not found
name = shared.GetStringOr("name", "anonymous")       // Returns "anonymous" if not found
price = shared.GetFloat64Or("price", 99.99)          // Returns 99.99 if not found
enabled = shared.GetBoolOr("enabled", true)          // Returns true if not found
```

The type-safe getters handle numeric conversions automatically:

* `GetInt()` converts from int8, int16, int32, int64, uint variants, and float types
* `GetFloat64()` converts from all numeric types including int and float32

#### Bind Method

Bind complex types directly to structs (similar to Echo framework):

```go
// Define your struct
type User struct {
    ID       int      `json:"id"`
    Name     string   `json:"name"`
    Email    string   `json:"email"`
    Tags     []string `json:"tags"`
}

// Store as map
shared.Set("user", map[string]any{
    "id":    123,
    "name":  "Alice",
    "email": "alice@example.com",
    "tags":  []string{"admin", "developer"},
})

// Bind to struct
var user User
err := shared.Bind("user", &user)  // Automatically converts map to struct
if err != nil {
    // Handle error
}

// Or use MustBind (panics on failure - use for required data)
var config Config
shared.MustBind("config", &config)
```

#### Utility Methods

Additional helper methods for store management:

```go
// Check if key exists
if shared.Has("user_id") {
    // Key exists
}

// Delete a key
shared.Delete("temp_data")

// Get all keys
keys := shared.Keys()  // Returns []string

// Get number of items
count := shared.Len()

// Clear all items
shared.Clear()
```

#### GetAll

Get a copy of all stored data:

```go
allData := shared.GetAll()
for key, value := range allData {
    fmt.Printf("%s: %v\n", key, value)
}
```

#### Merge

Merge multiple values at once:

```go
shared.Merge(map[string]any{
    "status": "active",
    "timestamp": time.Now(),
    "metadata": map[string]string{
        "version": "1.0",
        "env": "production",
    },
})
```

### Thread Safety

SharedStore is safe for concurrent access:

```go
var wg sync.WaitGroup

// Multiple goroutines can safely access
for i := 0; i < 10; i++ {
    wg.Add(1)
    go func(id int) {
        defer wg.Done()
        shared.Set(fmt.Sprintf("worker_%d", id), "done")
    }(i)
}

wg.Wait()
```

### Common Patterns

#### Configuration Storage

Store configuration that multiple nodes need:

```go
// Define configuration struct
type APIConfig struct {
    BaseURL string `json:"base_url"`
    APIKey  string `json:"api_key"`
    Timeout string `json:"timeout"`
}

// In main or initial node
shared.Set("api_config", APIConfig{
    BaseURL: "https://api.example.com",
    APIKey:  os.Getenv("API_KEY"),
    Timeout: "30s",
})

// In any node - using Bind
func (n *APINode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    var config APIConfig
    if err := shared.Bind("api_config", &config); err != nil {
        return nil, err
    }
    return config, nil
}

// Or using GetMap for simple access
func (n *APINode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    config := shared.GetMap("api_config")
    return config, nil
}
```

#### Accumulating Results

Collect results from multiple nodes:

```go
// Node 1 - Using type-safe getters
func (n *Node1) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    // GetSlice returns nil if not found, perfect for initialization
    results := shared.GetSlice("results")
    if results == nil {
        results = []any{}
    }
    
    results = append(results, execResult)
    shared.Set("results", results)
    
    return flyt.DefaultAction, nil
}
```

#### State Management

Track workflow state with type safety:

```go
// Initialize state
shared.Set("workflow_state", "initialized")
shared.Set("retry_count", 0)
shared.Set("start_time", time.Now())

// Update state in nodes with increment
func incrementRetry(shared *flyt.SharedStore) int {
    count := shared.GetInt("retry_count")
    count++
    shared.Set("retry_count", count)
    shared.Set("last_retry", time.Now())
    return count
}

// Check state
func checkState(shared *flyt.SharedStore) string {
    return shared.GetStringOr("workflow_state", "unknown")
}
```

#### Error Context

Store error information for debugging:

```go
func (n *ErrorHandler) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if err := execResult.(error); err != nil {
        shared.Set("last_error", map[string]any{
            "error": err.Error(),
            "node": "ProcessNode",
            "timestamp": time.Now(),
            "input": prepResult,
        })
        return "error", nil
    }
    return flyt.DefaultAction, nil
}
```

### Batch Processing

SharedStore in batch operations:

```go
// Store items to process
shared.Set("items", []string{"item1", "item2", "item3"})

// Store batch configuration
shared.Set("batch_config", map[string]any{
    "batch_size": 10,
    "concurrent": true,
    "timeout": 60,
})

// After batch processing
results := shared.GetSlice("results")
errors := shared.GetSlice("errors")
```

### Isolation in Batch Flows

Each flow in a batch has its own SharedStore:

```go
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    // This shared is from the parent
    baseConfig := shared.GetMap("base_config")
    
    return []flyt.FlowInputs{
        {"id": 1, "config": baseConfig}, // Each gets own SharedStore
        {"id": 2, "config": baseConfig},
    }, nil
}
```

### Best Practices

#### 1. Type Safety

Use type-safe getters to avoid manual assertions:

```go
// Type-safe getter (recommended)
count := shared.GetInt("count")  // Returns 0 if not found or wrong type

// Or with custom default
count := shared.GetIntOr("count", -1)  // Returns -1 if not found

// For complex types, use Bind
var userData UserData
if err := shared.Bind("user_data", &userData); err != nil {
    // Handle error
}
```

#### 2. Key Naming

Use consistent, descriptive keys:

```go
const (
    KeyUserID     = "user_id"
    KeyAuthToken  = "auth_token"
    KeyResults    = "processing_results"
    KeyErrorCount = "error_count"
)
```

#### 3. Data Structure

Store structured data for clarity:

```go
type WorkflowContext struct {
    RequestID string
    UserID    int
    StartTime time.Time
    Metadata  map[string]string
}

shared.Set("context", WorkflowContext{
    RequestID: "req-123",
    UserID:    456,
    StartTime: time.Now(),
    Metadata:  map[string]string{"source": "api"},
})
```

#### 4. Cleanup

Clear sensitive data when done:

```go
defer func() {
    // Clear sensitive data
    shared.Set("auth_token", nil)
    shared.Set("api_key", nil)
}()
```

#### 5. Documentation

Document expected keys:

```go
// SharedStore keys used by this flow:
// - "input_file": string - Path to input file
// - "output_dir": string - Output directory path
// - "processed_count": int - Number of processed items
// - "errors": []error - Collection of errors
```

### Debugging

Use GetAll for debugging:

```go
func debugSharedStore(shared *flyt.SharedStore) {
    data := shared.GetAll()
    fmt.Println("=== SharedStore Contents ===")
    for k, v := range data {
        fmt.Printf("%s: %T = %v\n", k, v, v)
    }
    fmt.Println("===========================")
}
```

### Next Steps

* [Nodes](/concepts/nodes) - Use SharedStore in node lifecycle
* [Batch Processing](/advanced/batch-processing) - SharedStore in batch operations
* [Best Practices](/best-practices) - General Flyt best practices


## Installation

Flyt requires Go 1.21 or later.

### Install with go get

```bash
go get github.com/mark3labs/flyt
```

### Import in your code

```go
import "github.com/mark3labs/flyt"
```

### Verify installation

Create a simple test file to verify the installation:

```go
package main

import (
    "fmt"
    "github.com/mark3labs/flyt"
)

func main() {
    shared := flyt.NewSharedStore()
    shared.Set("test", "success")
    
    val := shared.GetString("test")
    fmt.Printf("Flyt installed successfully! Value: %s\n", val)
}
```

Run it:

```bash
go run main.go
```

You should see:

```
Flyt installed successfully! Value: success
```

### Next Steps

* [Quick Start Guide](/getting-started/quick-start) - Build your first workflow
* [Project Template](/getting-started/template) - Start with a pre-configured project
* [Core Concepts](/concepts/nodes) - Understand the fundamentals


## Quick Start

This guide will help you build your first Flyt workflow in 5 minutes.

### Your First Node

Let's start with a simple node that processes data:

```go
package main

import (
    "context"
    "fmt"
    "github.com/mark3labs/flyt"
)

func main() {
    // Create a node with just an Exec function
    node := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            fmt.Println("Processing data...")
            return "Hello, Flyt!", nil
        }),
    )

    // Create shared store and context
    shared := flyt.NewSharedStore()
    ctx := context.Background()

    // Run the node
    action, err := flyt.Run(ctx, node, shared)
    if err != nil {
        panic(err)
    }
    
    fmt.Printf("Completed with action: %s\n", action)
}
```

### Building a Flow

Now let's create a simple workflow with multiple nodes:

```go
package main

import (
    "context"
    "fmt"
    "github.com/mark3labs/flyt"
)

func main() {
    // Create nodes
    fetchNode := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            fmt.Println("Fetching data...")
            return map[string]string{"data": "important info"}, nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            shared.Set("fetched_data", execResult)
            return flyt.DefaultAction, nil
        }),
    )

    processNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Use GetMap for type-safe access
            data := shared.GetMap("fetched_data")
            return data, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            data := prepResult.(map[string]any)
            fmt.Printf("Processing: %v\n", data["data"])
            return "processed: " + fmt.Sprint(data["data"]), nil
        }),
    )

    // Build the flow
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, processNode)

    // Run the flow
    shared := flyt.NewSharedStore()
    ctx := context.Background()
    
    err := flow.Run(ctx, shared)
    if err != nil {
        panic(err)
    }
    
    fmt.Println("Flow completed successfully!")
}
```

### Adding Error Handling

Let's add retry logic and error handling:

```go
func createRobustNode() flyt.Node {
    attempts := 0
    
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            attempts++
            fmt.Printf("Attempt %d...\n", attempts)
            
            // Simulate flaky operation
            if attempts < 2 {
                return nil, fmt.Errorf("temporary failure")
            }
            
            return "Success!", nil
        }),
        flyt.WithMaxRetries(3),
        flyt.WithWait(time.Second),
    )
}
```

### Using Shared Store

The SharedStore allows nodes to communicate:

```go
func main() {
    shared := flyt.NewSharedStore()
    
    // Set initial data
    shared.Set("config", map[string]any{
        "timeout": 30,
        "retries": 3,
    })
    
    node := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            config := shared.GetMap("config")
            return config, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            config := prepResult.(map[string]any)
            fmt.Printf("Using config: %v\n", config)
            return "configured", nil
        }),
    )
    
    ctx := context.Background()
    flyt.Run(ctx, node, shared)
}
```

### Next Steps

Now that you've built your first workflow, explore:

* [Nodes](/concepts/nodes) - Deep dive into node lifecycle
* [Actions](/concepts/actions) - Control flow with actions
* [Error Handling](/patterns/error-handling) - Build resilient workflows
* [Examples](https://github.com/mark3labs/flyt/tree/main/cookbook) - Real-world use cases


## Project Template

The fastest way to start a new Flyt project is using the official template.

### Quick Setup

```bash
# Clone the template
git clone https://github.com/mark3labs/flyt-project-template my-flyt-project
cd my-flyt-project

# Remove template git history
rm -rf .git
git init

# Install dependencies
go mod tidy

# Run the example
go run main.go
```

### What's Included

The template provides:

#### Project Structure

```
my-flyt-project/
├── main.go           # Entry point with example workflow
├── nodes/            # Custom node implementations
│   ├── fetch.go      # Example fetch node
│   ├── process.go    # Example processing node
│   └── validate.go   # Example validation node
├── flows/            # Reusable flow definitions
│   └── example.go    # Example flow composition
├── go.mod            # Go module file
└── README.md         # Project documentation
```

#### Example Code

The template includes a working example that demonstrates:

* Creating custom nodes
* Building flows
* Using the SharedStore
* Error handling with retries
* Action-based routing

#### main.go

```go
package main

import (
    "context"
    "log"
    
    "github.com/mark3labs/flyt"
    "myproject/flows"
)

func main() {
    // Create shared store with initial data
    shared := flyt.NewSharedStore()
    shared.Set("api_key", "your-api-key")
    shared.Set("base_url", "https://api.example.com")
    
    // Create and run the example flow
    flow := flows.CreateExampleFlow()
    
    ctx := context.Background()
    if err := flow.Run(ctx, shared); err != nil {
        log.Fatal(err)
    }
    
    // Get results
    result := shared.GetString("final_result")
    if result != "" {
        log.Printf("Success! Result: %s\n", result)
    }
}
```

### Customizing the Template

#### Adding New Nodes

Create a new file in the `nodes/` directory:

```go
// nodes/custom.go
package nodes

import (
    "context"
    "github.com/mark3labs/flyt"
)

func CreateCustomNode() flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Your custom logic here
            return "custom result", nil
        }),
    )
}
```

#### Creating New Flows

Add flows to the `flows/` directory:

```go
// flows/custom.go
package flows

import (
    "github.com/mark3labs/flyt"
    "myproject/nodes"
)

func CreateCustomFlow() *flyt.Flow {
    // Create nodes
    startNode := nodes.CreateCustomNode()
    processNode := nodes.CreateProcessNode()
    
    // Build flow
    flow := flyt.NewFlow(startNode)
    flow.Connect(startNode, flyt.DefaultAction, processNode)
    
    return flow
}
```

### Best Practices

When using the template:

1. **Organize by Feature**: Group related nodes and flows together
2. **Use Configuration**: Store config in SharedStore or environment variables
3. **Add Tests**: Create `*_test.go` files for your nodes and flows
4. **Document Your Nodes**: Add comments explaining what each node does
5. **Version Control**: Initialize git and commit regularly

### Deployment

The template is ready for deployment:

```bash
# Build the binary
go build -o myapp

# Run in production
./myapp

# Or use Docker
docker build -t myapp .
docker run myapp
```

### Next Steps

* [Core Concepts](/concepts/nodes) - Understand Flyt fundamentals
* [Patterns](/patterns/closures) - Learn common patterns
* [Examples](https://github.com/mark3labs/flyt/tree/main/cookbook) - See real-world implementations


## Conditional Branching

Control flow execution dynamically based on runtime conditions using action-based routing.

### Simple Binary Branching

Make yes/no decisions:

```go
validationNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        data := prepResult.(string)
        isValid := len(data) > 0 && len(data) < 100
        return isValid, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        if execResult.(bool) {
            return "valid", nil
        }
        return "invalid", nil
    }),
)

flow := flyt.NewFlow(validationNode)
flow.Connect(validationNode, "valid", processNode)
flow.Connect(validationNode, "invalid", errorNode)
```

### Multi-Way Branching

Route to multiple paths:

```go
categoryNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        value := prepResult.(float64)
        
        switch {
        case value < 10:
            return "small", nil
        case value < 100:
            return "medium", nil
        case value < 1000:
            return "large", nil
        default:
            return "xlarge", nil
        }
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        return flyt.Action(execResult.(string)), nil
    }),
)

flow := flyt.NewFlow(categoryNode)
flow.Connect(categoryNode, "small", smallHandler)
flow.Connect(categoryNode, "medium", mediumHandler)
flow.Connect(categoryNode, "large", largeHandler)
flow.Connect(categoryNode, "xlarge", xlargeHandler)
```

### State Machine Pattern

Implement state transitions:

```go
type StateMachine struct {
    *flyt.BaseNode
}

func (n *StateMachine) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    state := shared.GetStringOr("state", "init")
    event := execResult.(string)
    
    // State transition logic
    nextState := n.transition(state, event)
    shared.Set("state", nextState)
    
    // Return action based on new state
    return flyt.Action(nextState), nil
}

func (n *StateMachine) transition(state, event string) string {
    transitions := map[string]map[string]string{
        "init": {
            "start": "processing",
            "cancel": "cancelled",
        },
        "processing": {
            "complete": "done",
            "error": "failed",
            "pause": "paused",
        },
        "paused": {
            "resume": "processing",
            "cancel": "cancelled",
        },
    }
    
    if stateTransitions, ok := transitions[state]; ok {
        if nextState, ok := stateTransitions[event]; ok {
            return nextState
        }
    }
    
    return state // No transition
}
```

### Dynamic Routing

Route based on external configuration:

```go
type DynamicRouter struct {
    *flyt.BaseNode
    routes map[string]string
}

func NewDynamicRouter(configPath string) *DynamicRouter {
    // Load routing configuration
    data, _ := os.ReadFile(configPath)
    var routes map[string]string
    json.Unmarshal(data, &routes)
    
    return &DynamicRouter{
        BaseNode: flyt.NewBaseNode(),
        routes:   routes,
    }
}

func (n *DynamicRouter) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    result := execResult.(string)
    
    // Look up route in configuration
    if action, ok := n.routes[result]; ok {
        return flyt.Action(action), nil
    }
    
    // Default route
    return flyt.DefaultAction, nil
}
```

### Weighted Routing

Distribute load across paths:

```go
type LoadBalancer struct {
    *flyt.BaseNode
    weights  map[string]int
    counter  int
    mu       sync.Mutex
}

func NewLoadBalancer(weights map[string]int) *LoadBalancer {
    return &LoadBalancer{
        BaseNode: flyt.NewBaseNode(),
        weights:  weights,
    }
}

func (n *LoadBalancer) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    n.mu.Lock()
    defer n.mu.Unlock()
    
    n.counter++
    
    // Calculate total weight
    totalWeight := 0
    for _, weight := range n.weights {
        totalWeight += weight
    }
    
    // Determine which path based on counter
    position := n.counter % totalWeight
    currentWeight := 0
    
    for action, weight := range n.weights {
        currentWeight += weight
        if position < currentWeight {
            return flyt.Action(action), nil
        }
    }
    
    return flyt.DefaultAction, nil
}

// Usage
balancer := NewLoadBalancer(map[string]int{
    "server1": 3,  // 30% of traffic
    "server2": 5,  // 50% of traffic
    "server3": 2,  // 20% of traffic
})
```

### Conditional Loops

Create loops with exit conditions:

```go
retryNode := flyt.NewNode(
    flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
        attempts := shared.GetInt("attempts")
        return attempts, nil
    }),
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        attempts := prepResult.(int)
        
        // Try operation
        result, err := performOperation()
        if err != nil {
            return map[string]any{
                "success": false,
                "attempts": attempts + 1,
                "error": err.Error(),
            }, nil
        }
        
        return map[string]any{
            "success": true,
            "result": result,
        }, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        result := execResult.(map[string]any)
        
        if result["success"].(bool) {
            return "success", nil
        }
        
        attempts := result["attempts"].(int)
        shared.Set("attempts", attempts)
        
        if attempts < 3 {
            return "retry", nil  // Loop back
        }
        
        return "failed", nil  // Exit loop
    }),
)

flow := flyt.NewFlow(retryNode)
flow.Connect(retryNode, "retry", retryNode)  // Loop back to self
flow.Connect(retryNode, "success", successNode)
flow.Connect(retryNode, "failed", failureNode)
```

### Pipeline Branching

Branch and merge pipelines:

```go
// Split node decides which pipeline(s) to execute
splitNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        data := prepResult.(map[string]any)
        
        needsValidation := data["validate"].(bool)
        needsEnrichment := data["enrich"].(bool)
        
        if needsValidation && needsEnrichment {
            return "both", nil
        } else if needsValidation {
            return "validate_only", nil
        } else if needsEnrichment {
            return "enrich_only", nil
        }
        return "skip", nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        return flyt.Action(execResult.(string)), nil
    }),
)

// Build flow with different pipelines
flow := flyt.NewFlow(splitNode)

// Both pipelines
flow.Connect(splitNode, "both", validateNode)
flow.Connect(validateNode, flyt.DefaultAction, enrichNode)
flow.Connect(enrichNode, flyt.DefaultAction, mergeNode)

// Validation only
flow.Connect(splitNode, "validate_only", validateNode)
flow.Connect(validateNode, "skip_enrich", mergeNode)

// Enrichment only
flow.Connect(splitNode, "enrich_only", enrichNode)
flow.Connect(enrichNode, "skip_validate", mergeNode)

// Skip both
flow.Connect(splitNode, "skip", mergeNode)
```

### Feature Flags

Control flow with feature toggles:

```go
type FeatureFlagNode struct {
    *flyt.BaseNode
    flags map[string]bool
}

func (n *FeatureFlagNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    feature := execResult.(string)
    
    // Check if feature is enabled
    if enabled, ok := n.flags[feature]; ok && enabled {
        return flyt.Action(feature + "_enabled"), nil
    }
    
    return flyt.Action(feature + "_disabled"), nil
}

// Usage
flagNode := &FeatureFlagNode{
    BaseNode: flyt.NewBaseNode(),
    flags: map[string]bool{
        "new_algorithm": true,
        "beta_feature": false,
        "experimental": true,
    },
}

flow := flyt.NewFlow(flagNode)
flow.Connect(flagNode, "new_algorithm_enabled", newAlgorithmNode)
flow.Connect(flagNode, "new_algorithm_disabled", oldAlgorithmNode)
```

### A/B Testing

Route based on experiment groups:

```go
func createABTestNode(testName string, distribution map[string]int) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            userID := shared.GetString("user_id")
            return userID, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            userID := prepResult.(string)
            
            // Hash user ID for consistent assignment
            h := fnv.New32a()
            h.Write([]byte(userID + testName))
            hash := h.Sum32()
            
            // Determine variant based on distribution
            bucket := int(hash % 100)
            cumulative := 0
            
            for variant, percentage := range distribution {
                cumulative += percentage
                if bucket < cumulative {
                    return variant, nil
                }
            }
            
            return "control", nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            variant := execResult.(string)
            shared.Set("ab_variant", variant)
            return flyt.Action(variant), nil
        }),
    )
}

// Usage
abNode := createABTestNode("checkout_flow", map[string]int{
    "variant_a": 33,  // 33% of users
    "variant_b": 33,  // 33% of users
    "control":   34,  // 34% of users
})
```

### Best Practices

1. **Clear Action Names**: Use descriptive action names that indicate the path
2. **Document Branches**: Comment all possible branches and their conditions
3. **Handle All Cases**: Ensure all possible actions have connections
4. **Avoid Deep Nesting**: Keep branching logic simple and readable
5. **Test All Paths**: Write tests for each branch condition
6. **Monitor Branch Usage**: Track which paths are taken most frequently

### Next Steps

* [Actions](/concepts/actions) - Deep dive into action system
* [Flows](/concepts/flows) - Building complex workflows
* [State Machines](/patterns/branching#state-machine-pattern) - Advanced state management


## Configuration via Closures

Use closures to create configurable, reusable nodes with encapsulated state and configuration.

### Basic Closure Pattern

Pass configuration to nodes using closures:

```go
func createAPINode(apiKey string, baseURL string) flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // apiKey and baseURL are captured in the closure
            url := fmt.Sprintf("%s/data", baseURL)
            req, _ := http.NewRequest("GET", url, nil)
            req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))
            
            client := &http.Client{Timeout: 30 * time.Second}
            resp, err := client.Do(req)
            if err != nil {
                return nil, err
            }
            defer resp.Body.Close()
            
            var data map[string]any
            json.NewDecoder(resp.Body).Decode(&data)
            return data, nil
        }),
    )
}

// Usage
apiNode := createAPINode("secret-key-123", "https://api.example.com")
```

### Stateful Nodes

Maintain state across executions:

```go
func createCounterNode() flyt.Node {
    count := 0
    mu := &sync.Mutex{}
    
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            mu.Lock()
            count++
            current := count
            mu.Unlock()
            
            return fmt.Sprintf("Execution #%d", current), nil
        }),
    )
}
```

### Configuration Objects

Use structs for complex configuration:

```go
type DatabaseConfig struct {
    Host     string
    Port     int
    User     string
    Password string
    Database string
    MaxConns int
}

func createDatabaseNode(config DatabaseConfig) flyt.Node {
    // Create connection pool once
    dsn := fmt.Sprintf("%s:%s@tcp(%s:%d)/%s",
        config.User, config.Password, config.Host, config.Port, config.Database)
    
    db, _ := sql.Open("mysql", dsn)
    db.SetMaxOpenConns(config.MaxConns)
    
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            query := prepResult.(string)
            rows, err := db.QueryContext(ctx, query)
            if err != nil {
                return nil, err
            }
            defer rows.Close()
            
            var results []map[string]any
            // Process rows...
            return results, nil
        }),
    )
}

// Usage
dbNode := createDatabaseNode(DatabaseConfig{
    Host:     "localhost",
    Port:     3306,
    User:     "app",
    Password: "secret",
    Database: "myapp",
    MaxConns: 10,
})
```

### Factory Functions

Create specialized node variants:

```go
func createHTTPNode(method string, headers map[string]string) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            url := shared.GetString("url")
            body := shared.GetMap("body")
            return map[string]any{"url": url, "body": body}, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            data := prepResult.(map[string]any)
            url := data["url"].(string)
            
            var bodyReader io.Reader
            if body, ok := data["body"]; ok {
                bodyBytes, _ := json.Marshal(body)
                bodyReader = bytes.NewReader(bodyBytes)
            }
            
            req, _ := http.NewRequest(method, url, bodyReader)
            
            // Apply configured headers
            for key, value := range headers {
                req.Header.Set(key, value)
            }
            
            client := &http.Client{}
            resp, err := client.Do(req)
            if err != nil {
                return nil, err
            }
            defer resp.Body.Close()
            
            var result map[string]any
            json.NewDecoder(resp.Body).Decode(&result)
            return result, nil
        }),
    )
}

// Create specialized nodes
getNode := createHTTPNode("GET", map[string]string{
    "Accept": "application/json",
})

postNode := createHTTPNode("POST", map[string]string{
    "Content-Type": "application/json",
    "Accept": "application/json",
})
```

### Resource Management

Manage shared resources:

```go
func createFileProcessorNode(bufferSize int) flyt.Node {
    // Pre-allocate buffer
    buffer := make([]byte, bufferSize)
    
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            filePath := prepResult.(string)
            
            file, err := os.Open(filePath)
            if err != nil {
                return nil, err
            }
            defer file.Close()
            
            // Reuse buffer
            n, err := file.Read(buffer)
            if err != nil && err != io.EOF {
                return nil, err
            }
            
            // Process buffer[:n]
            return processData(buffer[:n]), nil
        }),
    )
}
```

### Middleware Pattern

Wrap nodes with additional behavior:

```go
func withLogging(name string, node flyt.Node) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            log.Printf("[%s] Starting prep", name)
            return node.Prep(ctx, shared)
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            start := time.Now()
            result, err := node.Exec(ctx, prepResult)
            log.Printf("[%s] Exec took %v", name, time.Since(start))
            return result, err
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            action, err := node.Post(ctx, shared, prepResult, execResult)
            log.Printf("[%s] Returning action: %s", name, action)
            return action, err
        }),
    )
}

// Usage
processNode := withLogging("processor", createProcessNode())
```

### Dynamic Configuration

Load configuration at runtime:

```go
func createConfigurableNode(configPath string) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Load config file
            data, err := os.ReadFile(configPath)
            if err != nil {
                return nil, err
            }
            
            var config map[string]any
            json.Unmarshal(data, &config)
            return config, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            config := prepResult.(map[string]any)
            // Use configuration
            return processWithConfig(config), nil
        }),
    )
}
```

### Dependency Injection

Inject dependencies through closures:

```go
type Dependencies struct {
    DB       *sql.DB
    Cache    *redis.Client
    Logger   *log.Logger
    Metrics  *prometheus.Registry
}

func createServiceNode(deps Dependencies) flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Use injected dependencies
            deps.Logger.Println("Processing request")
            
            // Check cache
            if cached, err := deps.Cache.Get(ctx, "key").Result(); err == nil {
                deps.Metrics.Inc("cache_hits")
                return cached, nil
            }
            
            // Query database
            result, err := queryDB(deps.DB, prepResult)
            if err != nil {
                deps.Logger.Printf("DB error: %v", err)
                return nil, err
            }
            
            // Update cache
            deps.Cache.Set(ctx, "key", result, time.Hour)
            
            return result, nil
        }),
    )
}
```

### Best Practices

1. **Immutable Configuration**: Don't modify captured variables after node creation
2. **Thread Safety**: Use mutexes for shared state in concurrent scenarios
3. **Resource Cleanup**: Ensure resources are properly closed
4. **Error Handling**: Handle configuration errors gracefully
5. **Documentation**: Document required configuration clearly

### Next Steps

* [Error Handling](/patterns/error-handling) - Build resilient nodes
* [Custom Node Types](/advanced/custom-nodes) - Advanced node patterns
* [Best Practices](/best-practices) - General guidelines


## Error Handling & Retries

Build resilient workflows with proper error handling and retry strategies.

### Basic Retry Configuration

Configure retries at the node level:

```go
node := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        // This will be retried up to 3 times
        return callFlakeyAPI()
    }),
    flyt.WithMaxRetries(3),
    flyt.WithWait(time.Second), // Wait 1 second between retries
    flyt.WithExecFallbackFunc(func(prepResult any, err error) (any, error) {
        // Called after all retries fail
        log.Printf("API failed after retries: %v", err)
        return nil, nil // Return nil to handle in Post
    }),
)
```

### Exponential Backoff

Implement exponential backoff with RetryableNode:

```go
type BackoffNode struct {
    *flyt.BaseNode
    attempt int
}

func (n *BackoffNode) GetMaxRetries() int {
    return 5
}

func (n *BackoffNode) GetWait() time.Duration {
    // Exponential backoff: 1s, 2s, 4s, 8s, 16s
    return time.Duration(math.Pow(2, float64(n.attempt))) * time.Second
}

func (n *BackoffNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.attempt++
    result, err := callAPI()
    if err != nil {
        log.Printf("Attempt %d failed: %v", n.attempt, err)
        return nil, err
    }
    n.attempt = 0 // Reset on success
    return result, nil
}
```

### Circuit Breaker Pattern

Prevent cascading failures:

```go
type CircuitBreakerNode struct {
    *flyt.BaseNode
    failures    int
    lastFailure time.Time
    threshold   int
    timeout     time.Duration
}

func NewCircuitBreakerNode() *CircuitBreakerNode {
    return &CircuitBreakerNode{
        BaseNode:  flyt.NewBaseNode(),
        threshold: 5,
        timeout:   30 * time.Second,
    }
}

func (n *CircuitBreakerNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Check if circuit is open
    if n.failures >= n.threshold {
        if time.Since(n.lastFailure) < n.timeout {
            return nil, fmt.Errorf("circuit breaker open")
        }
        // Reset after timeout
        n.failures = 0
    }
    
    result, err := callService()
    if err != nil {
        n.failures++
        n.lastFailure = time.Now()
        return nil, err
    }
    
    n.failures = 0 // Reset on success
    return result, nil
}
```

### Fallback on Failure

Implement the FallbackNode interface for graceful degradation:

```go
type CachedAPINode struct {
    *flyt.BaseNode
    cache sync.Map
}

func (n *CachedAPINode) Exec(ctx context.Context, prepResult any) (any, error) {
    key := prepResult.(string)
    
    // Try to fetch fresh data
    data, err := fetchFromAPI(key)
    if err == nil {
        // Cache successful result
        n.cache.Store(key, data)
        return data, nil
    }
    
    return nil, err
}

func (n *CachedAPINode) ExecFallback(prepResult any, err error) (any, error) {
    key := prepResult.(string)
    
    // Return cached data on failure
    if cached, ok := n.cache.Load(key); ok {
        log.Printf("Returning cached data for %s due to error: %v", key, err)
        return cached, nil
    }
    
    // Return default if no cache
    return map[string]any{
        "status": "unavailable",
        "cached": false,
    }, nil
}
```

### Error Aggregation

Collect errors from batch operations:

```go
func processBatch(ctx context.Context, items []Item) error {
    var errs []error
    
    for i, item := range items {
        if err := processItem(item); err != nil {
            errs = append(errs, fmt.Errorf("item %d: %w", i, err))
        }
    }
    
    if len(errs) > 0 {
        return &flyt.BatchError{
            Errors: errs,
            Message: fmt.Sprintf("%d/%d items failed", len(errs), len(items)),
        }
    }
    
    return nil
}
```

### Retry with Jitter

Add randomization to prevent thundering herd:

```go
func (n *JitterNode) GetWait() time.Duration {
    base := time.Second * time.Duration(n.attempt)
    jitter := time.Duration(rand.Intn(1000)) * time.Millisecond
    return base + jitter
}
```

### Selective Retry

Only retry specific errors:

```go
func (n *SelectiveRetryNode) Exec(ctx context.Context, prepResult any) (any, error) {
    result, err := callAPI()
    if err != nil {
        // Only retry on network errors
        if isNetworkError(err) {
            return nil, err // Will be retried
        }
        // Don't retry business logic errors
        return nil, fmt.Errorf("permanent error: %w", err)
    }
    return result, nil
}

func (n *SelectiveRetryNode) GetMaxRetries() int {
    // Check error type from last execution
    if n.lastError != nil && !isRetryable(n.lastError) {
        return 0 // Don't retry
    }
    return 3
}
```

### Error Context

Provide context for debugging:

```go
type ErrorContext struct {
    Node      string
    Action    string
    Input     any
    Error     error
    Timestamp time.Time
    Attempts  int
}

func (n *DetailedErrorNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if err, ok := execResult.(error); ok && err != nil {
        errorCtx := ErrorContext{
            Node:      "DetailedErrorNode",
            Action:    "process",
            Input:     prepResult,
            Error:     err,
            Timestamp: time.Now(),
            Attempts:  n.attempts,
        }
        
        shared.Set("last_error", errorCtx)
        
        if n.attempts < n.maxRetries {
            return "retry", nil
        }
        return "error", nil
    }
    
    return flyt.DefaultAction, nil
}
```

### Timeout Handling

Prevent hanging operations:

```go
func (n *TimeoutNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Create timeout context
    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)
    defer cancel()
    
    resultChan := make(chan any)
    errChan := make(chan error)
    
    go func() {
        result, err := longRunningOperation()
        if err != nil {
            errChan <- err
        } else {
            resultChan <- result
        }
    }()
    
    select {
    case result := <-resultChan:
        return result, nil
    case err := <-errChan:
        return nil, err
    case <-ctx.Done():
        return nil, fmt.Errorf("operation timed out: %w", ctx.Err())
    }
}
```

### Best Practices

1. **Identify Transient vs Permanent Errors**: Only retry transient failures
2. **Set Reasonable Limits**: Don't retry indefinitely
3. **Use Backoff**: Avoid overwhelming failing services
4. **Log Failures**: Track retry attempts for debugging
5. **Provide Fallbacks**: Gracefully degrade when possible
6. **Monitor Retry Rates**: High retry rates indicate problems

### Next Steps

* [Fallback on Failure](/patterns/fallback) - Graceful degradation
* [Batch Error Handling](/advanced/batch-processing#batch-error-handling) - Handle batch failures
* [Best Practices](/best-practices) - General guidelines


## Fallback on Failure

Implement graceful degradation when operations fail, ensuring your workflows remain resilient and provide the best possible user experience even during failures.

### FallbackNode Interface

The `FallbackNode` interface allows custom fallback behavior:

```go
type FallbackNode interface {
    Node
    ExecFallback(prepResult any, err error) (any, error)
}
```

### Basic Fallback

Return default values on failure:

```go
type DefaultValueNode struct {
    *flyt.BaseNode
}

func (n *DefaultValueNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Try primary operation
    result, err := fetchFromPrimarySource()
    if err != nil {
        return nil, err // Will trigger fallback
    }
    return result, nil
}

func (n *DefaultValueNode) ExecFallback(prepResult any, err error) (any, error) {
    log.Printf("Primary source failed: %v, returning default", err)
    
    // Return safe default value
    return map[string]any{
        "status": "degraded",
        "data": "default_value",
        "error": err.Error(),
    }, nil
}
```

### Cached Fallback

Use cached data when fresh data is unavailable:

```go
type CachedAPINode struct {
    *flyt.BaseNode
    cache map[string]CacheEntry
    mu    sync.RWMutex
}

type CacheEntry struct {
    Data      any
    Timestamp time.Time
}

func (n *CachedAPINode) Exec(ctx context.Context, prepResult any) (any, error) {
    key := prepResult.(string)
    
    // Try to fetch fresh data
    data, err := fetchFromAPI(key)
    if err == nil {
        // Update cache on success
        n.mu.Lock()
        n.cache[key] = CacheEntry{
            Data:      data,
            Timestamp: time.Now(),
        }
        n.mu.Unlock()
        return data, nil
    }
    
    return nil, err
}

func (n *CachedAPINode) ExecFallback(prepResult any, err error) (any, error) {
    key := prepResult.(string)
    
    n.mu.RLock()
    entry, exists := n.cache[key]
    n.mu.RUnlock()
    
    if exists {
        age := time.Since(entry.Timestamp)
        log.Printf("Returning cached data (age: %v) due to error: %v", age, err)
        
        // Add metadata about cache usage
        return map[string]any{
            "data":       entry.Data,
            "cached":     true,
            "cache_age":  age.Seconds(),
            "error":      err.Error(),
        }, nil
    }
    
    // No cache available
    return nil, fmt.Errorf("no fallback available: %w", err)
}
```

### Multi-Level Fallback

Try multiple fallback strategies:

```go
type MultiLevelFallbackNode struct {
    *flyt.BaseNode
    primaryURL   string
    secondaryURL string
    cache        sync.Map
}

func (n *MultiLevelFallbackNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Try primary source
    data, err := fetchFromURL(n.primaryURL)
    if err == nil {
        n.cache.Store("last_good", data)
        return data, nil
    }
    
    return nil, err
}

func (n *MultiLevelFallbackNode) ExecFallback(prepResult any, primaryErr error) (any, error) {
    // Level 1: Try secondary source
    data, err := fetchFromURL(n.secondaryURL)
    if err == nil {
        log.Printf("Using secondary source due to primary error: %v", primaryErr)
        return data, nil
    }
    
    // Level 2: Try cache
    if cached, ok := n.cache.Load("last_good"); ok {
        log.Printf("Using cached data due to all sources failing")
        return cached, nil
    }
    
    // Level 3: Return minimal default
    log.Printf("All fallbacks exhausted, returning minimal response")
    return map[string]any{
        "status": "unavailable",
        "message": "Service temporarily unavailable",
    }, nil
}
```

### Partial Fallback

Return partial results when complete processing fails:

```go
type BatchProcessorNode struct {
    *flyt.BaseNode
    results []Result
    errors  []error
}

func (n *BatchProcessorNode) Exec(ctx context.Context, prepResult any) (any, error) {
    items := prepResult.([]Item)
    n.results = make([]Result, 0, len(items))
    n.errors = make([]error, 0)
    
    for _, item := range items {
        result, err := processItem(item)
        if err != nil {
            n.errors = append(n.errors, err)
            continue
        }
        n.results = append(n.results, result)
    }
    
    if len(n.errors) > 0 {
        return nil, fmt.Errorf("processing failed: %d errors", len(n.errors))
    }
    
    return n.results, nil
}

func (n *BatchProcessorNode) ExecFallback(prepResult any, err error) (any, error) {
    // Return partial results
    return map[string]any{
        "partial_results": n.results,
        "success_count":   len(n.results),
        "error_count":     len(n.errors),
        "errors":          n.errors,
        "status":          "partial_success",
    }, nil
}
```

### Circuit Breaker Fallback

Prevent cascading failures:

```go
type CircuitBreakerNode struct {
    *flyt.BaseNode
    failures    int
    lastFailure time.Time
    threshold   int
    timeout     time.Duration
    fallbackMsg string
}

func (n *CircuitBreakerNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Check if circuit is open
    if n.isCircuitOpen() {
        return nil, fmt.Errorf("circuit breaker open")
    }
    
    result, err := callService(prepResult)
    if err != nil {
        n.recordFailure()
        return nil, err
    }
    
    n.reset()
    return result, nil
}

func (n *CircuitBreakerNode) ExecFallback(prepResult any, err error) (any, error) {
    if n.isCircuitOpen() {
        // Return cached or default response immediately
        return map[string]any{
            "status": "circuit_open",
            "message": n.fallbackMsg,
            "retry_after": n.timeout - time.Since(n.lastFailure),
        }, nil
    }
    
    // Circuit not open, but request failed
    return map[string]any{
        "status": "degraded",
        "message": "Service temporarily unavailable",
    }, nil
}

func (n *CircuitBreakerNode) isCircuitOpen() bool {
    return n.failures >= n.threshold && 
           time.Since(n.lastFailure) < n.timeout
}

func (n *CircuitBreakerNode) recordFailure() {
    n.failures++
    n.lastFailure = time.Now()
}

func (n *CircuitBreakerNode) reset() {
    n.failures = 0
}
```

### Fallback with Metrics

Track fallback usage:

```go
type MetricsFallbackNode struct {
    *flyt.BaseNode
    primaryCalls   int64
    fallbackCalls  int64
    lastFallback   time.Time
}

func (n *MetricsFallbackNode) ExecFallback(prepResult any, err error) (any, error) {
    atomic.AddInt64(&n.fallbackCalls, 1)
    n.lastFallback = time.Now()
    
    // Log metrics
    total := atomic.LoadInt64(&n.primaryCalls) + atomic.LoadInt64(&n.fallbackCalls)
    fallbackRate := float64(n.fallbackCalls) / float64(total) * 100
    
    log.Printf("Fallback metrics - Rate: %.2f%%, Total fallbacks: %d", 
        fallbackRate, n.fallbackCalls)
    
    // Return fallback data
    return getDefaultResponse(), nil
}
```

### Conditional Fallback

Different fallbacks based on error type:

```go
func (n *ConditionalFallbackNode) ExecFallback(prepResult any, err error) (any, error) {
    switch {
    case errors.Is(err, ErrTimeout):
        // For timeouts, return cached data
        return n.getCachedResponse(), nil
        
    case errors.Is(err, ErrRateLimit):
        // For rate limits, return throttled message
        return map[string]any{
            "error": "rate_limited",
            "retry_after": 60,
        }, nil
        
    case errors.Is(err, ErrNotFound):
        // For not found, return empty result
        return map[string]any{
            "found": false,
            "data": nil,
        }, nil
        
    default:
        // Generic fallback
        return map[string]any{
            "status": "error",
            "message": "Service unavailable",
        }, nil
    }
}
```

### Best Practices

1. **Log Fallback Usage**: Track when and why fallbacks are triggered
2. **Monitor Fallback Rates**: High rates indicate system issues
3. **Set Appropriate Timeouts**: Don't wait too long before falling back
4. **Provide Meaningful Defaults**: Fallback data should be useful
5. **Document Fallback Behavior**: Make it clear what happens during failures
6. **Test Fallback Paths**: Ensure fallbacks work correctly
7. **Consider User Experience**: Degraded service is better than no service

### Next Steps

* [Error Handling](/patterns/error-handling) - Comprehensive error strategies
* [Conditional Branching](/patterns/branching) - Dynamic flow control
* [Circuit Breaker Pattern](/patterns/error-handling#circuit-breaker-pattern) - Prevent cascading failures

