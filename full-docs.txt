Directory structure:
└── flyt/
    ├── README.md
    ├── AGENTS.md
    ├── batch.go
    ├── batch_test.go
    ├── flyt.go
    ├── flyt_test.go
    ├── go.mod
    ├── LICENSE
    ├── www/
    │   ├── README.md
    │   ├── package.json
    │   ├── tsconfig.json
    │   ├── vocs.config.ts
    │   └── docs/
    │       ├── pages/
    │       │   ├── best-practices.mdx
    │       │   ├── index.mdx
    │       │   ├── advanced/
    │       │   │   ├── batch-flows.mdx
    │       │   │   ├── batch-processing.mdx
    │       │   │   ├── custom-nodes.mdx
    │       │   │   ├── flow-as-node.mdx
    │       │   │   ├── nested-flows.mdx
    │       │   │   ├── utilities.mdx
    │       │   │   └── worker-pool.mdx
    │       │   ├── concepts/
    │       │   │   ├── actions.mdx
    │       │   │   ├── flows.mdx
    │       │   │   ├── nodes.mdx
    │       │   │   └── shared-store.mdx
    │       │   ├── getting-started/
    │       │   │   ├── installation.mdx
    │       │   │   ├── quick-start.mdx
    │       │   │   └── template.mdx
    │       │   └── patterns/
    │       │       ├── branching.mdx
    │       │       ├── closures.mdx
    │       │       ├── error-handling.mdx
    │       │       └── fallback.mdx
    │       └── public/
    │           └── site.webmanifest
    └── .github/
        └── workflows/
            ├── pages.yml
            ├── release.yml
            └── test.yml

================================================
FILE: README.md
================================================
![Flyt Logo](flyt-logo.png)

# Flyt

*Norwegian for "flow" • Pronounced "fleet"*

A minimalist workflow framework for Go with zero dependencies inspired by [Pocket Flow](https://github.com/The-Pocket/PocketFlow).

## Table of Contents

- [Installation](#installation)
- [Getting Started](#getting-started)
  - [Using the Project Template (Recommended)](#using-the-project-template-recommended)
  - [Manual Setup](#manual-setup)
- [Core Concepts](#core-concepts)
  - [Nodes](#nodes)
  - [Actions](#actions)
  - [Flows](#flows)
  - [Shared Store](#shared-store)
- [Intermediate Patterns](#intermediate-patterns)
  - [Configuration via Closures](#configuration-via-closures)
  - [Error Handling & Retries](#error-handling--retries)
  - [Fallback on Failure](#fallback-on-failure)
  - [Conditional Branching](#conditional-branching)
- [Advanced Usage](#advanced-usage)
  - [Custom Node Types](#custom-node-types)
    - [RetryableNode Interface](#retryablenode-interface)
  - [Batch Processing](#batch-processing)
    - [Advanced Batch Configuration](#advanced-batch-configuration)
    - [Batch Error Handling](#batch-error-handling)
  - [Batch Flows](#batch-flows)
  - [Nested Flows](#nested-flows)
  - [Flow as Node](#flow-as-node)
  - [Worker Pool](#worker-pool)
  - [Utility Functions](#utility-functions)
    - [ToSlice](#toslice)
- [Best Practices](#best-practices)
- [Examples](#examples)
- [License](#license)

## Installation

```bash
go get github.com/mark3labs/flyt
```

## Getting Started

### Using the Project Template (Recommended)

The fastest way to start a new Flyt project is using the official template:

```bash
# Create a new project from the template
git clone https://github.com/mark3labs/flyt-project-template my-flyt-project
cd my-flyt-project

# Remove the template git history and start fresh
rm -rf .git
git init

# Install dependencies
go mod tidy

# Run the example
go run main.go
```

The template provides a starting point for your Flyt project with a basic structure and example code.

### Manual Setup

```go
package main

import (
    "context"
    "fmt"
    "github.com/mark3labs/flyt"
)

func main() {
    // Create a simple node using the helper
    node := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            fmt.Println("Hello, Flyt!")
            return "done", nil
        }),
    )

    // Run it
    ctx := context.Background()
    shared := flyt.NewSharedStore()
    
    action, err := flyt.Run(ctx, node, shared)
    if err != nil {
        panic(err)
    }
    fmt.Printf("Completed with action: %s\n", action)
}
```

## Core Concepts

### Nodes

Nodes are the building blocks. Each node has three phases:

1. **Prep** - Read from shared store and prepare data
2. **Exec** - Execute main logic (can be retried)
3. **Post** - Process results and decide next action

```go
// Simple node with type-safe getters
node := flyt.NewNode(
    flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
        // Use type-safe getters to retrieve data
        input := shared.GetString("input")
        return input, nil
    }),
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        // Process data
        return "result", nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        shared.Set("output", execResult)
        return flyt.DefaultAction, nil
    }),
)

// Working with structured data
type ProcessRequest struct {
    UserID    int      `json:"user_id"`
    Operation string   `json:"operation"`
    Resources []string `json:"resources"`
}

processNode := flyt.NewNode(
    flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
        // Bind structured data from shared store
        var request ProcessRequest
        if err := shared.Bind("request", &request); err != nil {
            return nil, fmt.Errorf("invalid request: %w", err)
        }
        return request, nil
    }),
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        request := prepResult.(ProcessRequest)
        // Process the structured request
        result := processUserRequest(request.UserID, request.Operation, request.Resources)
        return result, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        shared.Set("process_result", execResult)
        return flyt.DefaultAction, nil
    }),
)
```

### Actions

Actions are strings returned by a node's Post phase that determine what happens next:

```go
func (n *MyNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if execResult.(bool) {
        return "success", nil  // Go to node connected with "success"
    }
    return "retry", nil       // Go to node connected with "retry"
}
```

The default action is `flyt.DefaultAction` (value: "default"). If no connection exists for an action, the flow ends.

### Flows

Connect nodes to create workflows:

```go
// Create nodes
validateNode := createValidateNode()
processNode := createProcessNode()
errorNode := createErrorNode()

// Build flow with action-based routing
flow := flyt.NewFlow(validateNode)
flow.Connect(validateNode, "valid", processNode)    // If validation succeeds
flow.Connect(validateNode, "invalid", errorNode)    // If validation fails
flow.Connect(processNode, "done", nil)              // End flow after processing

// Run flow
err := flow.Run(ctx, shared)
```

### Shared Store

Thread-safe data sharing between nodes with type-safe helpers:

```go
shared := flyt.NewSharedStore()

// Set values
shared.Set("name", "Alice")
shared.Set("count", 42)
shared.Set("price", 19.99)
shared.Set("enabled", true)
shared.Set("items", []string{"apple", "banana"})
shared.Set("config", map[string]any{"timeout": 30})

// Type-safe getters (return zero values if not found or wrong type)
str := shared.GetString("name")           // Returns "Alice"
num := shared.GetInt("count")             // Returns 42
price := shared.GetFloat64("price")       // Returns 19.99
enabled := shared.GetBool("enabled")      // Returns true
items := shared.GetSlice("items")         // Returns []any{"apple", "banana"}
config := shared.GetMap("config")         // Returns map[string]any{"timeout": 30}

// Type-safe getters with custom defaults
str = shared.GetStringOr("missing", "anonymous")     // Returns "anonymous"
num = shared.GetIntOr("missing", -1)                 // Returns -1
price = shared.GetFloat64Or("missing", 99.99)        // Returns 99.99
enabled = shared.GetBoolOr("missing", true)          // Returns true

// Bind complex types (similar to Echo framework)
type User struct {
    ID    int      `json:"id"`
    Name  string   `json:"name"`
    Email string   `json:"email"`
    Tags  []string `json:"tags"`
}

// Store a typed struct - it gets stored as-is
user := User{
    ID:    123,
    Name:  "Alice",
    Email: "alice@example.com",
    Tags:  []string{"admin", "developer"},
}
shared.Set("user", user)

// Later, in a node's Prep function, bind it back to a struct
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    var user User
    err := shared.Bind("user", &user)  // Binds stored data to struct
    if err != nil {
        return nil, err
    }
    // Or use MustBind (panics on failure - use for required data)
    // shared.MustBind("user", &user)
    
    return user, nil
}

// Utility methods
exists := shared.Has("key")       // Check if key exists
shared.Delete("key")               // Remove a key
keys := shared.Keys()              // Get all keys
length := shared.Len()             // Get number of items
shared.Clear()                     // Remove all items

// Get all data as a map (returns a copy)
allData := shared.GetAll()

// Merge multiple values at once
shared.Merge(map[string]any{
    "user_id": 123,
    "config": map[string]any{"timeout": 30},
})
```

The type-safe getters handle numeric conversions automatically:
- `GetInt()` converts from int8, int16, int32, int64, uint variants, and float types
- `GetFloat64()` converts from all numeric types including int and float32
- `GetSlice()` uses the same conversion logic as `ToSlice()` utility

## Intermediate Patterns

### Configuration via Closures

Pass configuration to nodes using closures:

```go
func createAPINode(apiKey string, baseURL string) flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // apiKey and baseURL are captured in the closure
            url := fmt.Sprintf("%s/data", baseURL)
            req, _ := http.NewRequest("GET", url, nil)
            req.Header.Set("Authorization", apiKey)
            // ... make request
            return data, nil
        }),
    )
}

// Usage
node := createAPINode("secret-key", "https://api.example.com")
```

### Error Handling & Retries

Add retry logic to handle transient failures:

```go
node := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        // This will be retried up to 3 times
        return callFlakeyAPI()
    }),
    flyt.WithMaxRetries(3),
    flyt.WithWait(time.Second),
    flyt.WithExecFallbackFunc(func(prepResult any, err error) (any, error) {
        // Called after all retries fail
        return "default-value", nil
    }),
)
```

### Fallback on Failure

Handle failures gracefully by implementing the `FallbackNode` interface:

```go
type CachedAPINode struct {
    *flyt.BaseNode
    cache map[string]any
}

func (n *CachedAPINode) ExecFallback(prepResult any, err error) (any, error) {
    // Return cached data when API fails
    key := prepResult.(string)
    if cached, ok := n.cache[key]; ok {
        return cached, nil
    }
    // Return default value if no cache
    return map[string]any{"status": "unavailable"}, nil
}

func (n *CachedAPINode) Exec(ctx context.Context, prepResult any) (any, error) {
    key := prepResult.(string)
    data, err := callAPI(key)
    if err == nil {
        n.cache[key] = data // Update cache on success
    }
    return data, err
}
```

The `ExecFallback` method is called automatically after all retries are exhausted, allowing you to provide degraded functionality, cached results, or default values.

### Conditional Branching

Control flow based on results:

```go
decisionNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        value := prepResult.(int)
        return value > 100, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        if execResult.(bool) {
            return "high", nil
        }
        return "low", nil
    }),
)

flow := flyt.NewFlow(decisionNode)
flow.Connect(decisionNode, "high", highNode)
flow.Connect(decisionNode, "low", lowNode)
```

## Advanced Usage

### Custom Node Types

For complex nodes with state, create custom types:

```go
type RateLimitedNode struct {
    *flyt.BaseNode
    limiter *rate.Limiter
}

func NewRateLimitedNode(rps int) *RateLimitedNode {
    return &RateLimitedNode{
        BaseNode: flyt.NewBaseNode(),
        limiter:  rate.NewLimiter(rate.Limit(rps), 1),
    }
}

func (n *RateLimitedNode) Exec(ctx context.Context, prepResult any) (any, error) {
    if err := n.limiter.Wait(ctx); err != nil {
        return nil, err
    }
    // Process with rate limiting
    return process(prepResult)
}
```

#### RetryableNode Interface

For custom retry logic, implement the `RetryableNode` interface:

```go
type CustomRetryNode struct {
    *flyt.BaseNode
    attempts int
}

func (n *CustomRetryNode) GetMaxRetries() int {
    // Dynamic retry count based on state
    if n.attempts > 5 {
        return 0 // Stop retrying after 5 total attempts
    }
    return 3
}

func (n *CustomRetryNode) GetWait() time.Duration {
    // Exponential backoff
    return time.Duration(n.attempts) * time.Second
}

func (n *CustomRetryNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.attempts++
    return callAPI(prepResult)
}
```

### Batch Processing

Process multiple items concurrently:

```go
// Simple batch node for processing items
processFunc := func(ctx context.Context, item any) (any, error) {
    // Process each item
    return fmt.Sprintf("processed: %v", item), nil
}

batchNode := flyt.NewBatchNode(processFunc, true) // true for concurrent
shared.Set("items", []string{"item1", "item2", "item3"})
```

#### Advanced Batch Configuration

For more control over batch processing:

```go
config := &flyt.BatchConfig{
    BatchSize:   10,        // Process 10 items at a time
    Concurrency: 5,         // Use 5 concurrent workers
    ItemsKey:    "data",    // Custom key for input items
    ResultsKey:  "output",  // Custom key for results
    CountKey:    "total",   // Custom key for processed count
}

processFunc := func(ctx context.Context, item any) (any, error) {
    return processItem(item)
}

batchNode := flyt.NewBatchNodeWithConfig(processFunc, true, config)
```

#### Batch Error Handling

Batch operations aggregate errors:

```go
action, err := flyt.Run(ctx, batchNode, shared)
if err != nil {
    if batchErr, ok := err.(*flyt.BatchError); ok {
        // Access individual errors
        for i, e := range batchErr.Errors {
            if e != nil {
                fmt.Printf("Item %d failed: %v\n", i, e)
            }
        }
    }
}
```

### Batch Flows

Run the same flow multiple times with different parameters:

```go
// Create a flow factory - returns a new flow instance for each iteration
flowFactory := func() *flyt.Flow {
    validateNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Each flow has its own SharedStore with merged FlowInputs
            userID := shared.GetInt("user_id")
            email := shared.GetString("email")
            return map[string]any{"user_id": userID, "email": email}, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            data := prepResult.(map[string]any)
            // Process user data
            return processUser(data), nil
        }),
    )
    return flyt.NewFlow(validateNode)
}

// Define input parameters for each flow iteration
// Each FlowInputs map is merged into that flow's isolated SharedStore
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    // Could fetch from database, API, etc.
    return []flyt.FlowInputs{
        {"user_id": 1, "email": "user1@example.com"},
        {"user_id": 2, "email": "user2@example.com"},
        {"user_id": 3, "email": "user3@example.com"},
    }, nil
}

// Create and run batch flow
batchFlow := flyt.NewBatchFlow(flowFactory, batchFunc, true) // true for concurrent
err := batchFlow.Run(ctx, shared)

// Each flow runs in isolation with its own SharedStore containing the FlowInputs
```

### Nested Flows

Compose flows for complex workflows:

```go
// Sub-flow for data validation
validationFlow := createValidationFlow()

// Main flow
mainFlow := flyt.NewFlow(fetchNode)
mainFlow.Connect(fetchNode, "validate", validationFlow)
mainFlow.Connect(validationFlow, flyt.DefaultAction, processNode)
```

### Flow as Node

Flows implement the Node interface and can be used anywhere a node is expected:

```go
// Create a reusable flow
func createProcessingFlow() *flyt.Flow {
    validateNode := createValidateNode()
    transformNode := createTransformNode()
    
    flow := flyt.NewFlow(validateNode)
    flow.Connect(validateNode, "valid", transformNode)
    return flow
}

// Use the flow as a node in another flow
processingFlow := createProcessingFlow()
mainFlow := flyt.NewFlow(fetchNode)
mainFlow.Connect(fetchNode, flyt.DefaultAction, processingFlow) // Flow used as node
mainFlow.Connect(processingFlow, flyt.DefaultAction, saveNode)
```

### Worker Pool

For custom concurrent task management:

```go
// Create a worker pool with 10 workers
pool := flyt.NewWorkerPool(10)

// Submit tasks
for _, item := range items {
    item := item // Capture loop variable
    pool.Submit(func() {
        // Process item
        result := processItem(item)
        // Store result safely
        mu.Lock()
        results = append(results, result)
        mu.Unlock()
    })
}

// Wait for all tasks to complete
pool.Wait()

// Clean up
pool.Close()
```

### Utility Functions

#### ToSlice

Convert various types to slices for batch processing:

```go
// Convert different types to []any
items1 := flyt.ToSlice([]string{"a", "b", "c"})
items2 := flyt.ToSlice([]int{1, 2, 3})
items3 := flyt.ToSlice("single item") // Returns []any{"single item"}

// Useful for batch processing with mixed types
shared.Set("items", flyt.ToSlice(data))
```

## Best Practices

1. **Single Responsibility**: Each node should do one thing well
2. **Idempotency**: Nodes should be idempotent when possible
3. **Error Handling**: Always handle errors appropriately
4. **Context Awareness**: Respect context cancellation
5. **Concurrency Safety**: Don't share node instances across flows

## Examples

Check out the [cookbook](cookbook/) directory for complete, real-world examples:

- [Agent](cookbook/agent/) - AI agent with web search capabilities using LLM and search providers
- [Chat](cookbook/chat/) - Interactive chat application with conversation history
- [LLM Streaming](cookbook/llm-streaming/) - Real-time streaming of LLM responses with OpenAI SSE
- [MCP](cookbook/mcp/) - Model Context Protocol integration with OpenAI function calling
- [Summarize](cookbook/summarize/) - Text summarization with error handling and retries
- [Tracing](cookbook/tracing/) - Distributed tracing with Langfuse for observability

## License

MIT



================================================
FILE: AGENTS.md
================================================
# Flyt Codebase Guidelines for AI Agents

## Build/Test Commands
- Run all tests: `go test -race ./...`
- Run single test: `go test -race -v -run TestName`
- Format code: `go fmt ./...`
- Lint code: `go vet ./...`
- Build: `go build`

## Code Style
- Package: Always start with package comment describing purpose
- Imports: Group stdlib, then external (none used), then internal
- Naming: Use Go conventions (camelCase for private, PascalCase for public)
- Interfaces: Define minimal interfaces, embed for composition
- Error handling: Return explicit errors, no panic in library code
- Comments: Document all exported types/functions with godoc format
- Testing: Use table-driven tests, test both success and error cases
- Concurrency: Use sync primitives directly, no abstraction layers
- Dependencies: ZERO external dependencies - stdlib only

## Project Structure
- Single package design (package flyt)
- Core types: Node, Flow, Shared, Params, Action
- Helper functions for batch processing patterns
- Comprehensive test coverage with TestNode implementations


================================================
FILE: batch.go
================================================
// Package flyt provides batch processing capabilities for the flyt workflow framework.
//
// The batch package includes utilities for processing collections of items either
// sequentially or concurrently, with configurable batch sizes and concurrency limits.
//
// Key Features:
//   - Batch processing nodes for item collections
//   - Batch flow execution with parameter variations
//   - Concurrent and sequential processing modes
//   - Configurable batch sizes and concurrency limits
//   - Error aggregation for batch operations
//
// Example (Batch Processing):
//
//	// Process items concurrently
//	processFunc := func(ctx context.Context, item any) (any, error) {
//	    // Process each item
//	    return fmt.Sprintf("processed: %v", item), nil
//	}
//
//	node := flyt.NewBatchNode(processFunc, true) // true for concurrent
//	shared := flyt.NewSharedStore()
//	shared.Set(flyt.KeyItems, []string{"item1", "item2", "item3"})
//
//	action, err := flyt.Run(ctx, node, shared)
//	if err != nil {
//	    log.Fatal(err)
//	}
//
//	results, _ := shared.Get(flyt.KeyResults)
//	fmt.Println(results) // ["processed: item1", "processed: item2", "processed: item3"]
//
// Example (Batch Flow):
//
//	// Run a flow multiple times with different parameters
//	flowFactory := func() *flyt.Flow {
//	    // Create your flow here
//	    return flyt.NewFlow(startNode)
//	}
//
//	batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
//	    return []flyt.FlowInputs{
//	        {"user_id": 1, "action": "process"},
//	        {"user_id": 2, "action": "process"},
//	    }, nil
//	}
//
//	batchFlow := flyt.NewBatchFlow(flowFactory, batchFunc, true)
//	err := batchFlow.Run(ctx, shared)
package flyt

import (
	"context"
	"fmt"
	"sync"
)

// BatchError aggregates multiple errors from batch operations.
// It implements the error interface and provides detailed information
// about all errors that occurred during batch processing.
type BatchError struct {
	Errors []error
}

func (e *BatchError) Error() string {
	if len(e.Errors) == 0 {
		return "batch: no errors recorded"
	}
	if len(e.Errors) == 1 {
		return fmt.Sprintf("batch: %v", e.Errors[0])
	}
	return fmt.Sprintf("batch: %d errors occurred, first: %v", len(e.Errors), e.Errors[0])
}

// BatchConfig holds configuration for batch operations.
// It allows customization of batch processing behavior including
// size limits, concurrency settings, and storage keys.
type BatchConfig struct {
	// MaxBatchSize is the maximum number of items to process in a single batch.
	// If a batch exceeds this size, an error will be returned.
	// Default: 1000
	MaxBatchSize int

	// MaxConcurrency is the maximum number of concurrent workers for parallel processing.
	// This is only used when concurrent processing is enabled.
	// Default: 10
	MaxConcurrency int

	// ItemsKey is the SharedStore key to read items from.
	// Default: "items"
	ItemsKey string

	// ResultsKey is the SharedStore key to write results to.
	// Default: "results"
	ResultsKey string

	// BatchCountKey is the SharedStore key to write the batch count for BatchFlow.
	// Default: "batch_count"
	BatchCountKey string
}

// DefaultBatchConfig returns a BatchConfig with sensible defaults.
// The defaults are:
//   - MaxBatchSize: 1000
//   - MaxConcurrency: 10
//   - ItemsKey: "items"
//   - ResultsKey: "results"
//   - BatchCountKey: "batch_count"
func DefaultBatchConfig() *BatchConfig {
	return &BatchConfig{
		MaxBatchSize:   1000,
		MaxConcurrency: 10,
		ItemsKey:       KeyItems,
		ResultsKey:     KeyResults,
		BatchCountKey:  KeyBatchCount,
	}
}

// BatchProcessFunc is a function that processes a single item in a batch.
// It receives a context and an item, and returns the processed result or an error.
// The function should be thread-safe if concurrent processing is enabled.
type BatchProcessFunc func(ctx context.Context, item any) (any, error)

// NewBatchNode creates a node that processes items in batch.
// The node reads items from the SharedStore (using the key "items" by default),
// processes each item using the provided function, and stores results back
// to the SharedStore (using the key "results" by default).
//
// Parameters:
//   - processFunc: Function to process each item
//   - concurrent: If true, items are processed concurrently using a worker pool
//   - opts: Additional node options (e.g., WithMaxRetries, WithWait)
//
// Example:
//
//	processFunc := func(ctx context.Context, item any) (any, error) {
//	    // Process the item
//	    return processedItem, nil
//	}
//	node := flyt.NewBatchNode(processFunc, true)
func NewBatchNode(processFunc BatchProcessFunc, concurrent bool, opts ...NodeOption) Node {
	baseOpts := append([]NodeOption{}, opts...)
	return &batchNode{
		BaseNode:    NewBaseNode(baseOpts...),
		processFunc: processFunc,
		concurrent:  concurrent,
		config:      DefaultBatchConfig(),
	}
}

// NewBatchNodeWithKeys creates a batch node with custom keys for items and results.
// This allows you to specify which keys in the SharedStore to read items from
// and write results to, instead of using the default keys.
//
// Parameters:
//   - processFunc: Function to process each item
//   - concurrent: If true, items are processed concurrently
//   - itemsKey: SharedStore key to read items from
//   - resultsKey: SharedStore key to write results to
//   - opts: Additional node options
//
// Example:
//
//	node := flyt.NewBatchNodeWithKeys(processFunc, true, "input_data", "output_data")
func NewBatchNodeWithKeys(processFunc BatchProcessFunc, concurrent bool, itemsKey, resultsKey string, opts ...NodeOption) Node {
	config := DefaultBatchConfig()
	config.ItemsKey = itemsKey
	config.ResultsKey = resultsKey

	baseOpts := append([]NodeOption{}, opts...)
	return &batchNode{
		BaseNode:    NewBaseNode(baseOpts...),
		processFunc: processFunc,
		concurrent:  concurrent,
		config:      config,
	}
}

// NewBatchNodeWithConfig creates a batch node with custom configuration.
// This provides full control over all batch processing settings.
//
// Parameters:
//   - processFunc: Function to process each item
//   - concurrent: If true, items are processed concurrently
//   - config: Custom batch configuration
//   - opts: Additional node options
//
// Example:
//
//	config := &flyt.BatchConfig{
//	    MaxBatchSize:   500,
//	    MaxConcurrency: 20,
//	    ItemsKey:       "tasks",
//	    ResultsKey:     "completed_tasks",
//	}
//	node := flyt.NewBatchNodeWithConfig(processFunc, true, config)
func NewBatchNodeWithConfig(processFunc BatchProcessFunc, concurrent bool, config *BatchConfig, opts ...NodeOption) Node {
	baseOpts := append([]NodeOption{}, opts...)
	return &batchNode{
		BaseNode:    NewBaseNode(baseOpts...),
		processFunc: processFunc,
		concurrent:  concurrent,
		config:      config,
	}
}

type batchNode struct {
	*BaseNode
	processFunc BatchProcessFunc
	concurrent  bool
	config      *BatchConfig
}

func (n *batchNode) Prep(ctx context.Context, shared *SharedStore) (any, error) {
	// Use configured key or fall back to common keys
	keysToCheck := []string{}
	if n.config != nil && n.config.ItemsKey != "" {
		keysToCheck = []string{n.config.ItemsKey}
	} else {
		keysToCheck = []string{KeyItems, "data", "batch"}
	}

	for _, key := range keysToCheck {
		if val, ok := shared.Get(key); ok {
			return val, nil
		}
	}

	return nil, fmt.Errorf("batchNode: prep failed: no batch data found in shared store (looked for: %v)",
		keysToCheck)
}

func (n *batchNode) Exec(ctx context.Context, prepResult any) (any, error) {
	// Convert to slice
	items := ToSlice(prepResult)

	// Validate batch size
	if n.config != nil && n.config.MaxBatchSize > 0 && len(items) > n.config.MaxBatchSize {
		return nil, fmt.Errorf("batchNode: exec failed: batch size %d exceeds maximum %d", len(items), n.config.MaxBatchSize)
	}

	if len(items) == 0 {
		return []any{}, nil
	}

	results := make([]any, len(items))

	if n.concurrent {
		// Process concurrently with worker pool
		maxWorkers := 10
		if n.config != nil && n.config.MaxConcurrency > 0 {
			maxWorkers = n.config.MaxConcurrency
		}

		pool := NewWorkerPool(maxWorkers)
		defer pool.Close()

		errors := make([]error, len(items))
		var mu sync.Mutex

		for i, item := range items {
			idx, itm := i, item // Capture loop variables
			pool.Submit(func() {
				// Check context
				if ctx.Err() != nil {
					mu.Lock()
					errors[idx] = fmt.Errorf("batch item %d: context cancelled: %w", idx, ctx.Err())
					mu.Unlock()
					return
				}

				result, err := n.processFunc(ctx, itm)
				mu.Lock()
				results[idx] = result
				errors[idx] = err
				mu.Unlock()
			})
		}

		pool.Wait()

		// Collect all errors
		var batchErrors []error
		for _, err := range errors {
			if err != nil {
				batchErrors = append(batchErrors, err)
			}
		}

		if len(batchErrors) > 0 {
			return nil, &BatchError{Errors: batchErrors}
		}
	} else {
		// Process sequentially
		for i, item := range items {
			// Check context
			if err := ctx.Err(); err != nil {
				return nil, fmt.Errorf("batchNode: exec cancelled at item %d: %w", i, err)
			}

			result, err := n.processFunc(ctx, item)
			if err != nil {
				return nil, fmt.Errorf("batch item %d: process failed: %w", i, err)
			}
			results[i] = result
		}
	}

	return results, nil
}

func (n *batchNode) Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error) {
	resultsKey := KeyResults
	if n.config != nil && n.config.ResultsKey != "" {
		resultsKey = n.config.ResultsKey
	}
	shared.Set(resultsKey, execResult)
	return DefaultAction, nil
}

// FlowInputs holds input parameters for a flow iteration in batch processing.
// These parameters are merged into each flow's isolated SharedStore,
// allowing each flow instance to have its own set of input data.
//
// Example:
//
//	inputs := flyt.FlowInputs{
//	    "user_id": 123,
//	    "action": "process",
//	    "priority": "high",
//	}
type FlowInputs map[string]any

// BatchFlowFunc returns input parameters for each flow iteration in batch processing.
// This function is called during the Prep phase to determine how many flow instances
// to run and what parameters each should receive.
//
// The function receives the parent flow's SharedStore and should return a slice
// of FlowInputs, where each element represents parameters for one flow iteration.
type BatchFlowFunc func(ctx context.Context, shared *SharedStore) ([]FlowInputs, error)

// NewBatchFlow creates a flow that runs multiple times with different parameters.
// Each iteration gets its own isolated SharedStore with merged parameters.
//
// Important: The flowFactory must create new flow instances for concurrent
// execution to avoid race conditions. Do not reuse flow instances.
//
// Parameters:
//   - flowFactory: Function that creates new flow instances
//   - batchFunc: Function that returns parameters for each iteration
//   - concurrent: If true, flows run concurrently
//
// Example:
//
//	flowFactory := func() *flyt.Flow {
//	    // Create and return a new flow instance
//	    return flyt.NewFlow(startNode)
//	}
//
//	batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
//	    users, _ := shared.Get("users")
//	    var inputs []flyt.FlowInputs
//	    for _, user := range users.([]User) {
//	        inputs = append(inputs, flyt.FlowInputs{"user": user})
//	    }
//	    return inputs, nil
//	}
//
//	batchFlow := flyt.NewBatchFlow(flowFactory, batchFunc, true)
func NewBatchFlow(flowFactory FlowFactory, batchFunc BatchFlowFunc, concurrent bool) *Flow {
	batchNode := &batchFlowNode{
		BaseNode:    NewBaseNode(),
		flowFactory: flowFactory,
		batchFunc:   batchFunc,
		concurrent:  concurrent,
		config:      DefaultBatchConfig(),
	}
	return NewFlow(batchNode)
}

// NewBatchFlowWithCountKey creates a batch flow with a custom key for storing the batch count.
// After execution, the number of flows that were run is stored in the SharedStore
// using the specified key instead of the default "batch_count" key.
//
// Parameters:
//   - flowFactory: Function that creates new flow instances
//   - batchFunc: Function that returns parameters for each iteration
//   - concurrent: If true, flows run concurrently
//   - countKey: SharedStore key to store the batch count
//
// Example:
//
//	batchFlow := flyt.NewBatchFlowWithCountKey(flowFactory, batchFunc, true, "processed_count")
//	// After execution, retrieve count with: count, _ := shared.Get("processed_count")
func NewBatchFlowWithCountKey(flowFactory FlowFactory, batchFunc BatchFlowFunc, concurrent bool, countKey string) *Flow {
	config := DefaultBatchConfig()
	config.BatchCountKey = countKey

	batchNode := &batchFlowNode{
		BaseNode:    NewBaseNode(),
		flowFactory: flowFactory,
		batchFunc:   batchFunc,
		concurrent:  concurrent,
		config:      config,
	}
	return NewFlow(batchNode)
}

// NewBatchFlowWithConfig creates a batch flow with custom configuration.
// This provides full control over batch flow execution settings.
//
// Parameters:
//   - flowFactory: Function that creates new flow instances
//   - batchFunc: Function that returns parameters for each iteration
//   - concurrent: If true, flows run concurrently
//   - config: Custom batch configuration
//
// Example:
//
//	config := &flyt.BatchConfig{
//	    MaxBatchSize:   100,      // Limit to 100 flows
//	    MaxConcurrency: 5,        // Run max 5 flows concurrently
//	    BatchCountKey:  "total",  // Store count in "total" key
//	}
//	batchFlow := flyt.NewBatchFlowWithConfig(flowFactory, batchFunc, true, config)
func NewBatchFlowWithConfig(flowFactory FlowFactory, batchFunc BatchFlowFunc, concurrent bool, config *BatchConfig) *Flow {
	batchNode := &batchFlowNode{
		BaseNode:    NewBaseNode(),
		flowFactory: flowFactory,
		batchFunc:   batchFunc,
		concurrent:  concurrent,
		config:      config,
	}
	return NewFlow(batchNode)
}

type batchFlowNode struct {
	*BaseNode
	flowFactory FlowFactory
	batchFunc   BatchFlowFunc
	concurrent  bool
	config      *BatchConfig
}

func (n *batchFlowNode) Prep(ctx context.Context, shared *SharedStore) (any, error) {
	// Get batch parameters during prep phase
	batchParams, err := n.batchFunc(ctx, shared)
	if err != nil {
		return nil, fmt.Errorf("batch func failed: %w", err)
	}

	// Return both params and shared data as prepResult
	return map[string]any{
		"batchParams": batchParams,
		"sharedData":  shared.GetAll(),
	}, nil
}

func (n *batchFlowNode) Exec(ctx context.Context, prepResult any) (any, error) {
	// Extract data from prepResult
	data, ok := prepResult.(map[string]any)
	if !ok {
		return nil, fmt.Errorf("batchFlowNode: exec failed: invalid prepResult type %T, expected map[string]any", prepResult)
	}

	batchParams, ok := data["batchParams"].([]FlowInputs)
	if !ok {
		return nil, fmt.Errorf("batchFlowNode: exec failed: invalid batchParams type in prepResult")
	}

	sharedData, ok := data["sharedData"].(map[string]any)
	if !ok {
		return nil, fmt.Errorf("batchFlowNode: exec failed: invalid sharedData type in prepResult")
	}

	// Validate batch size
	if n.config != nil && n.config.MaxBatchSize > 0 && len(batchParams) > n.config.MaxBatchSize {
		return nil, fmt.Errorf("batchFlowNode: exec failed: batch size %d exceeds maximum %d", len(batchParams), n.config.MaxBatchSize)
	}

	if len(batchParams) == 0 {
		return 0, nil
	}

	if n.concurrent {
		// Run flows concurrently with worker pool
		maxWorkers := 10
		if n.config != nil && n.config.MaxConcurrency > 0 {
			maxWorkers = n.config.MaxConcurrency
		}

		pool := NewWorkerPool(maxWorkers)
		defer pool.Close()

		errors := make([]error, len(batchParams))
		var errMu sync.Mutex
		hasError := false

		for i, params := range batchParams {
			idx, p := i, params // Capture loop variables
			sd := sharedData    // Capture shared data
			pool.Submit(func() {
				// Check context
				if ctx.Err() != nil {
					errMu.Lock()
					errors[idx] = fmt.Errorf("batchFlowNode: flow %d cancelled: %w", idx, ctx.Err())
					hasError = true
					errMu.Unlock()
					return
				}

				// Create a new flow instance for concurrent execution
				flow := n.flowFactory()

				// Create isolated shared store
				localShared := NewSharedStore()

				// Copy shared data
				localShared.Merge(sd)

				// Merge params
				localShared.Merge(p)

				if err := flow.Run(ctx, localShared); err != nil {
					errMu.Lock()
					errors[idx] = fmt.Errorf("batchFlowNode: flow %d failed: %w", idx, err)
					hasError = true
					errMu.Unlock()
				}
			})
		}

		pool.Wait()

		if hasError {
			// Collect non-nil errors
			var batchErrors []error
			for _, err := range errors {
				if err != nil {
					batchErrors = append(batchErrors, err)
				}
			}
			return nil, &BatchError{Errors: batchErrors}
		}
	} else {
		// Run flows sequentially
		for i, params := range batchParams {
			// Check context
			if err := ctx.Err(); err != nil {
				return nil, fmt.Errorf("batchFlowNode: exec cancelled at flow %d: %w", i, err)
			}

			// Create a new flow instance for each iteration
			flow := n.flowFactory()

			// Create isolated shared store for each iteration
			iterShared := NewSharedStore()
			iterShared.Merge(sharedData)
			iterShared.Merge(params)

			if err := flow.Run(ctx, iterShared); err != nil {
				return nil, fmt.Errorf("batchFlowNode: flow %d failed: %w", i, err)
			}
		}
	}

	return len(batchParams), nil
}

func (n *batchFlowNode) Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error) {
	if count, ok := execResult.(int); ok {
		countKey := KeyBatchCount
		if n.config != nil && n.config.BatchCountKey != "" {
			countKey = n.config.BatchCountKey
		}
		shared.Set(countKey, count)
	}
	return DefaultAction, nil
}



================================================
FILE: batch_test.go
================================================
package flyt

import (
	"context"
	"errors"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"
)

// TestBatchErrorAggregation tests the BatchError type
func TestBatchErrorAggregation(t *testing.T) {
	// Test empty errors
	be := &BatchError{Errors: []error{}}
	if be.Error() != "batch: no errors recorded" {
		t.Errorf("unexpected error message: %s", be.Error())
	}

	// Test single error
	be = &BatchError{Errors: []error{errors.New("test error")}}
	expected := "batch: test error"
	if be.Error() != expected {
		t.Errorf("expected %q, got %q", expected, be.Error())
	}

	// Test multiple errors
	be = &BatchError{
		Errors: []error{
			errors.New("error 1"),
			errors.New("error 2"),
			errors.New("error 3"),
		},
	}
	expected = "batch: 3 errors occurred, first: error 1"
	if be.Error() != expected {
		t.Errorf("expected %q, got %q", expected, be.Error())
	}
}

// TestBatchNodeValidation tests batch node validation
func TestBatchNodeValidation(t *testing.T) {
	processFunc := func(ctx context.Context, item any) (any, error) {
		return item, nil
	}

	config := &BatchConfig{
		MaxBatchSize: 5,
	}

	node := NewBatchNodeWithConfig(processFunc, false, config)
	shared := NewSharedStore()

	// Test exceeding max batch size
	items := make([]int, 10)
	for i := range items {
		items[i] = i
	}
	shared.Set("items", items)

	ctx := context.Background()
	_, err := Run(ctx, node, shared)
	if err == nil {
		t.Error("expected batch size validation error")
	}

	expectedErr := "batchNode: exec failed: batch size 10 exceeds maximum 5"
	if err.Error() != fmt.Sprintf("run: exec failed after 1 retries: %s", expectedErr) {
		t.Errorf("unexpected error: %v", err)
	}
}

// TestBatchNodeConcurrency tests concurrent batch processing
func TestBatchNodeConcurrency(t *testing.T) {
	var counter int32
	var maxConcurrent int32

	processFunc := func(ctx context.Context, item any) (any, error) {
		current := atomic.AddInt32(&counter, 1)
		defer atomic.AddInt32(&counter, -1)

		// Track max concurrent executions
		for {
			max := atomic.LoadInt32(&maxConcurrent)
			if current <= max || atomic.CompareAndSwapInt32(&maxConcurrent, max, current) {
				break
			}
		}

		// Simulate work
		time.Sleep(10 * time.Millisecond)
		return item, nil
	}

	config := &BatchConfig{
		MaxConcurrency: 3,
	}

	node := NewBatchNodeWithConfig(processFunc, true, config)
	shared := NewSharedStore()
	shared.Set("items", []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10})

	ctx := context.Background()
	_, err := Run(ctx, node, shared)
	if err != nil {
		t.Errorf("unexpected error: %v", err)
	}

	// Check max concurrency was respected
	if maxConcurrent > 3 {
		t.Errorf("max concurrency exceeded: %d > 3", maxConcurrent)
	}

	// Check results
	results, _ := shared.Get("results")
	if results == nil {
		t.Error("results not found")
	}
}

// TestBatchNodeSequential tests sequential batch processing
func TestBatchNodeSequential(t *testing.T) {
	var order []int
	var mu sync.Mutex

	processFunc := func(ctx context.Context, item any) (any, error) {
		mu.Lock()
		order = append(order, item.(int))
		mu.Unlock()
		return item, nil
	}

	node := NewBatchNode(processFunc, false) // sequential
	shared := NewSharedStore()
	shared.Set("items", []int{1, 2, 3, 4, 5})

	ctx := context.Background()
	_, err := Run(ctx, node, shared)
	if err != nil {
		t.Errorf("unexpected error: %v", err)
	}

	// Check order is preserved
	for i, v := range order {
		if v != i+1 {
			t.Errorf("order[%d]: expected %d, got %d", i, i+1, v)
		}
	}
}

// TestBatchNodeCustomKeys tests batch node with custom keys
func TestBatchNodeCustomKeys(t *testing.T) {
	processFunc := func(ctx context.Context, item any) (any, error) {
		return fmt.Sprintf("processed_%v", item), nil
	}

	// Create batch node with custom keys
	node := NewBatchNodeWithKeys(processFunc, false, "my_items", "my_results")

	shared := NewSharedStore()
	shared.Set("my_items", []string{"a", "b", "c"})

	ctx := context.Background()
	_, err := Run(ctx, node, shared)
	if err != nil {
		t.Errorf("unexpected error: %v", err)
	}

	// Check results are stored with custom key
	results, ok := shared.Get("my_results")
	if !ok {
		t.Error("results not found with custom key")
	}

	resultSlice, ok := results.([]any)
	if !ok || len(resultSlice) != 3 {
		t.Error("unexpected results format")
	}

	// Verify default keys were not used
	if _, ok := shared.Get(KeyResults); ok {
		t.Error("results should not be stored with default key")
	}
}

// TestBatchFlowConcurrency tests concurrent batch flow execution
func TestBatchFlowConcurrency(t *testing.T) {
	var executionCount int32

	// Factory creates new flow instances
	flowFactory := func() *Flow {
		node := &CounterNode{
			BaseNode: NewBaseNode(),
			counter:  &executionCount,
		}
		return NewFlow(node)
	}

	// Batch function returns parameters for each iteration
	batchFunc := func(ctx context.Context, shared *SharedStore) ([]FlowInputs, error) {
		params := make([]FlowInputs, 5)
		for i := range params {
			params[i] = FlowInputs{"index": i}
		}
		return params, nil
	}

	config := &BatchConfig{
		MaxConcurrency: 3,
	}

	batchFlow := NewBatchFlowWithConfig(flowFactory, batchFunc, true, config)
	shared := NewSharedStore()
	ctx := context.Background()

	err := batchFlow.Run(ctx, shared)
	if err != nil {
		t.Errorf("unexpected error: %v", err)
	}

	// Check all flows executed
	if atomic.LoadInt32(&executionCount) != 5 {
		t.Errorf("expected 5 executions, got %d", executionCount)
	}

	// Check batch count was stored
	count, ok := shared.Get(KeyBatchCount)
	if !ok {
		t.Error("batch_count not found in shared store")
	}
	if count != 5 {
		t.Errorf("expected batch_count 5, got %v", count)
	}
}

// TestBatchFlowCustomCountKey tests batch flow with custom count key
func TestBatchFlowCustomCountKey(t *testing.T) {
	// Factory creates new flow instances
	flowFactory := func() *Flow {
		node := &TestNode{
			BaseNode: NewBaseNode(),
			name:     "test",
			action:   DefaultAction,
		}
		return NewFlow(node)
	}

	// Batch function returns parameters
	batchFunc := func(ctx context.Context, shared *SharedStore) ([]FlowInputs, error) {
		return []FlowInputs{
			{"id": 1},
			{"id": 2},
			{"id": 3},
		}, nil
	}

	// Create batch flow with custom count key
	batchFlow := NewBatchFlowWithCountKey(flowFactory, batchFunc, false, "my_batch_count")

	shared := NewSharedStore()
	ctx := context.Background()

	err := batchFlow.Run(ctx, shared)
	if err != nil {
		t.Errorf("unexpected error: %v", err)
	}

	// Check custom count key was used
	count, ok := shared.Get("my_batch_count")
	if !ok {
		t.Error("custom count key not found in shared store")
	}
	if count != 3 {
		t.Errorf("expected count 3, got %v", count)
	}

	// Verify default key was not used
	if _, ok := shared.Get(KeyBatchCount); ok {
		t.Error("count should not be stored with default key")
	}
}

// CounterNode counts executions
type CounterNode struct {
	*BaseNode
	counter *int32
}

func (n *CounterNode) Exec(ctx context.Context, prepResult any) (any, error) {
	atomic.AddInt32(n.counter, 1)
	return nil, nil
}

// BenchmarkBatchNodeProcessing benchmarks batch processing
func BenchmarkBatchNodeProcessing(b *testing.B) {
	processFunc := func(ctx context.Context, item any) (any, error) {
		// Simulate some work
		time.Sleep(time.Microsecond)
		return item, nil
	}

	node := NewBatchNode(processFunc, true)
	shared := NewSharedStore()

	// Create test data
	items := make([]int, 100)
	for i := range items {
		items[i] = i
	}
	shared.Set("items", items)

	ctx := context.Background()

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		_, err := Run(ctx, node, shared)
		if err != nil {
			b.Fatal(err)
		}
	}
}



================================================
FILE: flyt.go
================================================
// Package flyt is a minimalist workflow framework for Go, inspired by Pocket Flow.
// It provides a simple graph-based abstraction for orchestrating tasks.
//
// Thread Safety:
// When using concurrent batch operations, ensure that your Node implementations
// are thread-safe. The framework provides SharedStore for safe concurrent access
// to shared data.
//
// Example:
//
//	// Define a simple node
//	type PrintNode struct {
//	    *flyt.BaseNode
//	}
//
//	func (n *PrintNode) Exec(ctx context.Context, prepResult any) (any, error) {
//	    fmt.Println("Hello from node!")
//	    return nil, nil
//	}
//
//	// Create and run a flow
//	node := &PrintNode{BaseNode: flyt.NewBaseNode()}
//	shared := flyt.NewSharedStore()
//
//	ctx := context.Background()
//	action, err := flyt.Run(ctx, node, shared)
//	if err != nil {
//	    log.Fatal(err)
//	}
package flyt

import (
	"context"
	"encoding/json"
	"fmt"
	"reflect"
	"sync"
	"time"
)

// SharedStore provides thread-safe access to shared data across nodes in a flow.
// It acts as a key-value store that can be safely accessed by multiple goroutines
// during concurrent batch processing.
//
// Example:
//
//	shared := flyt.NewSharedStore()
//	shared.Set("user_id", 123)
//	shared.Set("config", map[string]any{"timeout": 30})
//
//	if val, ok := shared.Get("user_id"); ok {
//	    userID := val.(int)
//	    // Use userID
//	}
type SharedStore struct {
	mu   sync.RWMutex
	data map[string]any
}

// NewSharedStore creates a new thread-safe shared store.
// The store is initialized empty and ready for use.
func NewSharedStore() *SharedStore {
	return &SharedStore{
		data: make(map[string]any),
	}
}

// Get retrieves a value from the store by key.
// Returns the value and true if the key exists, or nil and false if not found.
// This method is safe for concurrent access.
func (s *SharedStore) Get(key string) (any, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	val, ok := s.data[key]
	return val, ok
}

// Set stores a value in the store with the given key.
// If the key already exists, its value is overwritten.
// This method is safe for concurrent access.
func (s *SharedStore) Set(key string, value any) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.data[key] = value
}

// GetAll returns a copy of all data in the store.
// The returned map is a shallow copy and can be safely modified
// without affecting the store's internal data.
// This method is safe for concurrent access.
func (s *SharedStore) GetAll() map[string]any {
	s.mu.RLock()
	defer s.mu.RUnlock()
	copy := make(map[string]any, len(s.data))
	for k, v := range s.data {
		copy[k] = v
	}
	return copy
}

// Merge merges another map into the store.
// Existing keys are overwritten with values from the provided map.
// If the provided map is nil, this method does nothing.
// This method is safe for concurrent access.
func (s *SharedStore) Merge(data map[string]any) {
	if data == nil {
		return
	}
	s.mu.Lock()
	defer s.mu.Unlock()
	for k, v := range data {
		s.data[k] = v
	}
}

// Has checks if a key exists in the store.
// This method is safe for concurrent access.
func (s *SharedStore) Has(key string) bool {
	s.mu.RLock()
	defer s.mu.RUnlock()
	_, ok := s.data[key]
	return ok
}

// Delete removes a key from the store.
// This method is safe for concurrent access.
func (s *SharedStore) Delete(key string) {
	s.mu.Lock()
	defer s.mu.Unlock()
	delete(s.data, key)
}

// Clear removes all keys from the store.
// This method is safe for concurrent access.
func (s *SharedStore) Clear() {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.data = make(map[string]any)
}

// Keys returns all keys in the store.
// The returned slice is a snapshot and can be safely modified
// without affecting the store's internal data.
// This method is safe for concurrent access.
func (s *SharedStore) Keys() []string {
	s.mu.RLock()
	defer s.mu.RUnlock()
	keys := make([]string, 0, len(s.data))
	for k := range s.data {
		keys = append(keys, k)
	}
	return keys
}

// Len returns the number of items in the store.
// This method is safe for concurrent access.
func (s *SharedStore) Len() int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return len(s.data)
}

// GetString retrieves a string value from the store.
// Returns empty string if the key doesn't exist or the value is not a string.
// This method is safe for concurrent access.
func (s *SharedStore) GetString(key string) string {
	val, ok := s.Get(key)
	if !ok {
		return ""
	}
	str, _ := val.(string)
	return str
}

// GetStringOr retrieves a string value from the store.
// Returns the provided default value if the key doesn't exist or the value is not a string.
// This method is safe for concurrent access.
func (s *SharedStore) GetStringOr(key string, defaultVal string) string {
	val, ok := s.Get(key)
	if !ok {
		return defaultVal
	}
	str, ok := val.(string)
	if !ok {
		return defaultVal
	}
	return str
}

// GetInt retrieves an int value from the store.
// Returns 0 if the key doesn't exist or the value cannot be converted to int.
// Supports conversion from int, int8, int16, int32, int64, uint, uint8, uint16, uint32, uint64, and float types.
// This method is safe for concurrent access.
func (s *SharedStore) GetInt(key string) int {
	return s.GetIntOr(key, 0)
}

// GetIntOr retrieves an int value from the store.
// Returns the provided default value if the key doesn't exist or the value cannot be converted to int.
// Supports conversion from various numeric types.
// This method is safe for concurrent access.
func (s *SharedStore) GetIntOr(key string, defaultVal int) int {
	val, ok := s.Get(key)
	if !ok {
		return defaultVal
	}

	switch v := val.(type) {
	case int:
		return v
	case int8:
		return int(v)
	case int16:
		return int(v)
	case int32:
		return int(v)
	case int64:
		return int(v)
	case uint:
		return int(v)
	case uint8:
		return int(v)
	case uint16:
		return int(v)
	case uint32:
		return int(v)
	case uint64:
		return int(v)
	case float32:
		return int(v)
	case float64:
		return int(v)
	default:
		return defaultVal
	}
}

// GetFloat64 retrieves a float64 value from the store.
// Returns 0.0 if the key doesn't exist or the value cannot be converted to float64.
// Supports conversion from int, float32, and other numeric types.
// This method is safe for concurrent access.
func (s *SharedStore) GetFloat64(key string) float64 {
	return s.GetFloat64Or(key, 0.0)
}

// GetFloat64Or retrieves a float64 value from the store.
// Returns the provided default value if the key doesn't exist or the value cannot be converted to float64.
// Supports conversion from various numeric types.
// This method is safe for concurrent access.
func (s *SharedStore) GetFloat64Or(key string, defaultVal float64) float64 {
	val, ok := s.Get(key)
	if !ok {
		return defaultVal
	}

	switch v := val.(type) {
	case float64:
		return v
	case float32:
		return float64(v)
	case int:
		return float64(v)
	case int8:
		return float64(v)
	case int16:
		return float64(v)
	case int32:
		return float64(v)
	case int64:
		return float64(v)
	case uint:
		return float64(v)
	case uint8:
		return float64(v)
	case uint16:
		return float64(v)
	case uint32:
		return float64(v)
	case uint64:
		return float64(v)
	default:
		return defaultVal
	}
}

// GetBool retrieves a bool value from the store.
// Returns false if the key doesn't exist or the value is not a bool.
// This method is safe for concurrent access.
func (s *SharedStore) GetBool(key string) bool {
	return s.GetBoolOr(key, false)
}

// GetBoolOr retrieves a bool value from the store.
// Returns the provided default value if the key doesn't exist or the value is not a bool.
// This method is safe for concurrent access.
func (s *SharedStore) GetBoolOr(key string, defaultVal bool) bool {
	val, ok := s.Get(key)
	if !ok {
		return defaultVal
	}
	b, ok := val.(bool)
	if !ok {
		return defaultVal
	}
	return b
}

// GetSlice retrieves a []any slice from the store.
// Returns nil if the key doesn't exist or the value is not a slice.
// This method is safe for concurrent access.
func (s *SharedStore) GetSlice(key string) []any {
	return s.GetSliceOr(key, nil)
}

// GetSliceOr retrieves a []any slice from the store.
// Returns the provided default value if the key doesn't exist or the value is not a slice.
// Uses ToSlice to convert various slice types to []any.
// This method is safe for concurrent access.
func (s *SharedStore) GetSliceOr(key string, defaultVal []any) []any {
	val, ok := s.Get(key)
	if !ok {
		return defaultVal
	}

	// Use ToSlice for conversion which handles various slice types
	if val == nil {
		return defaultVal
	}

	// Check if it's already []any
	if slice, ok := val.([]any); ok {
		return slice
	}

	// Try to convert using reflection
	result := ToSlice(val)
	if len(result) == 1 && result[0] == val {
		// ToSlice wrapped a non-slice value, so this wasn't actually a slice
		return defaultVal
	}
	return result
}

// GetMap retrieves a map[string]any from the store.
// Returns nil if the key doesn't exist or the value is not a map[string]any.
// This method is safe for concurrent access.
func (s *SharedStore) GetMap(key string) map[string]any {
	return s.GetMapOr(key, nil)
}

// GetMapOr retrieves a map[string]any from the store.
// Returns the provided default value if the key doesn't exist or the value is not a map[string]any.
// This method is safe for concurrent access.
func (s *SharedStore) GetMapOr(key string, defaultVal map[string]any) map[string]any {
	val, ok := s.Get(key)
	if !ok {
		return defaultVal
	}
	m, ok := val.(map[string]any)
	if !ok {
		return defaultVal
	}
	return m
}

// Bind binds a value from the store to a struct using JSON marshaling/unmarshaling.
// This allows for easy conversion of complex types stored in the SharedStore.
// The destination must be a pointer to the target struct.
// Returns an error if the key is not found or binding fails.
// This method is safe for concurrent access.
//
// Example:
//
//	type User struct {
//	    ID   int    `json:"id"`
//	    Name string `json:"name"`
//	}
//	var user User
//	err := shared.Bind("user", &user)
func (s *SharedStore) Bind(key string, dest any) error {
	val, ok := s.Get(key)
	if !ok {
		return fmt.Errorf("key %q not found in shared store", key)
	}

	// Check if dest is a pointer
	rv := reflect.ValueOf(dest)
	if rv.Kind() != reflect.Ptr || rv.IsNil() {
		return fmt.Errorf("destination must be a non-nil pointer")
	}

	// If val is already the correct type, assign directly
	valType := reflect.TypeOf(val)
	destType := rv.Type().Elem()
	if valType == destType {
		rv.Elem().Set(reflect.ValueOf(val))
		return nil
	}

	// Otherwise use JSON as intermediate format
	jsonBytes, err := json.Marshal(val)
	if err != nil {
		return fmt.Errorf("failed to marshal value: %w", err)
	}

	if err := json.Unmarshal(jsonBytes, dest); err != nil {
		return fmt.Errorf("failed to unmarshal to destination: %w", err)
	}

	return nil
}

// MustBind is like Bind but panics if binding fails.
// Use this only when binding failure should be considered a programming error.
// This method is safe for concurrent access.
//
// Example:
//
//	var config Config
//	shared.MustBind("config", &config)  // Panics if binding fails
func (s *SharedStore) MustBind(key string, dest any) {
	if err := s.Bind(key, dest); err != nil {
		panic(fmt.Sprintf("SharedStore.MustBind failed: %v", err))
	}
}

// Action represents the next action to take after a node executes.
// Actions are used to determine flow control in workflows, allowing
// nodes to direct execution to different paths based on their results.
//
// Example:
//
//	const (
//	    ActionSuccess Action = "success"
//	    ActionRetry   Action = "retry"
//	    ActionFail    Action = "fail"
//	)
type Action string

const (
	// DefaultAction is the default action if none is specified.
	// Flows use this when a node doesn't explicitly return an action.
	DefaultAction Action = "default"

	// KeyItems is the shared store key for items to be processed.
	// Batch nodes look for items under this key by default.
	KeyItems = "items"

	// KeyResults is the shared store key for processing results.
	// Batch nodes store their results under this key by default.
	KeyResults = "results"

	// KeyBatchCount is the shared store key for batch count.
	// Batch flows store the number of iterations under this key.
	KeyBatchCount = "batch_count"
)

// Node is the interface that all nodes must implement.
//
// Important: Nodes should not be shared across concurrent flow executions.
// If you need to run the same logic concurrently, create separate node instances.
type Node interface {
	// Prep reads and preprocesses data from shared store
	Prep(ctx context.Context, shared *SharedStore) (any, error)

	// Exec executes the main logic with optional retries
	Exec(ctx context.Context, prepResult any) (any, error)

	// Post processes results and writes back to shared store
	Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error)
}

// BaseNode provides a base implementation of the Node interface.
// It includes common functionality like retry configuration and default
// implementations of Prep, Exec, and Post methods that can be overridden.
//
// BaseNode is designed to be embedded in custom node implementations:
//
//	type MyNode struct {
//	    *flyt.BaseNode
//	    // custom fields
//	}
//
//	func (n *MyNode) Exec(ctx context.Context, prepResult any) (any, error) {
//	    // custom implementation
//	}
type BaseNode struct {
	mu         sync.RWMutex
	maxRetries int
	wait       time.Duration
}

// NewBaseNode creates a new BaseNode with the provided options.
// By default, maxRetries is set to 1 (no retries) and wait is 0.
//
// Example:
//
//	node := flyt.NewBaseNode(
//	    flyt.WithMaxRetries(3),
//	    flyt.WithWait(time.Second),
//	)
func NewBaseNode(opts ...NodeOption) *BaseNode {
	n := &BaseNode{
		maxRetries: 1,
		wait:       0,
	}

	for _, opt := range opts {
		opt(n)
	}

	return n
}

// NodeOption is a function that configures a BaseNode.
// Options can be passed to NewBaseNode to customize its behavior.
type NodeOption func(*BaseNode)

// WithMaxRetries sets the maximum number of retries for the Exec phase.
// The default is 1 (no retries). Setting this to a value greater than 1
// enables automatic retry on Exec failures.
//
// Example:
//
//	node := flyt.NewBaseNode(flyt.WithMaxRetries(3))
func WithMaxRetries(retries int) NodeOption {
	return func(n *BaseNode) {
		n.maxRetries = retries
	}
}

// WithWait sets the wait duration between retries.
// This only applies when maxRetries is greater than 1.
// The default is 0 (no wait between retries).
//
// Example:
//
//	node := flyt.NewBaseNode(
//	    flyt.WithMaxRetries(3),
//	    flyt.WithWait(time.Second * 2),
//	)
func WithWait(wait time.Duration) NodeOption {
	return func(n *BaseNode) {
		n.wait = wait
	}
}

// GetMaxRetries returns the maximum number of retries configured for this node.
// This method is thread-safe.
func (n *BaseNode) GetMaxRetries() int {
	n.mu.RLock()
	defer n.mu.RUnlock()
	return n.maxRetries
}

// GetWait returns the wait duration between retries configured for this node.
// This method is thread-safe.
func (n *BaseNode) GetWait() time.Duration {
	n.mu.RLock()
	defer n.mu.RUnlock()
	return n.wait
}

// Prep is the default prep implementation that returns nil.
// Override this method in your node implementation to read and preprocess
// data from the SharedStore before execution.
func (n *BaseNode) Prep(ctx context.Context, shared *SharedStore) (any, error) {
	return nil, nil
}

// Exec is the default exec implementation that returns nil.
// This method should be overridden in your node implementation to provide
// the main processing logic.
func (n *BaseNode) Exec(ctx context.Context, prepResult any) (any, error) {
	return nil, nil
}

// Post is the default post implementation that returns DefaultAction.
// Override this method in your node implementation to process results
// and determine the next action in the flow.
func (n *BaseNode) Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error) {
	return DefaultAction, nil
}

// ExecFallback handles errors after all retries are exhausted.
// The default implementation simply returns the error.
// Override this method to provide custom fallback behavior.
func (n *BaseNode) ExecFallback(prepResult any, err error) (any, error) {
	return nil, err
}

// RetryableNode is a node that supports automatic retries on Exec failures.
// Nodes implementing this interface can specify retry behavior through
// GetMaxRetries and GetWait methods.
type RetryableNode interface {
	Node
	GetMaxRetries() int
	GetWait() time.Duration
}

// FallbackNode is a node that supports custom fallback behavior on error.
// When all retries are exhausted, the ExecFallback method is called to
// provide an alternative result or handle the error gracefully.
type FallbackNode interface {
	ExecFallback(prepResult any, err error) (any, error)
}

// Run executes a node with the standard prep->exec->post lifecycle.
// This is the main entry point for executing individual nodes.
//
// The execution flow is:
//  1. Prep: Read and preprocess data from SharedStore
//  2. Exec: Execute main logic with automatic retries if configured
//  3. Post: Process results and write back to SharedStore
//
// If the node implements RetryableNode, the Exec phase will automatically
// retry on failure according to the configured settings.
//
// If the node implements FallbackNode and all retries fail, ExecFallback
// is called to provide alternative handling.
//
// Parameters:
//   - ctx: Context for cancellation and timeouts
//   - node: The node to execute
//   - shared: SharedStore for data exchange
//
// Returns:
//   - Action: The next action to take in the flow
//   - error: Any error that occurred during execution
//
// Example:
//
//	node := &MyNode{BaseNode: flyt.NewBaseNode()}
//	shared := flyt.NewSharedStore()
//	shared.Set("input", "data")
//
//	action, err := flyt.Run(ctx, node, shared)
//	if err != nil {
//	    log.Fatal(err)
//	}
func Run(ctx context.Context, node Node, shared *SharedStore) (Action, error) {
	// Check context before each phase
	if err := ctx.Err(); err != nil {
		return "", fmt.Errorf("run: context cancelled: %w", err)
	}

	// Prep phase
	prepResult, err := node.Prep(ctx, shared)
	if err != nil {
		return "", fmt.Errorf("run: prep failed: %w", err)
	}

	// Check context again
	if err := ctx.Err(); err != nil {
		return "", fmt.Errorf("run: context cancelled after prep: %w", err)
	}

	// Get retry settings if available
	var maxRetries int = 1
	var wait time.Duration = 0

	if retryable, ok := node.(RetryableNode); ok {
		maxRetries = retryable.GetMaxRetries()
		wait = retryable.GetWait()
	}

	// Exec phase with retries
	var execResult any
	var execErr error

	for attempt := 0; attempt < maxRetries; attempt++ {
		// Check context before retry
		if err := ctx.Err(); err != nil {
			return "", fmt.Errorf("run: context cancelled during retry: %w", err)
		}

		if attempt > 0 && wait > 0 {
			select {
			case <-time.After(wait):
				// Continue with retry
			case <-ctx.Done():
				return "", fmt.Errorf("run: context cancelled during wait: %w", ctx.Err())
			}
		}

		execResult, execErr = node.Exec(ctx, prepResult)
		if execErr == nil {
			break
		}
	}

	// Handle exec failure
	if execErr != nil {
		if fallback, ok := node.(FallbackNode); ok {
			execResult, execErr = fallback.ExecFallback(prepResult, execErr)
		}
		if execErr != nil {
			return "", fmt.Errorf("run: exec failed after %d retries: %w", maxRetries, execErr)
		}
	}

	// Post phase
	action, err := node.Post(ctx, shared, prepResult, execResult)
	if err != nil {
		return "", fmt.Errorf("run: post failed: %w", err)
	}

	if action == "" {
		action = DefaultAction
	}

	return action, nil
}

// Flow represents a workflow of connected nodes.
// A Flow is itself a Node, allowing flows to be nested within other flows.
// Nodes are connected via actions, creating a directed graph of execution.
//
// Example:
//
//	// Create nodes
//	validateNode := &ValidateNode{BaseNode: flyt.NewBaseNode()}
//	processNode := &ProcessNode{BaseNode: flyt.NewBaseNode()}
//	errorNode := &ErrorNode{BaseNode: flyt.NewBaseNode()}
//
//	// Create flow
//	flow := flyt.NewFlow(validateNode)
//	flow.Connect(validateNode, ActionSuccess, processNode)
//	flow.Connect(validateNode, ActionFail, errorNode)
//
//	// Run flow
//	err := flow.Run(ctx, shared)
type Flow struct {
	*BaseNode
	start       Node
	transitions map[Node]map[Action]Node
}

// NewFlow creates a new Flow with a start node.
// The flow begins execution at the start node and follows
// transitions based on the actions returned by each node.
//
// Parameters:
//   - start: The first node to execute in the flow
//
// Example:
//
//	flow := flyt.NewFlow(startNode)
func NewFlow(start Node) *Flow {
	return &Flow{
		BaseNode:    NewBaseNode(),
		start:       start,
		transitions: make(map[Node]map[Action]Node),
	}
}

// Connect adds a transition from one node to another based on an action.
// When the 'from' node returns the specified action, execution continues
// with the 'to' node. Multiple actions can be connected from a single node.
//
// Parameters:
//   - from: The source node
//   - action: The action that triggers this transition
//   - to: The destination node
//
// Example:
//
//	flow.Connect(nodeA, "success", nodeB)
//	flow.Connect(nodeA, "retry", nodeA)  // Self-loop for retry
//	flow.Connect(nodeA, "fail", errorNode)
func (f *Flow) Connect(from Node, action Action, to Node) {
	if f.transitions[from] == nil {
		f.transitions[from] = make(map[Action]Node)
	}
	f.transitions[from][action] = to
}

// Run executes the flow starting from the start node.
// This is a convenience method that wraps the standard Run function.
// The flow executes nodes in sequence based on their action transitions
// until no more transitions are available or an error occurs.
//
// Parameters:
//   - ctx: Context for cancellation and timeouts
//   - shared: SharedStore for data exchange between nodes
//
// Returns:
//   - error: Any error that occurred during flow execution
func (f *Flow) Run(ctx context.Context, shared *SharedStore) error {
	// Use the standard Run function to execute this flow as a node
	_, err := Run(ctx, f, shared)
	return err
}

// Prep implements Node interface for Flow
func (f *Flow) Prep(ctx context.Context, shared *SharedStore) (any, error) {
	// Pass the shared store to Exec
	return shared, nil
}

// Exec orchestrates the flow execution by running nodes in sequence
func (f *Flow) Exec(ctx context.Context, prepResult any) (any, error) {
	// Extract shared store from prepResult
	shared, ok := prepResult.(*SharedStore)
	if !ok {
		return nil, fmt.Errorf("flow: exec failed: invalid prepResult type %T, expected *SharedStore", prepResult)
	}

	if f.start == nil {
		return nil, fmt.Errorf("flow: exec failed: no start node configured")
	}

	current := f.start
	var lastAction Action

	for current != nil {
		// Check context
		if err := ctx.Err(); err != nil {
			return nil, fmt.Errorf("flow: exec cancelled: %w", err)
		}

		// Run the current node using the standard Run function
		action, err := Run(ctx, current, shared)
		if err != nil {
			return nil, err
		}

		lastAction = action

		// Find next node based on action
		if transitions, ok := f.transitions[current]; ok {
			if next, ok := transitions[action]; ok {
				current = next
			} else {
				// No transition for this action, flow ends
				break
			}
		} else {
			// No transitions defined for this node, flow ends
			break
		}
	}

	// Return the last action as the result
	return lastAction, nil
}

// Post implements Node interface for Flow
func (f *Flow) Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error) {
	// Return the last action from the flow execution
	if action, ok := execResult.(Action); ok {
		return action, nil
	}
	return DefaultAction, nil
}

// WorkerPool manages concurrent task execution with a fixed number of workers.
// It provides a simple way to limit concurrency and execute tasks in parallel.
// WorkerPool is used internally by batch processing nodes but can also be
// used directly for custom concurrent operations.
//
// Example:
//
//	pool := flyt.NewWorkerPool(5)
//	defer pool.Close()
//
//	for _, item := range items {
//	    item := item // capture loop variable
//	    pool.Submit(func() {
//	        // Process item
//	    })
//	}
//
//	pool.Wait()
type WorkerPool struct {
	workers int
	tasks   chan func()
	wg      sync.WaitGroup
	done    chan struct{}
}

// NewWorkerPool creates a new worker pool with the specified number of workers.
// If workers is less than or equal to 0, it defaults to 1.
// The pool starts workers immediately and is ready to accept tasks.
//
// Parameters:
//   - workers: Number of concurrent workers
//
// Returns:
//   - *WorkerPool: A new worker pool ready for use
//
// Remember to call Close() when done to clean up resources.
func NewWorkerPool(workers int) *WorkerPool {
	if workers <= 0 {
		workers = 1
	}

	p := &WorkerPool{
		workers: workers,
		tasks:   make(chan func(), workers*2),
		done:    make(chan struct{}),
	}

	// Start workers
	for i := 0; i < workers; i++ {
		go p.worker()
	}

	return p
}

func (p *WorkerPool) worker() {
	for {
		select {
		case task, ok := <-p.tasks:
			if !ok {
				return
			}
			task()
		case <-p.done:
			return
		}
	}
}

// Submit submits a task to the pool for execution.
// The task will be executed by one of the available workers.
// This method blocks if all workers are busy and the task buffer is full.
//
// Parameters:
//   - task: Function to execute
func (p *WorkerPool) Submit(task func()) {
	p.wg.Add(1)
	p.tasks <- func() {
		defer p.wg.Done()
		task()
	}
}

// Wait waits for all submitted tasks to complete.
// This method blocks until all tasks have finished executing.
func (p *WorkerPool) Wait() {
	p.wg.Wait()
}

// Close closes the worker pool and waits for all workers to finish.
// After calling Close, no new tasks can be submitted.
// This method should be called when the pool is no longer needed
// to properly clean up resources.
func (p *WorkerPool) Close() {
	close(p.done)
	close(p.tasks)
}

// ToSlice converts various types to []any for batch processing.
// This utility function handles common slice types and single values,
// making it easier to work with batch operations.
//
// Supported types:
//   - []any: returned as-is
//   - []string, []int, []float64: converted to []any
//   - []map[string]any: converted to []any
//   - Other slice types: converted using reflection
//   - Single values: wrapped in a slice
//   - nil: returns empty slice
//
// Example:
//
//	items1 := flyt.ToSlice([]string{"a", "b", "c"})  // []any{"a", "b", "c"}
//	items2 := flyt.ToSlice("single")                 // []any{"single"}
//	items3 := flyt.ToSlice(nil)                      // []any{}
func ToSlice(v any) []any {
	if v == nil {
		return []any{}
	}

	switch val := v.(type) {
	case []any:
		return val
	case []string:
		result := make([]any, len(val))
		for i, v := range val {
			result[i] = v
		}
		return result
	case []int:
		result := make([]any, len(val))
		for i, v := range val {
			result[i] = v
		}
		return result
	case []float64:
		result := make([]any, len(val))
		for i, v := range val {
			result[i] = v
		}
		return result
	case []map[string]any:
		result := make([]any, len(val))
		for i, v := range val {
			result[i] = v
		}
		return result
	default:
		// Try reflection for other slice types
		rv := reflect.ValueOf(v)
		if rv.Kind() == reflect.Slice {
			result := make([]any, rv.Len())
			for i := 0; i < rv.Len(); i++ {
				result[i] = rv.Index(i).Interface()
			}
			return result
		}
		return []any{v} // Single item
	}
}

// FlowFactory creates new instances of a flow.
// This is used by batch flow operations to create isolated flow instances
// for concurrent execution. Each call should return a new flow instance
// to avoid race conditions.
//
// Example:
//
//	factory := func() *flyt.Flow {
//	    node1 := &ProcessNode{BaseNode: flyt.NewBaseNode()}
//	    node2 := &SaveNode{BaseNode: flyt.NewBaseNode()}
//
//	    flow := flyt.NewFlow(node1)
//	    flow.Connect(node1, flyt.DefaultAction, node2)
//	    return flow
//	}
type FlowFactory func() *Flow

// CustomNode is a node implementation that uses custom functions
// for Prep, Exec, and Post phases. This allows creating nodes
// without defining new types, useful for simple operations.
//
// Example:
//
//	node := &flyt.CustomNode{
//	    BaseNode: flyt.NewBaseNode(),
//	    execFunc: func(ctx context.Context, prepResult any) (any, error) {
//	        // Process data
//	        return result, nil
//	    },
//	}
type CustomNode struct {
	*BaseNode
	prepFunc         func(context.Context, *SharedStore) (any, error)
	execFunc         func(context.Context, any) (any, error)
	postFunc         func(context.Context, *SharedStore, any, any) (Action, error)
	execFallbackFunc func(any, error) (any, error)
}

// Prep implements Node.Prep by calling the custom prepFunc if provided
func (n *CustomNode) Prep(ctx context.Context, shared *SharedStore) (any, error) {
	if n.prepFunc != nil {
		return n.prepFunc(ctx, shared)
	}
	return n.BaseNode.Prep(ctx, shared)
}

// Exec implements Node.Exec by calling the custom execFunc if provided
func (n *CustomNode) Exec(ctx context.Context, prepResult any) (any, error) {
	if n.execFunc != nil {
		return n.execFunc(ctx, prepResult)
	}
	return n.BaseNode.Exec(ctx, prepResult)
}

// Post implements Node.Post by calling the custom postFunc if provided
func (n *CustomNode) Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error) {
	if n.postFunc != nil {
		return n.postFunc(ctx, shared, prepResult, execResult)
	}
	return n.BaseNode.Post(ctx, shared, prepResult, execResult)
}

// ExecFallback implements FallbackNode.ExecFallback by calling the custom execFallbackFunc if provided
func (n *CustomNode) ExecFallback(prepResult any, err error) (any, error) {
	if n.execFallbackFunc != nil {
		return n.execFallbackFunc(prepResult, err)
	}
	return n.BaseNode.ExecFallback(prepResult, err)
}

// NewNode creates a new node with custom function implementations.
// This is a convenience function for creating nodes without defining new types.
// It accepts both NodeOption (for BaseNode configuration) and CustomNodeOption
// (for custom function implementations).
//
// Parameters:
//   - opts: Mix of NodeOption and CustomNodeOption values
//
// Example:
//
//	node := flyt.NewNode(
//	    flyt.WithMaxRetries(3),
//	    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
//	        // Process data
//	        return processedData, nil
//	    }),
//	    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
//	        shared.Set("result", execResult)
//	        return flyt.DefaultAction, nil
//	    }),
//	)
func NewNode(opts ...any) Node {
	node := &CustomNode{
		BaseNode: NewBaseNode(),
	}

	// Separate options by type
	var customOpts []CustomNodeOption
	var baseOpts []NodeOption

	for _, opt := range opts {
		switch o := opt.(type) {
		case CustomNodeOption:
			customOpts = append(customOpts, o)
		case NodeOption:
			baseOpts = append(baseOpts, o)
		case func(*BaseNode):
			baseOpts = append(baseOpts, NodeOption(o))
		default:
			// Ignore unknown option types
		}
	}

	// Apply base node options first
	for _, opt := range baseOpts {
		opt(node.BaseNode)
	}

	// Apply custom node options
	for _, opt := range customOpts {
		opt.apply(node)
	}

	return node
}

// CustomNodeOption is an option for configuring a CustomNode.
// It allows setting custom implementations for Prep, Exec, and Post methods.
type CustomNodeOption interface {
	apply(*CustomNode)
}

// customNodeOption is the internal implementation of CustomNodeOption
type customNodeOption struct {
	f func(*CustomNode)
}

func (o *customNodeOption) apply(n *CustomNode) {
	o.f(n)
}

// WithPrepFunc sets a custom Prep implementation for a CustomNode.
// The provided function will be called during the Prep phase to read
// and preprocess data from the SharedStore.
//
// Example:
//
//	flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
//	    data, _ := shared.Get("input")
//	    // Preprocess data
//	    return preprocessedData, nil
//	})
func WithPrepFunc(fn func(context.Context, *SharedStore) (any, error)) CustomNodeOption {
	return &customNodeOption{
		f: func(n *CustomNode) {
			n.prepFunc = fn
		},
	}
}

// WithExecFunc sets a custom Exec implementation for a CustomNode.
// The provided function will be called during the Exec phase with
// the result from Prep as input.
//
// Example:
//
//	flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
//	    // Process the data
//	    return processedResult, nil
//	})
func WithExecFunc(fn func(context.Context, any) (any, error)) CustomNodeOption {
	return &customNodeOption{
		f: func(n *CustomNode) {
			n.execFunc = fn
		},
	}
}

// WithPostFunc sets a custom Post implementation for a CustomNode.
// The provided function will be called during the Post phase to process
// results and determine the next action.
//
// Example:
//
//	flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
//	    shared.Set("output", execResult)
//	    if success {
//	        return "success", nil
//	    }
//	    return "retry", nil
//	})
func WithPostFunc(fn func(context.Context, *SharedStore, any, any) (Action, error)) CustomNodeOption {
	return &customNodeOption{
		f: func(n *CustomNode) {
			n.postFunc = fn
		},
	}
}

// WithExecFallbackFunc sets a custom ExecFallback implementation for a CustomNode.
// The provided function will be called when Exec fails after all retries are exhausted.
// This allows for custom error handling or returning a default value.
//
// Example:
//
//	flyt.WithExecFallbackFunc(func(prepResult any, err error) (any, error) {
//	    log.Printf("Exec failed after retries: %v", err)
//	    // Return nil to indicate failure, which can be handled in Post
//	    return nil, nil
//	})
func WithExecFallbackFunc(fn func(any, error) (any, error)) CustomNodeOption {
	return &customNodeOption{
		f: func(n *CustomNode) {
			n.execFallbackFunc = fn
		},
	}
}



================================================
FILE: flyt_test.go
================================================
package flyt

import (
	"context"
	"errors"
	"fmt"
	"reflect"
	"sync"
	"testing"
	"time"
)

// TestSharedStoreConcurrency tests concurrent access to SharedStore
func TestSharedStoreConcurrency(t *testing.T) {
	store := NewSharedStore()
	var wg sync.WaitGroup

	// Concurrent writes
	for i := 0; i < 100; i++ {
		wg.Add(1)
		go func(n int) {
			defer wg.Done()
			store.Set(fmt.Sprintf("key%d", n), n)
		}(i)
	}

	// Concurrent reads
	for i := 0; i < 100; i++ {
		wg.Add(1)
		go func(n int) {
			defer wg.Done()
			store.Get(fmt.Sprintf("key%d", n))
		}(i)
	}

	wg.Wait()

	// Verify all values
	for i := 0; i < 100; i++ {
		val, ok := store.Get(fmt.Sprintf("key%d", i))
		if !ok {
			t.Errorf("key%d not found", i)
		}
		if val != i {
			t.Errorf("key%d: expected %d, got %v", i, i, val)
		}
	}
}

// TestSharedStoreGetAll tests GetAll returns a copy
func TestSharedStoreGetAll(t *testing.T) {
	store := NewSharedStore()
	store.Set("key1", "value1")
	store.Set("key2", "value2")

	// Get all data
	data := store.GetAll()

	// Modify the returned map
	data["key1"] = "modified"
	data["key3"] = "new"

	// Original store should be unchanged
	val, _ := store.Get("key1")
	if val != "value1" {
		t.Errorf("store was modified: expected value1, got %v", val)
	}

	_, ok := store.Get("key3")
	if ok {
		t.Error("store has key3 which should not exist")
	}
}

// TestSharedStoreMerge tests the Merge method
func TestSharedStoreMerge(t *testing.T) {
	store := NewSharedStore()
	store.Set("key1", "value1")
	store.Set("key2", "value2")

	// Merge new data
	newData := map[string]any{
		"key2": "updated",
		"key3": "new",
	}
	store.Merge(newData)

	// Check results
	val1, _ := store.Get("key1")
	if val1 != "value1" {
		t.Errorf("key1: expected value1, got %v", val1)
	}

	val2, _ := store.Get("key2")
	if val2 != "updated" {
		t.Errorf("key2: expected updated, got %v", val2)
	}

	val3, _ := store.Get("key3")
	if val3 != "new" {
		t.Errorf("key3: expected new, got %v", val3)
	}
}

// TestSharedStoreTypeGetters tests all the type-specific getter methods
func TestSharedStoreTypeGetters(t *testing.T) {
	store := NewSharedStore()

	// Set various types
	store.Set("string", "hello")
	store.Set("int", 42)
	store.Set("int64", int64(100))
	store.Set("float32", float32(3.14))
	store.Set("float64", 2.718)
	store.Set("bool", true)
	store.Set("slice", []string{"a", "b", "c"})
	store.Set("map", map[string]any{"name": "test", "value": 123})

	// Test GetString
	if got := store.GetString("string"); got != "hello" {
		t.Errorf("GetString: expected hello, got %v", got)
	}
	if got := store.GetString("notfound"); got != "" {
		t.Errorf("GetString (not found): expected empty string, got %v", got)
	}
	if got := store.GetString("int"); got != "" {
		t.Errorf("GetString (wrong type): expected empty string, got %v", got)
	}

	// Test GetStringOr
	if got := store.GetStringOr("string", "default"); got != "hello" {
		t.Errorf("GetStringOr: expected hello, got %v", got)
	}
	if got := store.GetStringOr("notfound", "default"); got != "default" {
		t.Errorf("GetStringOr (not found): expected default, got %v", got)
	}

	// Test GetInt with numeric conversions
	if got := store.GetInt("int"); got != 42 {
		t.Errorf("GetInt: expected 42, got %v", got)
	}
	if got := store.GetInt("int64"); got != 100 {
		t.Errorf("GetInt (int64): expected 100, got %v", got)
	}
	if got := store.GetInt("float32"); got != 3 {
		t.Errorf("GetInt (float32): expected 3, got %v", got)
	}
	if got := store.GetInt("notfound"); got != 0 {
		t.Errorf("GetInt (not found): expected 0, got %v", got)
	}

	// Test GetIntOr
	if got := store.GetIntOr("int", -1); got != 42 {
		t.Errorf("GetIntOr: expected 42, got %v", got)
	}
	if got := store.GetIntOr("notfound", -1); got != -1 {
		t.Errorf("GetIntOr (not found): expected -1, got %v", got)
	}

	// Test GetFloat64 with numeric conversions
	if got := store.GetFloat64("float64"); got != 2.718 {
		t.Errorf("GetFloat64: expected 2.718, got %v", got)
	}
	if got := store.GetFloat64("float32"); got != float64(float32(3.14)) {
		t.Errorf("GetFloat64 (float32): expected %v, got %v", float64(float32(3.14)), got)
	}
	if got := store.GetFloat64("int"); got != 42.0 {
		t.Errorf("GetFloat64 (int): expected 42.0, got %v", got)
	}
	if got := store.GetFloat64("notfound"); got != 0.0 {
		t.Errorf("GetFloat64 (not found): expected 0.0, got %v", got)
	}

	// Test GetFloat64Or
	if got := store.GetFloat64Or("float64", -1.0); got != 2.718 {
		t.Errorf("GetFloat64Or: expected 2.718, got %v", got)
	}
	if got := store.GetFloat64Or("notfound", -1.0); got != -1.0 {
		t.Errorf("GetFloat64Or (not found): expected -1.0, got %v", got)
	}

	// Test GetBool
	if got := store.GetBool("bool"); got != true {
		t.Errorf("GetBool: expected true, got %v", got)
	}
	if got := store.GetBool("notfound"); got != false {
		t.Errorf("GetBool (not found): expected false, got %v", got)
	}
	if got := store.GetBool("string"); got != false {
		t.Errorf("GetBool (wrong type): expected false, got %v", got)
	}

	// Test GetBoolOr
	if got := store.GetBoolOr("bool", false); got != true {
		t.Errorf("GetBoolOr: expected true, got %v", got)
	}
	if got := store.GetBoolOr("notfound", true); got != true {
		t.Errorf("GetBoolOr (not found): expected true, got %v", got)
	}

	// Test GetSlice
	if got := store.GetSlice("slice"); got == nil || len(got) != 3 {
		t.Errorf("GetSlice: expected slice of length 3, got %v", got)
	}
	if got := store.GetSlice("notfound"); got != nil {
		t.Errorf("GetSlice (not found): expected nil, got %v", got)
	}

	// Test GetSliceOr
	defaultSlice := []any{"default"}
	if got := store.GetSliceOr("slice", defaultSlice); got == nil || len(got) != 3 {
		t.Errorf("GetSliceOr: expected slice of length 3, got %v", got)
	}
	if got := store.GetSliceOr("notfound", defaultSlice); !reflect.DeepEqual(got, defaultSlice) {
		t.Errorf("GetSliceOr (not found): expected %v, got %v", defaultSlice, got)
	}

	// Test GetMap
	if got := store.GetMap("map"); got == nil || got["name"] != "test" {
		t.Errorf("GetMap: expected map with name=test, got %v", got)
	}
	if got := store.GetMap("notfound"); got != nil {
		t.Errorf("GetMap (not found): expected nil, got %v", got)
	}

	// Test GetMapOr
	defaultMap := map[string]any{"default": true}
	if got := store.GetMapOr("map", defaultMap); got == nil || got["name"] != "test" {
		t.Errorf("GetMapOr: expected map with name=test, got %v", got)
	}
	if got := store.GetMapOr("notfound", defaultMap); !reflect.DeepEqual(got, defaultMap) {
		t.Errorf("GetMapOr (not found): expected %v, got %v", defaultMap, got)
	}
}

// TestSharedStoreUtilityMethods tests Has, Delete, Clear, Keys, Len
func TestSharedStoreUtilityMethods(t *testing.T) {
	store := NewSharedStore()

	// Test Has
	store.Set("key1", "value1")
	if !store.Has("key1") {
		t.Error("Has: expected true for existing key")
	}
	if store.Has("notfound") {
		t.Error("Has: expected false for non-existing key")
	}

	// Test Len
	store.Set("key2", "value2")
	store.Set("key3", "value3")
	if got := store.Len(); got != 3 {
		t.Errorf("Len: expected 3, got %v", got)
	}

	// Test Keys
	keys := store.Keys()
	if len(keys) != 3 {
		t.Errorf("Keys: expected 3 keys, got %v", len(keys))
	}
	keyMap := make(map[string]bool)
	for _, k := range keys {
		keyMap[k] = true
	}
	if !keyMap["key1"] || !keyMap["key2"] || !keyMap["key3"] {
		t.Errorf("Keys: missing expected keys, got %v", keys)
	}

	// Test Delete
	store.Delete("key2")
	if store.Has("key2") {
		t.Error("Delete: key2 should be deleted")
	}
	if got := store.Len(); got != 2 {
		t.Errorf("Len after delete: expected 2, got %v", got)
	}

	// Test Clear
	store.Clear()
	if got := store.Len(); got != 0 {
		t.Errorf("Len after clear: expected 0, got %v", got)
	}
	if store.Has("key1") || store.Has("key3") {
		t.Error("Clear: store should be empty")
	}
}

// TestSharedStoreBind tests the Bind and MustBind methods
func TestSharedStoreBind(t *testing.T) {
	store := NewSharedStore()

	// Test struct binding
	type User struct {
		ID   int      `json:"id"`
		Name string   `json:"name"`
		Tags []string `json:"tags"`
	}

	// Store as map
	store.Set("user", map[string]any{
		"id":   123,
		"name": "Alice",
		"tags": []string{"admin", "developer"},
	})

	var user User
	if err := store.Bind("user", &user); err != nil {
		t.Errorf("Bind: unexpected error: %v", err)
	}
	if user.ID != 123 || user.Name != "Alice" || len(user.Tags) != 2 {
		t.Errorf("Bind: incorrect values: %+v", user)
	}

	// Test binding to non-pointer
	var notPointer User
	if err := store.Bind("user", notPointer); err == nil {
		t.Error("Bind: should error on non-pointer")
	}

	// Test binding non-existent key
	var missing User
	if err := store.Bind("missing", &missing); err == nil {
		t.Error("Bind: should error on missing key")
	}

	// Test direct type match
	type Config struct {
		Timeout int
		Debug   bool
	}
	config := Config{Timeout: 30, Debug: true}
	store.Set("config", config)

	var boundConfig Config
	if err := store.Bind("config", &boundConfig); err != nil {
		t.Errorf("Bind (direct type): unexpected error: %v", err)
	}
	if boundConfig.Timeout != 30 || boundConfig.Debug != true {
		t.Errorf("Bind (direct type): incorrect values: %+v", boundConfig)
	}

	// Test MustBind success
	var user2 User
	func() {
		defer func() {
			if r := recover(); r != nil {
				t.Errorf("MustBind: unexpected panic: %v", r)
			}
		}()
		store.MustBind("user", &user2)
	}()

	if user2.ID != 123 {
		t.Error("MustBind: binding failed")
	}

	// Test MustBind panic
	func() {
		defer func() {
			if r := recover(); r == nil {
				t.Error("MustBind: expected panic for missing key")
			}
		}()
		var missing User
		store.MustBind("notfound", &missing)
	}()
}

// TestSharedStoreNumericConversions tests numeric type conversions
func TestSharedStoreNumericConversions(t *testing.T) {
	store := NewSharedStore()

	// Test all numeric types to int conversion
	store.Set("int8", int8(8))
	store.Set("int16", int16(16))
	store.Set("int32", int32(32))
	store.Set("int64", int64(64))
	store.Set("uint", uint(10))
	store.Set("uint8", uint8(8))
	store.Set("uint16", uint16(16))
	store.Set("uint32", uint32(32))
	store.Set("uint64", uint64(64))

	tests := []struct {
		key      string
		expected int
	}{
		{"int8", 8},
		{"int16", 16},
		{"int32", 32},
		{"int64", 64},
		{"uint", 10},
		{"uint8", 8},
		{"uint16", 16},
		{"uint32", 32},
		{"uint64", 64},
	}

	for _, test := range tests {
		if got := store.GetInt(test.key); got != test.expected {
			t.Errorf("GetInt(%s): expected %d, got %d", test.key, test.expected, got)
		}
	}

	// Test all numeric types to float64 conversion
	for _, test := range tests {
		if got := store.GetFloat64(test.key); got != float64(test.expected) {
			t.Errorf("GetFloat64(%s): expected %f, got %f", test.key, float64(test.expected), got)
		}
	}
}

// TestSharedStoreConcurrentTypeGetters tests concurrent access to type-specific getters
func TestSharedStoreConcurrentTypeGetters(t *testing.T) {
	store := NewSharedStore()
	store.Set("string", "test")
	store.Set("int", 42)
	store.Set("bool", true)

	var wg sync.WaitGroup

	// Concurrent type-specific reads
	for i := 0; i < 100; i++ {
		wg.Add(3)
		go func() {
			defer wg.Done()
			_ = store.GetString("string")
		}()
		go func() {
			defer wg.Done()
			_ = store.GetInt("int")
		}()
		go func() {
			defer wg.Done()
			_ = store.GetBool("bool")
		}()
	}

	// Concurrent writes and utility methods
	for i := 0; i < 50; i++ {
		wg.Add(4)
		go func(n int) {
			defer wg.Done()
			store.Set(fmt.Sprintf("concurrent_%d", n), n)
		}(i)
		go func(n int) {
			defer wg.Done()
			store.Has(fmt.Sprintf("concurrent_%d", n))
		}(i)
		go func() {
			defer wg.Done()
			_ = store.Keys()
		}()
		go func() {
			defer wg.Done()
			_ = store.Len()
		}()
	}

	wg.Wait()
}

// SlowNode is a test node that takes time to execute
type SlowNode struct {
	*BaseNode
	delay time.Duration
}

func (n *SlowNode) Exec(ctx context.Context, prepResult any) (any, error) {
	select {
	case <-time.After(n.delay):
		return "completed", nil
	case <-ctx.Done():
		return nil, ctx.Err()
	}
}

// TestContextCancellation tests context cancellation
func TestContextCancellation(t *testing.T) {
	node := &SlowNode{
		BaseNode: NewBaseNode(),
		delay:    500 * time.Millisecond,
	}
	shared := NewSharedStore()

	ctx, cancel := context.WithTimeout(context.Background(), 100*time.Millisecond)
	defer cancel()

	_, err := Run(ctx, node, shared)
	if err == nil {
		t.Error("expected context cancellation error")
	}

	if !errors.Is(err, context.DeadlineExceeded) {
		t.Errorf("expected DeadlineExceeded, got %v", err)
	}
}

// TestContextCancellationDuringRetry tests cancellation during retry wait
func TestContextCancellationDuringRetry(t *testing.T) {
	attempts := 0
	node := &RetryNode{
		BaseNode: NewBaseNode(
			WithMaxRetries(3),
			WithWait(200*time.Millisecond),
		),
		onExec: func() error {
			attempts++
			return errors.New("retry me")
		},
	}

	shared := NewSharedStore()
	ctx, cancel := context.WithTimeout(context.Background(), 150*time.Millisecond)
	defer cancel()

	_, err := Run(ctx, node, shared)
	if err == nil {
		t.Error("expected context cancellation error")
	}

	// Should have attempted once, then cancelled during wait
	if attempts != 1 {
		t.Errorf("expected 1 attempt, got %d", attempts)
	}
}

// RetryNode is a test node for retry logic
type RetryNode struct {
	*BaseNode
	attempts int
	onExec   func() error
}

func (n *RetryNode) Exec(ctx context.Context, prepResult any) (any, error) {
	n.attempts++
	if n.onExec != nil {
		return nil, n.onExec()
	}
	if n.attempts < 3 {
		return nil, errors.New("retry me")
	}
	return "success", nil
}

// TestRetryLogic tests retry functionality
func TestRetryLogic(t *testing.T) {
	node := &RetryNode{
		BaseNode: NewBaseNode(
			WithMaxRetries(3),
			WithWait(10*time.Millisecond),
		),
	}

	shared := NewSharedStore()
	ctx := context.Background()

	action, err := Run(ctx, node, shared)
	if err != nil {
		t.Errorf("unexpected error: %v", err)
	}

	if action != DefaultAction {
		t.Errorf("expected DefaultAction, got %v", action)
	}

	if node.attempts != 3 {
		t.Errorf("expected 3 attempts, got %d", node.attempts)
	}
}

// TestBatchErrorAggregation tests error aggregation in batch operations
func TestFlowExecution(t *testing.T) {
	// Create nodes
	node1 := &TestNode{
		BaseNode: NewBaseNode(),
		name:     "node1",
		action:   "next",
	}
	node2 := &TestNode{
		BaseNode: NewBaseNode(),
		name:     "node2",
		action:   DefaultAction,
	}

	// Create flow
	flow := NewFlow(node1)
	flow.Connect(node1, "next", node2)

	// Execute
	shared := NewSharedStore()
	ctx := context.Background()

	err := flow.Run(ctx, shared)
	if err != nil {
		t.Errorf("unexpected error: %v", err)
	}

	// Check both nodes executed
	if !node1.executed {
		t.Error("node1 not executed")
	}
	if !node2.executed {
		t.Error("node2 not executed")
	}
}

// TestNode is a simple test node
type TestNode struct {
	*BaseNode
	name     string
	action   Action
	executed bool
	postFunc func(context.Context, *SharedStore, any, any) (Action, error)
}

func (n *TestNode) Exec(ctx context.Context, prepResult any) (any, error) {
	n.executed = true
	return n.name, nil
}

func (n *TestNode) Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error) {
	if n.postFunc != nil {
		return n.postFunc(ctx, shared, prepResult, execResult)
	}
	shared.Set(n.name+"_result", execResult)
	return n.action, nil
}

// TestBatchFlowCustomCountKey tests batch flow with custom count key

// TestNestedFlowExecution tests flows within flows
func TestNestedFlowExecution(t *testing.T) {
	// Create inner flow
	innerNode := &TestNode{
		BaseNode: NewBaseNode(),
		name:     "inner",
		action:   DefaultAction,
	}
	innerFlow := NewFlow(innerNode)

	// Create outer flow
	outerNode := &TestNode{
		BaseNode: NewBaseNode(),
		name:     "outer",
		action:   "next",
	}
	outerFlow := NewFlow(outerNode)
	outerFlow.Connect(outerNode, "next", innerFlow)

	// Execute
	shared := NewSharedStore()
	ctx := context.Background()

	err := outerFlow.Run(ctx, shared)
	if err != nil {
		t.Errorf("unexpected error: %v", err)
	}

	// Check both nodes executed
	if !outerNode.executed {
		t.Error("outer node not executed")
	}
	if !innerNode.executed {
		t.Error("inner node not executed")
	}
}

// BenchmarkSharedStoreConcurrentAccess benchmarks concurrent store access
func BenchmarkSharedStoreConcurrentAccess(b *testing.B) {
	store := NewSharedStore()

	// Pre-populate store
	for i := 0; i < 100; i++ {
		store.Set(fmt.Sprintf("key%d", i), i)
	}

	b.ResetTimer()
	b.RunParallel(func(pb *testing.PB) {
		i := 0
		for pb.Next() {
			if i%2 == 0 {
				store.Get(fmt.Sprintf("key%d", i%100))
			} else {
				store.Set(fmt.Sprintf("key%d", i%100), i)
			}
			i++
		}
	})
}

// BenchmarkBatchNodeProcessing benchmarks batch processing



================================================
FILE: go.mod
================================================
module github.com/mark3labs/flyt

go 1.23


================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2025 Mark III Labs LLC

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================
FILE: www/README.md
================================================
# Flyt Documentation

This directory contains the documentation website for Flyt, built with [Vocs](https://vocs.dev).

## Development

Install dependencies:

```bash
bun install
# or
npm install
```

Start the development server:

```bash
bun dev
# or
npm run dev
```

The documentation will be available at http://localhost:5173

## Building

Build the documentation for production:

```bash
bun build
# or
npm run build
```

Preview the production build:

```bash
bun preview
# or
npm run preview
```

## Structure

```
www/
├── docs/
│   ├── pages/           # Documentation pages (MDX)
│   │   ├── index.mdx    # Landing page
│   │   ├── getting-started/
│   │   ├── concepts/
│   │   ├── patterns/
│   │   ├── advanced/
│   │   └── examples/
│   └── public/          # Static assets
│       └── flyt-logo.png
├── vocs.config.ts       # Vocs configuration
├── package.json
└── README.md
```

## Adding Documentation

1. Create a new `.mdx` file in the appropriate directory under `docs/pages/`
2. Add the page to the sidebar in `vocs.config.ts`
3. Use MDX features for rich content (code blocks, components, etc.)

## Deployment

The documentation can be deployed to any static hosting service:

- Vercel
- Netlify
- GitHub Pages
- Cloudflare Pages

Build the docs and deploy the `dist` directory.


================================================
FILE: www/package.json
================================================
{
  "name": "www",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vocs dev",
    "build": "vocs build",
    "preview": "vocs preview"
  },
  "dependencies": {
    "react": "latest",
    "react-dom": "latest",
    "vocs": "latest"
  },
  "devDependencies": {
    "@types/react": "latest",
    "typescript": "latest"
  }
}



================================================
FILE: www/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true
  },
  "include": ["**/*.ts", "**/*.tsx"]
}



================================================
FILE: www/vocs.config.ts
================================================
import { defineConfig } from 'vocs'

export default defineConfig({
  title: 'Flyt',
  description: 'A minimalist workflow framework for Go with zero dependencies',
  baseUrl: 'https://go-flyt.dev',
  basePath: '/',
  logoUrl: '/flyt-logo.png',
  sidebar: [
    {
      text: 'Introduction',
      link: '/',
    },
    {
      text: 'Getting Started',
      items: [
        {
          text: 'Installation',
          link: '/getting-started/installation',
        },
        {
          text: 'Quick Start',
          link: '/getting-started/quick-start',
        },
        {
          text: 'Project Template',
          link: '/getting-started/template',
        },
      ],
    },
    {
      text: 'Core Concepts',
      items: [
        {
          text: 'Nodes',
          link: '/concepts/nodes',
        },
        {
          text: 'Actions',
          link: '/concepts/actions',
        },
        {
          text: 'Flows',
          link: '/concepts/flows',
        },
        {
          text: 'Shared Store',
          link: '/concepts/shared-store',
        },
      ],
    },
    {
      text: 'Patterns',
      items: [
        {
          text: 'Configuration via Closures',
          link: '/patterns/closures',
        },
        {
          text: 'Error Handling & Retries',
          link: '/patterns/error-handling',
        },
        {
          text: 'Fallback on Failure',
          link: '/patterns/fallback',
        },
        {
          text: 'Conditional Branching',
          link: '/patterns/branching',
        },
      ],
    },
    {
      text: 'Advanced',
      items: [
        {
          text: 'Custom Node Types',
          link: '/advanced/custom-nodes',
        },
        {
          text: 'Batch Processing',
          link: '/advanced/batch-processing',
        },
        {
          text: 'Batch Flows',
          link: '/advanced/batch-flows',
        },
        {
          text: 'Nested Flows',
          link: '/advanced/nested-flows',
        },
        {
          text: 'Flow as Node',
          link: '/advanced/flow-as-node',
        },
        {
          text: 'Worker Pool',
          link: '/advanced/worker-pool',
        },
        {
          text: 'Utilities',
          link: '/advanced/utilities',
        },
      ],
    },
    {
      text: 'Examples',
      items: [
        {
          text: 'Agent',
          link: 'https://github.com/mark3labs/flyt/tree/main/cookbook/agent',
        },
        {
          text: 'Chat',
          link: 'https://github.com/mark3labs/flyt/tree/main/cookbook/chat',
        },
        {
          text: 'LLM Streaming',
          link: 'https://github.com/mark3labs/flyt/tree/main/cookbook/llm-streaming',
        },
        {
          text: 'MCP',
          link: 'https://github.com/mark3labs/flyt/tree/main/cookbook/mcp',
        },
        {
          text: 'Slack Bot',
          link: 'https://github.com/mark3labs/flyt/tree/main/cookbook/slack-bot',
        },
        {
          text: 'SST Integration',
          link: 'https://github.com/mark3labs/flyt/tree/main/cookbook/sst-integration',
        },
        {
          text: 'Summarize',
          link: 'https://github.com/mark3labs/flyt/tree/main/cookbook/summarize',
        },
        {
          text: 'Tracing',
          link: 'https://github.com/mark3labs/flyt/tree/main/cookbook/tracing',
        },
      ],
    },
    {
      text: 'Best Practices',
      link: '/best-practices',
    },
  ],
  socials: [
    {
      icon: 'github',
      link: 'https://github.com/mark3labs/flyt',
    },
  ],
})



================================================
FILE: www/docs/pages/best-practices.mdx
================================================
# Best Practices

Follow these guidelines to build robust, maintainable Flyt workflows.

## Node Design

### Single Responsibility

Each node should do one thing well:

```go
// ❌ Bad: Node doing too much
node := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        // Fetch data
        data := fetchFromAPI()
        // Validate
        if !isValid(data) {
            return nil, errors.New("invalid")
        }
        // Transform
        transformed := transform(data)
        // Save
        saveToDatabase(transformed)
        return transformed, nil
    }),
)

// ✅ Good: Separate concerns
fetchNode := createFetchNode()
validateNode := createValidateNode()
transformNode := createTransformNode()
saveNode := createSaveNode()

flow := flyt.NewFlow(fetchNode)
flow.Connect(fetchNode, flyt.DefaultAction, validateNode)
flow.Connect(validateNode, "valid", transformNode)
flow.Connect(transformNode, flyt.DefaultAction, saveNode)
```

### Idempotency

Design nodes to be safely retryable:

```go
// ✅ Good: Idempotent operation
func (n *SaveNode) Exec(ctx context.Context, prepResult any) (any, error) {
    data := prepResult.(Record)
    
    // Use upsert instead of insert
    _, err := db.Exec(`
        INSERT INTO records (id, data) VALUES (?, ?)
        ON CONFLICT (id) DO UPDATE SET data = ?
    `, data.ID, data.Data, data.Data)
    
    return data.ID, err
}
```

### Error Handling

Return clear, actionable errors:

```go
// ❌ Bad: Generic error
return nil, errors.New("failed")

// ✅ Good: Descriptive error
return nil, fmt.Errorf("failed to fetch user %d: %w", userID, err)
```

### Type-Safe SharedStore Access

Use type-safe helpers to avoid runtime panics:

```go
// ❌ Bad: Manual type assertion can panic
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    val, _ := shared.Get("count")
    count := val.(int)  // Panics if val is nil or not int
    return count, nil
}

// ✅ Good: Type-safe getter with default
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    count := shared.GetInt("count")  // Returns 0 if not found
    // Or with custom default
    count := shared.GetIntOr("count", -1)
    return count, nil
}

// ✅ Good: Bind complex types
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    var config Config
    if err := shared.Bind("config", &config); err != nil {
        return nil, fmt.Errorf("invalid config: %w", err)
    }
    return config, nil
}
```

## Flow Design

### Modular Flows

Create reusable sub-flows:

```go
// Reusable validation flow
func createValidationFlow() *flyt.Flow {
    schemaCheck := createSchemaValidator()
    businessRules := createBusinessValidator()
    
    flow := flyt.NewFlow(schemaCheck)
    flow.Connect(schemaCheck, "valid", businessRules)
    return flow
}

// Use in multiple places
mainFlow.Connect(fetchNode, flyt.DefaultAction, createValidationFlow())
apiFlow.Connect(parseNode, flyt.DefaultAction, createValidationFlow())
```

### Error Boundaries

Centralize error handling:

```go
func createFlowWithErrorHandling() *flyt.Flow {
    flow := flyt.NewFlow(startNode)
    errorHandler := createErrorHandler()
    
    // Connect all error paths to handler
    for _, node := range []flyt.Node{startNode, processNode, saveNode} {
        flow.Connect(node, "error", errorHandler)
    }
    
    return flow
}
```

## Context Handling

### Respect Cancellation

Always check context in long-running operations:

```go
func (n *ProcessNode) Exec(ctx context.Context, prepResult any) (any, error) {
    items := prepResult.([]Item)
    results := []Result{}
    
    for _, item := range items {
        // Check context before each iteration
        select {
        case <-ctx.Done():
            return nil, ctx.Err()
        default:
        }
        
        result := processItem(ctx, item)
        results = append(results, result)
    }
    
    return results, nil
}
```

### Timeout Management

Set appropriate timeouts:

```go
func (n *APINode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Create timeout context
    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)
    defer cancel()
    
    return callAPI(ctx, prepResult)
}
```

## Concurrency Safety

### Thread-Safe Nodes

Protect shared state in nodes:

```go
type CounterNode struct {
    *flyt.BaseNode
    mu    sync.Mutex
    count int
}

func (n *CounterNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.mu.Lock()
    n.count++
    current := n.count
    n.mu.Unlock()
    
    return current, nil
}
```

### Avoid Shared Node Instances

Create new instances for concurrent use:

```go
// ❌ Bad: Sharing node instance
node := createProcessNode()
for i := 0; i < 10; i++ {
    go flyt.Run(ctx, node, shared) // Race condition!
}

// ✅ Good: Create new instances
for i := 0; i < 10; i++ {
    go flyt.Run(ctx, createProcessNode(), shared)
}
```

## Resource Management

### Clean Up Resources

Use defer for cleanup:

```go
func (n *FileNode) Exec(ctx context.Context, prepResult any) (any, error) {
    file, err := os.Open(prepResult.(string))
    if err != nil {
        return nil, err
    }
    defer file.Close() // Always cleanup
    
    // Process file...
    return processFile(file)
}
```

### Connection Pooling

Reuse expensive resources:

```go
type DatabaseFlow struct {
    db *sql.DB
}

func NewDatabaseFlow(db *sql.DB) *DatabaseFlow {
    return &DatabaseFlow{db: db}
}

func (f *DatabaseFlow) CreateNode() flyt.Node {
    return &DatabaseNode{
        BaseNode: flyt.NewBaseNode(),
        db: f.db, // Reuse connection pool
    }
}
```

## Testing

### Unit Test Nodes

Test nodes in isolation:

```go
func TestProcessNode(t *testing.T) {
    node := createProcessNode()
    ctx := context.Background()
    
    // Test successful case
    result, err := node.Exec(ctx, "test input")
    assert.NoError(t, err)
    assert.Equal(t, "expected output", result)
    
    // Test error case
    result, err = node.Exec(ctx, nil)
    assert.Error(t, err)
}
```

### Integration Test Flows

Test complete workflows:

```go
func TestCompleteFlow(t *testing.T) {
    flow := createMainFlow()
    shared := flyt.NewSharedStore()
    shared.Set("input", testData)
    
    ctx := context.Background()
    err := flow.Run(ctx, shared)
    assert.NoError(t, err)
    
    // Use type-safe getter or Bind for results
    var result OutputData
    err = shared.Bind("output", &result)
    assert.NoError(t, err)
    assert.Equal(t, expectedResult, result)
}
```

## Documentation

### Document Node Behavior

```go
// FetchUserNode fetches user data from the API.
// 
// Prep: Reads "user_id" from SharedStore
// Exec: Fetches user from API, retries on network errors
// Post: Stores user data in "user_data" key
// Actions:
//   - "success": User fetched successfully
//   - "not_found": User does not exist
//   - "error": Unrecoverable error occurred
type FetchUserNode struct {
    *flyt.BaseNode
    apiClient *APIClient
}
```

### Document Flow Structure

```go
// CreateOrderFlow processes new orders:
// 1. Validates order data
// 2. Checks inventory
// 3. Processes payment
// 4. Creates shipment
// 5. Sends confirmation
//
// Required SharedStore keys:
//   - "order_data": OrderData struct
//   - "customer_id": string
//
// Sets SharedStore keys:
//   - "order_id": string
//   - "tracking_number": string
func CreateOrderFlow() *flyt.Flow {
    // ...
}
```

## Performance

### Batch Operations

Process items in batches when possible:

```go
// Instead of processing one at a time
for _, item := range items {
    process(item)
}

// Process in batches
batchNode := flyt.NewBatchNode(processFunc, true)
shared.Set("items", items)
```

### Lazy Loading

Load data only when needed:

```go
func (n *ProcessNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    // Only load the data this node needs
    if needsUserData(shared) {
        userData := loadUserData()
        return userData, nil
    }
    return nil, nil
}
```

## Monitoring

### Add Observability

Log important events:

```go
func (n *ProcessNode) Exec(ctx context.Context, prepResult any) (any, error) {
    start := time.Now()
    defer func() {
        log.Printf("ProcessNode took %v", time.Since(start))
    }()
    
    result, err := process(prepResult)
    if err != nil {
        log.Printf("ProcessNode error: %v", err)
        return nil, err
    }
    
    log.Printf("ProcessNode success: processed %d items", len(result))
    return result, nil
}
```

## Next Steps

- [Examples](https://github.com/mark3labs/flyt/tree/main/cookbook) - See best practices in action
- [Advanced Usage](/advanced/custom-nodes) - Advanced patterns
- [Core Concepts](/concepts/nodes) - Review fundamentals


================================================
FILE: www/docs/pages/index.mdx
================================================
---
layout: landing
---

import { HomePage } from 'vocs/components'

<HomePage.Root>
  <div style={{ display: 'flex', flexDirection: 'column', alignItems: 'center', marginBottom: '1rem' }}>
    <img src="/flyt-logo.png" alt="Flyt Logo" style={{ width: '280px', height: 'auto' }} />
    <p style={{ fontStyle: 'italic', color: 'var(--vocs-color_text2)', marginTop: '0.5rem', fontSize: '0.95rem' }}>
      Norwegian for "flow" • Pronounced "fleet"
    </p>
  </div>
  <HomePage.Tagline>A minimalist workflow framework for Go</HomePage.Tagline>
  
  ```bash
  go get github.com/mark3labs/flyt
  ```
  
  <HomePage.Description>
    Build powerful, composable workflows with zero dependencies. Flyt provides a simple yet flexible 
    graph-based abstraction for orchestrating tasks in Go.
  </HomePage.Description>
  
  <HomePage.Buttons>
    <HomePage.Button href="/getting-started/quick-start" variant="accent">Get Started</HomePage.Button>
    <HomePage.Button href="https://github.com/mark3labs/flyt">GitHub</HomePage.Button>
  </HomePage.Buttons>
</HomePage.Root>

<div style={{ marginTop: '4rem' }}>

## Features

<div style={{ 
  display: 'grid', 
  gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))',
  gap: '1.5rem',
  marginTop: '2rem'
}}>
  <div>
    <h3 style={{ fontSize: '1.1rem', marginBottom: '0.5rem' }}>🚀 Zero Dependencies</h3>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.95rem' }}>Pure Go standard library - no external dependencies required</p>
  </div>
  <div>
    <h3 style={{ fontSize: '1.1rem', marginBottom: '0.5rem' }}>🔄 Composable Workflows</h3>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.95rem' }}>Build complex flows from simple, reusable nodes</p>
  </div>
  <div>
    <h3 style={{ fontSize: '1.1rem', marginBottom: '0.5rem' }}>🎯 Action-Based Routing</h3>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.95rem' }}>Dynamic flow control based on runtime results</p>
  </div>
  <div>
    <h3 style={{ fontSize: '1.1rem', marginBottom: '0.5rem' }}>🔁 Built-in Retry Logic</h3>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.95rem' }}>Handle transient failures with configurable retries</p>
  </div>
  <div>
    <h3 style={{ fontSize: '1.1rem', marginBottom: '0.5rem' }}>🔒 Thread-Safe</h3>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.95rem' }}>Concurrent batch processing with safe shared state</p>
  </div>
  <div>
    <h3 style={{ fontSize: '1.1rem', marginBottom: '0.5rem' }}>📦 Batch Processing</h3>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.95rem' }}>Process collections efficiently with built-in patterns</p>
  </div>
</div>

</div>

<div style={{ marginTop: '3rem' }}>

## Quick Example

<div style={{ marginTop: '1.5rem' }}>

```go
package main

import (
    "context"
    "fmt"
    "github.com/mark3labs/flyt"
)

func main() {
    // Create nodes that share data via SharedStore
    fetchNode := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, _ any) (any, error) {
            fmt.Println("Fetching data...")
            return map[string]int{"value": 42}, nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, _, execResult any) (flyt.Action, error) {
            shared.Set("data", execResult)
            return flyt.DefaultAction, nil
        }),
    )
    
    processNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Type-safe access to data
            data := shared.GetMap("data")
            return data, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, data any) (any, error) {
            val := data.(map[string]any)["value"].(int)
            fmt.Printf("Processing: %d\n", val)
            return val * 2, nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, _, execResult any) (flyt.Action, error) {
            shared.Set("result", execResult)
            return flyt.DefaultAction, nil
        }),
    )
    
    saveNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Type-safe getter for integer result
            result := shared.GetInt("result")
            return result, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, result any) (any, error) {
            fmt.Printf("Saving result: %d\n", result)
            return nil, nil
        }),
    )
    
    // Build and run flow
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, processNode)
    flow.Connect(processNode, flyt.DefaultAction, saveNode)
    
    err := flow.Run(context.Background(), flyt.NewSharedStore())
    if err != nil {
        panic(err)
    }
}
```

</div>
</div>

<div style={{ marginTop: '3rem' }}>

## Why Flyt?

<p style={{ fontSize: '1.05rem', lineHeight: '1.7', color: 'var(--vocs-color_text2)', marginTop: '1rem' }}>
Flyt was inspired by <a href="https://github.com/The-Pocket/PocketFlow" style={{ color: 'var(--vocs-color_link)' }}>Pocket Flow</a> and 
designed to provide a simple, dependency-free solution for workflow orchestration in Go. Whether you're building 
data pipelines, API orchestration, or complex business logic, Flyt gives you the tools to create maintainable, 
testable workflows.
</p>

<h3 style={{ marginTop: '2rem', marginBottom: '1.5rem' }}>Perfect for</h3>

<div style={{ 
  display: 'grid', 
  gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))',
  gap: '1rem'
}}>
  <div style={{ 
    padding: '1rem',
    backgroundColor: 'var(--vocs-color_backgroundDark)',
    borderRadius: '6px',
    border: '1px solid var(--vocs-color_border)'
  }}>
    <strong>Data Processing Pipelines</strong>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.9rem', marginTop: '0.5rem' }}>
      ETL workflows with built-in error handling
    </p>
  </div>
  <div style={{ 
    padding: '1rem',
    backgroundColor: 'var(--vocs-color_backgroundDark)',
    borderRadius: '6px',
    border: '1px solid var(--vocs-color_border)'
  }}>
    <strong>API Orchestration</strong>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.9rem', marginTop: '0.5rem' }}>
      Chain multiple API calls with automatic retries
    </p>
  </div>
  <div style={{ 
    padding: '1rem',
    backgroundColor: 'var(--vocs-color_backgroundDark)',
    borderRadius: '6px',
    border: '1px solid var(--vocs-color_border)'
  }}>
    <strong>Business Logic Flows</strong>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.9rem', marginTop: '0.5rem' }}>
      Complex decision trees and state machines
    </p>
  </div>
  <div style={{ 
    padding: '1rem',
    backgroundColor: 'var(--vocs-color_backgroundDark)',
    borderRadius: '6px',
    border: '1px solid var(--vocs-color_border)'
  }}>
    <strong>Batch Operations</strong>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.9rem', marginTop: '0.5rem' }}>
      Process large datasets concurrently
    </p>
  </div>
  <div style={{ 
    padding: '1rem',
    backgroundColor: 'var(--vocs-color_backgroundDark)',
    borderRadius: '6px',
    border: '1px solid var(--vocs-color_border)'
  }}>
    <strong>AI/LLM Workflows</strong>
    <p style={{ color: 'var(--vocs-color_text2)', fontSize: '0.9rem', marginTop: '0.5rem' }}>
      Build agent systems and conversation flows
    </p>
  </div>
</div>

</div>


================================================
FILE: www/docs/pages/advanced/batch-flows.mdx
================================================
# Batch Flows

Run the same flow multiple times with different parameters, perfect for processing multiple entities or parallel workflows.

## Basic Batch Flow

Run a flow for each set of inputs:

```go
// Create a flow factory - returns a new flow instance for each iteration
flowFactory := func() *flyt.Flow {
    validateNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Each flow has its own SharedStore with merged FlowInputs
            userID := shared.GetInt("user_id")
            email := shared.GetString("email")
            return map[string]any{"user_id": userID, "email": email}, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            data := prepResult.(map[string]any)
            // Process user data
            return processUser(data), nil
        }),
    )
    return flyt.NewFlow(validateNode)
}

// Define input parameters for each flow iteration
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    // Could fetch from database, API, etc.
    return []flyt.FlowInputs{
        {"user_id": 1, "email": "user1@example.com"},
        {"user_id": 2, "email": "user2@example.com"},
        {"user_id": 3, "email": "user3@example.com"},
    }, nil
}

// Create and run batch flow
batchFlow := flyt.NewBatchFlow(flowFactory, batchFunc, true) // true for concurrent
shared := flyt.NewSharedStore()
err := batchFlow.Run(ctx, shared)
```

## Sequential vs Concurrent Execution

Control how flows are executed:

```go
// Sequential - one flow at a time
sequentialBatch := flyt.NewBatchFlow(flowFactory, batchFunc, false)

// Concurrent - multiple flows in parallel
concurrentBatch := flyt.NewBatchFlow(flowFactory, batchFunc, true)
```

## Dynamic Input Generation

Generate inputs based on runtime data:

```go
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    // Get configuration from parent shared store
    config := shared.GetMap("batch_config")
    batchSize := int(config["size"].(float64))  // JSON numbers are float64
    
    // Fetch data from database
    users, err := fetchUsers(batchSize)
    if err != nil {
        return nil, err
    }
    
    // Convert to FlowInputs
    inputs := make([]flyt.FlowInputs, len(users))
    for i, user := range users {
        inputs[i] = flyt.FlowInputs{
            "user_id":   user.ID,
            "user_name": user.Name,
            "user_data": user,
        }
    }
    
    return inputs, nil
}
```

## Complex Flow Factory

Create sophisticated flows for each batch:

```go
flowFactory := func() *flyt.Flow {
    // Create nodes
    fetchNode := createFetchNode()
    validateNode := createValidateNode()
    processNode := createProcessNode()
    saveNode := createSaveNode()
    errorNode := createErrorNode()
    
    // Build flow with error handling
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, validateNode)
    flow.Connect(validateNode, "valid", processNode)
    flow.Connect(validateNode, "invalid", errorNode)
    flow.Connect(processNode, flyt.DefaultAction, saveNode)
    flow.Connect(processNode, "error", errorNode)
    
    return flow
}
```

## Batch Flow with Configuration

Pass configuration to batch flows:

```go
func createConfiguredBatchFlow(config Config) *flyt.Flow {
    flowFactory := func() *flyt.Flow {
        // Each flow gets the same configuration
        node := flyt.NewNode(
            flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
                // Use config in processing
                return processWithConfig(prepResult, config), nil
            }),
        )
        return flyt.NewFlow(node)
    }
    
    batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
        items := shared.GetSlice("items")
        
        inputs := make([]flyt.FlowInputs, 0)
        for _, item := range items {
            inputs = append(inputs, flyt.FlowInputs{
                "item": item,
                "config": config,
            })
        }
        
        return inputs, nil
    }
    
    return flyt.NewBatchFlow(flowFactory, batchFunc, true)
}
```

## Result Aggregation

Collect results from all flows:

```go
type ResultCollector struct {
    mu      sync.Mutex
    results []any
    errors  []error
}

func createAggregatingBatchFlow(collector *ResultCollector) *flyt.Flow {
    flowFactory := func() *flyt.Flow {
        node := flyt.NewNode(
            flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
                result, err := process(prepResult)
                
                collector.mu.Lock()
                if err != nil {
                    collector.errors = append(collector.errors, err)
                } else {
                    collector.results = append(collector.results, result)
                }
                collector.mu.Unlock()
                
                return result, err
            }),
        )
        return flyt.NewFlow(node)
    }
    
    // ... rest of batch flow setup
}
```

## Batch Flow with Progress

Track progress across batch execution:

```go
type ProgressTracker struct {
    total     int
    completed int32
    failed    int32
}

func createProgressBatchFlow(tracker *ProgressTracker) *flyt.Flow {
    flowFactory := func() *flyt.Flow {
        node := flyt.NewNode(
            flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
                if execResult != nil {
                    atomic.AddInt32(&tracker.completed, 1)
                } else {
                    atomic.AddInt32(&tracker.failed, 1)
                }
                
                progress := atomic.LoadInt32(&tracker.completed) + atomic.LoadInt32(&tracker.failed)
                percentage := float64(progress) / float64(tracker.total) * 100
                
                log.Printf("Batch progress: %.1f%% (%d/%d)", percentage, progress, tracker.total)
                
                return flyt.DefaultAction, nil
            }),
        )
        return flyt.NewFlow(node)
    }
    
    batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
        inputs := generateInputs()
        tracker.total = len(inputs)
        return inputs, nil
    }
    
    return flyt.NewBatchFlow(flowFactory, batchFunc, true)
}
```

## Conditional Batch Processing

Process batches based on conditions:

```go
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    mode := shared.GetString("processing_mode")
    
    var inputs []flyt.FlowInputs
    
    switch mode {
    case "all":
        inputs = getAllInputs()
    case "pending":
        inputs = getPendingInputs()
    case "failed":
        inputs = getFailedInputs()
    default:
        return nil, fmt.Errorf("unknown mode: %s", mode)
    }
    
    // Filter based on additional criteria
    filtered := make([]flyt.FlowInputs, 0)
    for _, input := range inputs {
        if shouldProcess(input) {
            filtered = append(filtered, input)
        }
    }
    
    return filtered, nil
}
```

## Nested Batch Flows

Batch flows within batch flows:

```go
outerFlowFactory := func() *flyt.Flow {
    // Inner batch flow for processing items
    innerBatchFlow := flyt.NewBatchFlow(
        innerFlowFactory,
        innerBatchFunc,
        true,
    )
    
    // Outer flow that includes the batch
    fetchNode := createFetchNode()
    
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, innerBatchFlow)
    flow.Connect(innerBatchFlow, flyt.DefaultAction, aggregateNode)
    
    return flow
}

// Create outer batch flow
outerBatchFlow := flyt.NewBatchFlow(outerFlowFactory, outerBatchFunc, false)
```

## Error Recovery

Handle failures in batch flows:

```go
flowFactory := func() *flyt.Flow {
    node := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            result, err := riskyOperation(prepResult)
            if err != nil {
                // Store error for later analysis
                errorData := map[string]any{
                    "input": prepResult,
                    "error": err.Error(),
                    "time":  time.Now(),
                }
                storeError(errorData)
                
                // Return partial result
                return map[string]any{
                    "status": "failed",
                    "error":  err.Error(),
                }, nil  // Don't fail the entire batch
            }
            return result, nil
        }),
    )
    return flyt.NewFlow(node)
}
```

## Best Practices

1. **Isolate Flows**: Each flow instance should be independent
2. **Manage Resources**: Be mindful of resource usage with concurrent flows
3. **Handle Failures**: Decide whether one failure should stop the batch
4. **Track Progress**: Implement progress tracking for long-running batches
5. **Limit Concurrency**: Set reasonable concurrency limits
6. **Test Thoroughly**: Test with various batch sizes and failure scenarios

## Next Steps

- [Batch Processing](/advanced/batch-processing) - Process items within a single node
- [Nested Flows](/advanced/nested-flows) - Compose complex workflows
- [Worker Pool](/advanced/worker-pool) - Fine-grained concurrency control


================================================
FILE: www/docs/pages/advanced/batch-processing.mdx
================================================
# Batch Processing

Process collections of items efficiently with concurrent or sequential execution.

## Basic Batch Processing

Process items with a simple function:

```go
// Define processing function
processFunc := func(ctx context.Context, item any) (any, error) {
    // Process each item
    return fmt.Sprintf("processed: %v", item), nil
}

// Create batch node
batchNode := flyt.NewBatchNode(processFunc, true) // true for concurrent

// Set items in shared store
shared := flyt.NewSharedStore()
shared.Set("items", []string{"item1", "item2", "item3"})

// Run batch processing
ctx := context.Background()
action, err := flyt.Run(ctx, batchNode, shared)

// Get results using type-safe getter
results := shared.GetSlice("results")
fmt.Println(results) // ["processed: item1", "processed: item2", "processed: item3"]
```

## Sequential vs Concurrent

Choose the right execution mode:

```go
// Sequential processing - maintains order
sequentialNode := flyt.NewBatchNode(processFunc, false)

// Concurrent processing - faster but unordered
concurrentNode := flyt.NewBatchNode(processFunc, true)
```

## Custom Keys

Use custom keys for input and output:

```go
batchNode := flyt.NewBatchNodeWithKeys(
    processFunc,
    true,           // concurrent
    "input_data",   // custom input key
    "output_data",  // custom output key
)

shared.Set("input_data", items)
// Results will be in "output_data"
```

## Advanced Configuration

Fine-tune batch processing with BatchConfig:

```go
config := &flyt.BatchConfig{
    BatchSize:   10,        // Process 10 items at a time
    Concurrency: 5,         // Use 5 concurrent workers
    ItemsKey:    "data",    // Key for input items
    ResultsKey:  "output",  // Key for results
    CountKey:    "total",   // Key for processed count
}

processFunc := func(ctx context.Context, item any) (any, error) {
    // Heavy processing
    time.Sleep(100 * time.Millisecond)
    return processItem(item)
}

batchNode := flyt.NewBatchNodeWithConfig(processFunc, true, config)
```

## Error Handling

Handle errors in batch operations:

```go
processFunc := func(ctx context.Context, item any) (any, error) {
    if item.(int) < 0 {
        return nil, fmt.Errorf("negative value: %v", item)
    }
    return item.(int) * 2, nil
}

batchNode := flyt.NewBatchNode(processFunc, true)
shared.Set("items", []int{1, -2, 3, -4, 5})

action, err := flyt.Run(ctx, batchNode, shared)
if err != nil {
    if batchErr, ok := err.(*flyt.BatchError); ok {
        fmt.Printf("Batch processing failed: %s\n", batchErr.Message)
        
        // Access individual errors
        for i, e := range batchErr.Errors {
            if e != nil {
                fmt.Printf("Item %d failed: %v\n", i, e)
            }
        }
    }
}
```

## Batch Processing Patterns

### Map Pattern

Transform each item:

```go
mapFunc := func(ctx context.Context, item any) (any, error) {
    user := item.(User)
    return UserDTO{
        ID:   user.ID,
        Name: user.Name,
        Age:  user.Age,
    }, nil
}

mapNode := flyt.NewBatchNode(mapFunc, true)
```

### Filter Pattern

Process only matching items:

```go
filterFunc := func(ctx context.Context, item any) (any, error) {
    value := item.(int)
    if value > 10 {
        return value, nil
    }
    return nil, nil  // Skip this item
}

filterNode := flyt.NewBatchNode(filterFunc, true)
```

### Reduce Pattern

Aggregate results:

```go
type SumNode struct {
    *flyt.BaseNode
    total int
    mu    sync.Mutex
}

func (n *SumNode) Exec(ctx context.Context, prepResult any) (any, error) {
    items := prepResult.([]int)
    
    for _, item := range items {
        n.mu.Lock()
        n.total += item
        n.mu.Unlock()
    }
    
    return n.total, nil
}
```

## Chunked Processing

Process large datasets in chunks:

```go
func createChunkedProcessor(chunkSize int) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            items := shared.GetSlice("items")
            return items, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            items := prepResult.([]any)
            results := make([]any, 0, len(items))
            
            // Process in chunks
            for i := 0; i < len(items); i += chunkSize {
                end := i + chunkSize
                if end > len(items) {
                    end = len(items)
                }
                
                chunk := items[i:end]
                chunkResults := processChunk(chunk)
                results = append(results, chunkResults...)
            }
            
            return results, nil
        }),
    )
}
```

## Progress Tracking

Monitor batch processing progress:

```go
type ProgressBatchNode struct {
    *flyt.BaseNode
    processed int32
    total     int32
}

func (n *ProgressBatchNode) processWithProgress(ctx context.Context, items []any) ([]any, error) {
    n.total = int32(len(items))
    results := make([]any, len(items))
    
    var wg sync.WaitGroup
    for i, item := range items {
        wg.Add(1)
        go func(idx int, data any) {
            defer wg.Done()
            
            result, _ := processItem(data)
            results[idx] = result
            
            // Update progress
            current := atomic.AddInt32(&n.processed, 1)
            progress := float64(current) / float64(n.total) * 100
            
            if current%10 == 0 || current == n.total {
                log.Printf("Progress: %.1f%% (%d/%d)", progress, current, n.total)
            }
        }(i, item)
    }
    
    wg.Wait()
    return results, nil
}
```

## Rate-Limited Batch Processing

Control processing rate:

```go
func createRateLimitedBatchNode(rps int) flyt.Node {
    limiter := rate.NewLimiter(rate.Limit(rps), 1)
    
    processFunc := func(ctx context.Context, item any) (any, error) {
        // Wait for rate limiter
        if err := limiter.Wait(ctx); err != nil {
            return nil, err
        }
        
        // Process item
        return callAPI(item)
    }
    
    return flyt.NewBatchNode(processFunc, true)
}
```

## Batch with Timeout

Set timeouts for batch operations:

```go
func createTimeoutBatchNode(timeout time.Duration) flyt.Node {
    processFunc := func(ctx context.Context, item any) (any, error) {
        // Create timeout context for this item
        itemCtx, cancel := context.WithTimeout(ctx, timeout)
        defer cancel()
        
        resultChan := make(chan any)
        errChan := make(chan error)
        
        go func() {
            result, err := processItem(item)
            if err != nil {
                errChan <- err
            } else {
                resultChan <- result
            }
        }()
        
        select {
        case result := <-resultChan:
            return result, nil
        case err := <-errChan:
            return nil, err
        case <-itemCtx.Done():
            return nil, fmt.Errorf("processing timeout for item: %v", item)
        }
    }
    
    return flyt.NewBatchNode(processFunc, true)
}
```

## Best Practices

1. **Choose Concurrency Wisely**: Use concurrent for I/O-bound, sequential for order-dependent
2. **Handle Errors Gracefully**: Decide whether to fail fast or collect all errors
3. **Monitor Progress**: Add logging for long-running batches
4. **Set Reasonable Limits**: Configure batch size and concurrency based on resources
5. **Test with Real Data**: Test with production-like data volumes
6. **Consider Memory Usage**: Be mindful of memory when processing large batches

## Next Steps

- [Batch Flows](/advanced/batch-flows) - Run flows with multiple inputs
- [Worker Pool](/advanced/worker-pool) - Custom concurrent processing
- [Error Handling](/patterns/error-handling) - Handle batch errors


================================================
FILE: www/docs/pages/advanced/custom-nodes.mdx
================================================
# Custom Node Types

Create sophisticated nodes with custom behavior, state management, and advanced features.

## Basic Custom Node

Extend BaseNode for custom functionality:

```go
type CustomNode struct {
    *flyt.BaseNode
    config Config
    state  State
}

func NewCustomNode(config Config) *CustomNode {
    return &CustomNode{
        BaseNode: flyt.NewBaseNode(),
        config:   config,
        state:    NewState(),
    }
}

func (n *CustomNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    // Custom preparation logic
    input := shared.GetString("input")
    n.state.Prepare(input)
    return input, nil
}

func (n *CustomNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Custom execution logic
    result := n.processWithConfig(prepResult, n.config)
    n.state.Update(result)
    return result, nil
}

func (n *CustomNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    // Custom post-processing
    shared.Set("state", n.state)
    
    if n.state.IsComplete() {
        return "complete", nil
    }
    return "continue", nil
}
```

## Stateful Nodes

Maintain state across executions:

```go
type AccumulatorNode struct {
    *flyt.BaseNode
    mu       sync.Mutex
    values   []any
    maxSize  int
}

func NewAccumulatorNode(maxSize int) *AccumulatorNode {
    return &AccumulatorNode{
        BaseNode: flyt.NewBaseNode(),
        values:   make([]any, 0, maxSize),
        maxSize:  maxSize,
    }
}

func (n *AccumulatorNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.mu.Lock()
    defer n.mu.Unlock()
    
    // Add to accumulator
    n.values = append(n.values, prepResult)
    
    // Check if buffer is full
    if len(n.values) >= n.maxSize {
        // Process batch
        result := n.processBatch(n.values)
        n.values = n.values[:0] // Clear buffer
        return result, nil
    }
    
    return nil, nil
}

func (n *AccumulatorNode) processBatch(values []any) any {
    // Process accumulated values
    return map[string]any{
        "count": len(values),
        "data":  values,
    }
}
```

## Resource-Managing Nodes

Handle external resources:

```go
type DatabaseNode struct {
    *flyt.BaseNode
    pool     *sql.DB
    prepared map[string]*sql.Stmt
    mu       sync.RWMutex
}

func NewDatabaseNode(dsn string) (*DatabaseNode, error) {
    db, err := sql.Open("postgres", dsn)
    if err != nil {
        return nil, err
    }
    
    db.SetMaxOpenConns(25)
    db.SetMaxIdleConns(5)
    
    return &DatabaseNode{
        BaseNode: flyt.NewBaseNode(),
        pool:     db,
        prepared: make(map[string]*sql.Stmt),
    }, nil
}

func (n *DatabaseNode) Exec(ctx context.Context, prepResult any) (any, error) {
    query := prepResult.(QueryRequest)
    
    // Use prepared statement if available
    stmt, err := n.getOrPrepare(query.SQL)
    if err != nil {
        return nil, err
    }
    
    rows, err := stmt.QueryContext(ctx, query.Args...)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    return n.scanResults(rows)
}

func (n *DatabaseNode) getOrPrepare(sql string) (*sql.Stmt, error) {
    n.mu.RLock()
    stmt, exists := n.prepared[sql]
    n.mu.RUnlock()
    
    if exists {
        return stmt, nil
    }
    
    n.mu.Lock()
    defer n.mu.Unlock()
    
    // Double-check after acquiring write lock
    if stmt, exists := n.prepared[sql]; exists {
        return stmt, nil
    }
    
    stmt, err := n.pool.Prepare(sql)
    if err != nil {
        return nil, err
    }
    
    n.prepared[sql] = stmt
    return stmt, nil
}

func (n *DatabaseNode) Close() error {
    n.mu.Lock()
    defer n.mu.Unlock()
    
    for _, stmt := range n.prepared {
        stmt.Close()
    }
    
    return n.pool.Close()
}
```

## RetryableNode Implementation

Custom retry logic:

```go
type SmartRetryNode struct {
    *flyt.BaseNode
    attempts      int
    lastError     error
    backoffFactor float64
}

func NewSmartRetryNode() *SmartRetryNode {
    return &SmartRetryNode{
        BaseNode:      flyt.NewBaseNode(),
        backoffFactor: 1.5,
    }
}

func (n *SmartRetryNode) GetMaxRetries() int {
    // Dynamic retry count based on error type
    if n.lastError != nil {
        switch {
        case isNetworkError(n.lastError):
            return 5  // More retries for network issues
        case isRateLimitError(n.lastError):
            return 3  // Fewer retries for rate limits
        case isAuthError(n.lastError):
            return 0  // No retries for auth errors
        default:
            return 2
        }
    }
    return 3
}

func (n *SmartRetryNode) GetWait() time.Duration {
    if n.lastError != nil && isRateLimitError(n.lastError) {
        // Extract retry-after from error if available
        if retryAfter := extractRetryAfter(n.lastError); retryAfter > 0 {
            return retryAfter
        }
    }
    
    // Exponential backoff with jitter
    base := math.Pow(n.backoffFactor, float64(n.attempts))
    jitter := rand.Float64() * 0.3 * base  // 30% jitter
    return time.Duration((base + jitter) * float64(time.Second))
}

func (n *SmartRetryNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.attempts++
    
    result, err := n.performOperation(ctx, prepResult)
    if err != nil {
        n.lastError = err
        return nil, err
    }
    
    // Reset on success
    n.attempts = 0
    n.lastError = nil
    return result, nil
}
```

## Composite Nodes

Combine multiple operations:

```go
type PipelineNode struct {
    *flyt.BaseNode
    stages []func(context.Context, any) (any, error)
}

func NewPipelineNode(stages ...func(context.Context, any) (any, error)) *PipelineNode {
    return &PipelineNode{
        BaseNode: flyt.NewBaseNode(),
        stages:   stages,
    }
}

func (n *PipelineNode) Exec(ctx context.Context, prepResult any) (any, error) {
    result := prepResult
    
    for i, stage := range n.stages {
        select {
        case <-ctx.Done():
            return nil, ctx.Err()
        default:
        }
        
        var err error
        result, err = stage(ctx, result)
        if err != nil {
            return nil, fmt.Errorf("stage %d failed: %w", i, err)
        }
    }
    
    return result, nil
}
```

## Monitoring Nodes

Add observability:

```go
type MonitoredNode struct {
    *flyt.BaseNode
    name    string
    metrics *Metrics
}

type Metrics struct {
    executions   int64
    successes    int64
    failures     int64
    totalLatency int64
}

func NewMonitoredNode(name string, baseNode flyt.Node) *MonitoredNode {
    return &MonitoredNode{
        BaseNode: baseNode.(*flyt.BaseNode),
        name:     name,
        metrics:  &Metrics{},
    }
}

func (n *MonitoredNode) Exec(ctx context.Context, prepResult any) (any, error) {
    start := time.Now()
    atomic.AddInt64(&n.metrics.executions, 1)
    
    result, err := n.BaseNode.Exec(ctx, prepResult)
    
    latency := time.Since(start).Milliseconds()
    atomic.AddInt64(&n.metrics.totalLatency, latency)
    
    if err != nil {
        atomic.AddInt64(&n.metrics.failures, 1)
        log.Printf("[%s] Execution failed: %v (latency: %dms)", n.name, err, latency)
    } else {
        atomic.AddInt64(&n.metrics.successes, 1)
        log.Printf("[%s] Execution succeeded (latency: %dms)", n.name, latency)
    }
    
    return result, err
}

func (n *MonitoredNode) GetMetrics() map[string]any {
    return map[string]any{
        "executions":    atomic.LoadInt64(&n.metrics.executions),
        "successes":     atomic.LoadInt64(&n.metrics.successes),
        "failures":      atomic.LoadInt64(&n.metrics.failures),
        "avg_latency":   n.getAverageLatency(),
        "success_rate":  n.getSuccessRate(),
    }
}
```

## Async Nodes

Handle asynchronous operations:

```go
type AsyncNode struct {
    *flyt.BaseNode
    workers int
    queue   chan Task
    wg      sync.WaitGroup
}

func NewAsyncNode(workers int) *AsyncNode {
    n := &AsyncNode{
        BaseNode: flyt.NewBaseNode(),
        workers:  workers,
        queue:    make(chan Task, workers*2),
    }
    
    // Start workers
    for i := 0; i < workers; i++ {
        go n.worker()
    }
    
    return n
}

func (n *AsyncNode) worker() {
    for task := range n.queue {
        n.processTask(task)
        n.wg.Done()
    }
}

func (n *AsyncNode) Exec(ctx context.Context, prepResult any) (any, error) {
    tasks := prepResult.([]Task)
    results := make([]Result, len(tasks))
    
    // Submit all tasks
    for i, task := range tasks {
        n.wg.Add(1)
        task.Index = i
        task.Results = &results
        n.queue <- task
    }
    
    // Wait for completion
    done := make(chan struct{})
    go func() {
        n.wg.Wait()
        close(done)
    }()
    
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    case <-done:
        return results, nil
    }
}

func (n *AsyncNode) Close() {
    close(n.queue)
}
```

## Validation Nodes

Ensure data integrity:

```go
type ValidationNode struct {
    *flyt.BaseNode
    rules []ValidationRule
}

type ValidationRule interface {
    Validate(any) error
    Name() string
}

func NewValidationNode(rules ...ValidationRule) *ValidationNode {
    return &ValidationNode{
        BaseNode: flyt.NewBaseNode(),
        rules:    rules,
    }
}

func (n *ValidationNode) Exec(ctx context.Context, prepResult any) (any, error) {
    var errors []string
    
    for _, rule := range n.rules {
        if err := rule.Validate(prepResult); err != nil {
            errors = append(errors, fmt.Sprintf("%s: %v", rule.Name(), err))
        }
    }
    
    if len(errors) > 0 {
        return nil, fmt.Errorf("validation failed: %s", strings.Join(errors, "; "))
    }
    
    return prepResult, nil
}

func (n *ValidationNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if execResult == nil {
        return "invalid", nil
    }
    return "valid", nil
}
```

## Best Practices

1. **Clear Interfaces**: Define clear interfaces for custom nodes
2. **Thread Safety**: Ensure nodes are thread-safe for concurrent use
3. **Resource Management**: Properly manage external resources
4. **Error Handling**: Provide detailed error information
5. **Testing**: Write comprehensive tests for custom logic
6. **Documentation**: Document node behavior and requirements
7. **Monitoring**: Add metrics and logging for observability

## Next Steps

- [RetryableNode Interface](/concepts/nodes#retryablenode-interface) - Custom retry logic
- [FallbackNode Interface](/patterns/fallback) - Graceful degradation
- [Worker Pool](/advanced/worker-pool) - Concurrent task management


================================================
FILE: www/docs/pages/advanced/flow-as-node.mdx
================================================
# Flow as Node

Flows implement the Node interface, allowing them to be used anywhere a node is expected. This enables powerful composition patterns.

## The Node Interface

Flows implement all Node methods:

```go
type Node interface {
    Prep(ctx context.Context, shared *SharedStore) (any, error)
    Exec(ctx context.Context, prepResult any) (any, error)
    Post(ctx context.Context, shared *SharedStore, prepResult, execResult any) (Action, error)
}

// Flow implements Node
var _ Node = (*Flow)(nil)
```

## Basic Usage

Use a flow wherever a node is expected:

```go
// Create a reusable flow
processingFlow := flyt.NewFlow(validateNode)
processingFlow.Connect(validateNode, "valid", transformNode)
processingFlow.Connect(transformNode, flyt.DefaultAction, enrichNode)

// Use the flow as a node
mainFlow := flyt.NewFlow(fetchNode)
mainFlow.Connect(fetchNode, flyt.DefaultAction, processingFlow) // Flow used as node
mainFlow.Connect(processingFlow, flyt.DefaultAction, saveNode)
```

## Flow Lifecycle as Node

Understanding how flows behave as nodes:

```go
// When a flow is used as a node:
// 1. Prep: Prepares the flow's start node
// 2. Exec: Runs the entire flow
// 3. Post: Returns the final action from the flow

func demonstrateFlowLifecycle() {
    subFlow := flyt.NewFlow(startNode)
    subFlow.Connect(startNode, flyt.DefaultAction, endNode)
    
    // When mainFlow executes subFlow:
    // - subFlow.Prep() calls startNode.Prep()
    // - subFlow.Exec() runs the entire sub-flow
    // - subFlow.Post() returns the final action
    
    mainFlow := flyt.NewFlow(initNode)
    mainFlow.Connect(initNode, flyt.DefaultAction, subFlow)
}
```

## Composable Workflows

Build complex workflows from simpler ones:

```go
// Level 1: Basic operations
func createValidationFlow() *flyt.Flow {
    schemaNode := createSchemaValidationNode()
    businessNode := createBusinessValidationNode()
    
    flow := flyt.NewFlow(schemaNode)
    flow.Connect(schemaNode, "valid", businessNode)
    return flow
}

func createEnrichmentFlow() *flyt.Flow {
    fetchNode := createDataFetchNode()
    mergeNode := createDataMergeNode()
    
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, mergeNode)
    return flow
}

// Level 2: Combine basic flows
func createProcessingPipeline() *flyt.Flow {
    validation := createValidationFlow()
    enrichment := createEnrichmentFlow()
    
    pipeline := flyt.NewFlow(validation)
    pipeline.Connect(validation, flyt.DefaultAction, enrichment)
    return pipeline
}

// Level 3: Use in application
func createApplicationFlow() *flyt.Flow {
    auth := createAuthFlow()
    pipeline := createProcessingPipeline()
    audit := createAuditFlow()
    
    app := flyt.NewFlow(auth)
    app.Connect(auth, flyt.DefaultAction, pipeline)
    app.Connect(pipeline, flyt.DefaultAction, audit)
    return app
}
```

## Dynamic Flow Selection

Choose flows at runtime:

```go
type FlowSelector struct {
    flows map[string]*flyt.Flow
}

func (fs *FlowSelector) CreateSelectorNode() flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            flowType := prepResult.(string)
            return flowType, nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            return flyt.Action(execResult.(string)), nil
        }),
    )
}

func (fs *FlowSelector) BuildDynamicFlow() *flyt.Flow {
    selector := fs.CreateSelectorNode()
    mainFlow := flyt.NewFlow(selector)
    
    // Connect different flows based on selection
    for name, flow := range fs.flows {
        mainFlow.Connect(selector, flyt.Action(name), flow)
    }
    
    return mainFlow
}

// Usage
selector := &FlowSelector{
    flows: map[string]*flyt.Flow{
        "simple":  createSimpleFlow(),
        "complex": createComplexFlow(),
        "custom":  createCustomFlow(),
    },
}

dynamicFlow := selector.BuildDynamicFlow()
```

## Flow Factories

Create flows on demand:

```go
type FlowFactory interface {
    CreateFlow(config FlowConfig) *flyt.Flow
}

type ProcessingFlowFactory struct{}

func (f *ProcessingFlowFactory) CreateFlow(config FlowConfig) *flyt.Flow {
    // Create nodes based on configuration
    var nodes []flyt.Node
    
    for _, nodeConfig := range config.Nodes {
        node := createNodeFromConfig(nodeConfig)
        nodes = append(nodes, node)
    }
    
    // Build flow
    flow := flyt.NewFlow(nodes[0])
    for i := 0; i < len(nodes)-1; i++ {
        flow.Connect(nodes[i], flyt.DefaultAction, nodes[i+1])
    }
    
    return flow
}

// Use factory-created flows as nodes
func createDynamicPipeline(factory FlowFactory, configs []FlowConfig) *flyt.Flow {
    pipeline := flyt.NewFlow(startNode)
    previous := flyt.Node(startNode)
    
    for _, config := range configs {
        flow := factory.CreateFlow(config)
        pipeline.Connect(previous, flyt.DefaultAction, flow)
        previous = flow
    }
    
    return pipeline
}
```

## Recursive Flow Patterns

Flows containing themselves:

```go
func createRecursiveProcessingFlow(maxDepth int) *flyt.Flow {
    var flow *flyt.Flow
    
    depthCheck := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            depth := shared.GetInt("recursion_depth")
            return depth, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            depth := prepResult.(int)
            if depth >= maxDepth {
                return "terminate", nil
            }
            return "recurse", nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            if execResult.(string) == "recurse" {
                depth := prepResult.(int)
                shared.Set("recursion_depth", depth+1)
            }
            return flyt.Action(execResult.(string)), nil
        }),
    )
    
    processNode := createProcessNode()
    
    flow = flyt.NewFlow(depthCheck)
    flow.Connect(depthCheck, "recurse", processNode)
    flow.Connect(processNode, flyt.DefaultAction, flow) // Recursive reference
    flow.Connect(depthCheck, "terminate", nil)
    
    return flow
}
```

## Flow Middleware

Wrap flows with additional behavior:

```go
func withLogging(name string, flow *flyt.Flow) *flyt.Flow {
    logStart := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            log.Printf("[%s] Flow starting", name)
            return prepResult, nil
        }),
    )
    
    logEnd := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            log.Printf("[%s] Flow completed", name)
            return prepResult, nil
        }),
    )
    
    wrapped := flyt.NewFlow(logStart)
    wrapped.Connect(logStart, flyt.DefaultAction, flow)
    wrapped.Connect(flow, flyt.DefaultAction, logEnd)
    
    return wrapped
}

// Usage
processFlow := createProcessingFlow()
loggedFlow := withLogging("ProcessingPipeline", processFlow)
```

## Testing Flows as Nodes

Test flow behavior when used as nodes:

```go
func TestFlowAsNode(t *testing.T) {
    // Create a simple flow
    innerFlow := flyt.NewFlow(
        flyt.NewNode(
            flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
                return "inner_result", nil
            }),
        ),
    )
    
    // Test the flow directly
    ctx := context.Background()
    shared := flyt.NewSharedStore()
    
    // Call flow methods as if it were a node
    prepResult, err := innerFlow.Prep(ctx, shared)
    assert.NoError(t, err)
    
    execResult, err := innerFlow.Exec(ctx, prepResult)
    assert.NoError(t, err)
    
    action, err := innerFlow.Post(ctx, shared, prepResult, execResult)
    assert.NoError(t, err)
    assert.Equal(t, flyt.DefaultAction, action)
}
```

## Performance Considerations

Using flows as nodes:

```go
// Lightweight flow - good as node
func createLightweightFlow() *flyt.Flow {
    node := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Simple operation
            return transform(prepResult), nil
        }),
    )
    return flyt.NewFlow(node)
}

// Heavy flow - consider alternatives
func createHeavyFlow() *flyt.Flow {
    // Many nodes, complex logic
    // Consider breaking into smaller flows
    // or using batch processing
}

// Alternative: Use node with embedded logic
func createOptimizedNode() flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Inline the flow logic for performance
            result := step1(prepResult)
            result = step2(result)
            result = step3(result)
            return result, nil
        }),
    )
}
```

## Best Practices

1. **Keep Flows Focused**: Flows used as nodes should have clear, single purposes
2. **Document Behavior**: Clearly document what the flow expects and returns
3. **Test Thoroughly**: Test flows both standalone and as nodes
4. **Consider Performance**: Be mindful of overhead when nesting many flows
5. **Use Meaningful Names**: Name flows to indicate they're used as nodes
6. **Handle Errors**: Ensure proper error propagation through nested flows

## Next Steps

- [Nested Flows](/advanced/nested-flows) - Complex flow composition
- [Nodes](/concepts/nodes) - Node interface details
- [Flows](/concepts/flows) - Flow fundamentals


================================================
FILE: www/docs/pages/advanced/nested-flows.mdx
================================================
# Nested Flows

Compose complex workflows by nesting flows within flows, creating modular and reusable workflow components.

## Basic Nested Flow

Use a flow as a node in another flow:

```go
// Create a sub-flow for validation
validationFlow := func() *flyt.Flow {
    schemaCheck := createSchemaCheckNode()
    businessRules := createBusinessRulesNode()
    
    flow := flyt.NewFlow(schemaCheck)
    flow.Connect(schemaCheck, "valid", businessRules)
    flow.Connect(schemaCheck, "invalid", nil)
    
    return flow
}()

// Use in main flow
mainFlow := flyt.NewFlow(fetchNode)
mainFlow.Connect(fetchNode, flyt.DefaultAction, validationFlow)
mainFlow.Connect(validationFlow, flyt.DefaultAction, processNode)
```

## Reusable Flow Components

Create modular flow components:

```go
// Reusable authentication flow
func createAuthFlow() *flyt.Flow {
    checkToken := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            token := prepResult.(string)
            return validateToken(token)
        }),
    )
    
    refreshToken := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            return refreshAuthToken()
        }),
    )
    
    flow := flyt.NewFlow(checkToken)
    flow.Connect(checkToken, "expired", refreshToken)
    flow.Connect(checkToken, "valid", nil)
    flow.Connect(refreshToken, flyt.DefaultAction, nil)
    
    return flow
}

// Use in multiple places
apiFlow := flyt.NewFlow(startNode)
apiFlow.Connect(startNode, flyt.DefaultAction, createAuthFlow())

adminFlow := flyt.NewFlow(adminNode)
adminFlow.Connect(adminNode, flyt.DefaultAction, createAuthFlow())
```

## Hierarchical Workflows

Build multi-level workflow hierarchies:

```go
// Level 3: Atomic operations
func createDatabaseOperation() *flyt.Flow {
    connect := createConnectNode()
    query := createQueryNode()
    disconnect := createDisconnectNode()
    
    flow := flyt.NewFlow(connect)
    flow.Connect(connect, flyt.DefaultAction, query)
    flow.Connect(query, flyt.DefaultAction, disconnect)
    
    return flow
}

// Level 2: Business operations
func createUserOperation() *flyt.Flow {
    validate := createValidateUserNode()
    dbOp := createDatabaseOperation()
    notify := createNotificationNode()
    
    flow := flyt.NewFlow(validate)
    flow.Connect(validate, "valid", dbOp)
    flow.Connect(dbOp, flyt.DefaultAction, notify)
    
    return flow
}

// Level 1: Application flow
func createApplicationFlow() *flyt.Flow {
    auth := createAuthFlow()
    userOp := createUserOperation()
    audit := createAuditFlow()
    
    flow := flyt.NewFlow(auth)
    flow.Connect(auth, flyt.DefaultAction, userOp)
    flow.Connect(userOp, flyt.DefaultAction, audit)
    
    return flow
}
```

## Conditional Nesting

Dynamically choose nested flows:

```go
routerNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        request := prepResult.(Request)
        return request.Type, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        return flyt.Action(execResult.(string)), nil
    }),
)

mainFlow := flyt.NewFlow(routerNode)
mainFlow.Connect(routerNode, "user", createUserFlow())
mainFlow.Connect(routerNode, "admin", createAdminFlow())
mainFlow.Connect(routerNode, "api", createAPIFlow())
```

## Shared Context in Nested Flows

Pass context through nested flows:

```go
func createNestedFlowWithContext(parentContext map[string]any) *flyt.Flow {
    node := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Access parent context
            for k, v := range parentContext {
                shared.Set(k, v)
            }
            
            // Get data from parent flow
            parentData := shared.GetMap("parent_data")
            return parentData, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Process with parent context
            return processWithContext(prepResult, parentContext), nil
        }),
    )
    
    return flyt.NewFlow(node)
}
```

## Error Propagation

Handle errors across nested flows:

```go
func createErrorHandlingFlow() *flyt.Flow {
    subFlow := createSubFlow()
    errorHandler := createErrorHandlerNode()
    
    mainFlow := flyt.NewFlow(startNode)
    mainFlow.Connect(startNode, flyt.DefaultAction, subFlow)
    mainFlow.Connect(subFlow, "error", errorHandler)
    mainFlow.Connect(subFlow, flyt.DefaultAction, successNode)
    
    // Error handler can retry or recover
    mainFlow.Connect(errorHandler, "retry", subFlow)
    mainFlow.Connect(errorHandler, "abort", nil)
    
    return mainFlow
}
```

## Recursive Flows

Create recursive workflow patterns:

```go
func createRecursiveFlow(maxDepth int) *flyt.Flow {
    checkDepth := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            depth := shared.GetInt("depth")
            return depth, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            depth := prepResult.(int)
            if depth >= maxDepth {
                return "max_depth", nil
            }
            return "continue", nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            if execResult.(string) == "continue" {
                depth := prepResult.(int)
                shared.Set("depth", depth+1)
            }
            return flyt.Action(execResult.(string)), nil
        }),
    )
    
    processNode := createProcessNode()
    
    flow := flyt.NewFlow(checkDepth)
    flow.Connect(checkDepth, "continue", processNode)
    flow.Connect(processNode, flyt.DefaultAction, flow) // Recursive connection
    flow.Connect(checkDepth, "max_depth", nil)
    
    return flow
}
```

## Parallel Nested Flows

Execute nested flows in parallel:

```go
func createParallelNestedFlow() *flyt.Flow {
    splitNode := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Split data for parallel processing
            data := prepResult.(Data)
            shared.Set("part1", data.Part1)
            shared.Set("part2", data.Part2)
            return nil, nil
        }),
    )
    
    // Create parallel sub-flows
    flow1 := createProcessingFlow1()
    flow2 := createProcessingFlow2()
    
    // Merge results
    mergeNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            result1 := shared.GetMap("result1")
            result2 := shared.GetMap("result2")
            return map[string]any{
                "result1": result1,
                "result2": result2,
            }, nil
        }),
    )
    
    // Connect with parallel execution
    mainFlow := flyt.NewFlow(splitNode)
    
    // Both flows execute after split
    mainFlow.Connect(splitNode, "flow1", flow1)
    mainFlow.Connect(splitNode, "flow2", flow2)
    
    // Both must complete before merge
    mainFlow.Connect(flow1, flyt.DefaultAction, mergeNode)
    mainFlow.Connect(flow2, flyt.DefaultAction, mergeNode)
    
    return mainFlow
}
```

## Dynamic Flow Composition

Build flows at runtime:

```go
func createDynamicFlow(config FlowConfig) *flyt.Flow {
    startNode := createStartNode()
    flow := flyt.NewFlow(startNode)
    
    previousNode := flyt.Node(startNode)
    
    for _, step := range config.Steps {
        var stepFlow *flyt.Flow
        
        switch step.Type {
        case "validate":
            stepFlow = createValidationFlow(step.Config)
        case "process":
            stepFlow = createProcessingFlow(step.Config)
        case "save":
            stepFlow = createSaveFlow(step.Config)
        }
        
        if stepFlow != nil {
            flow.Connect(previousNode, flyt.DefaultAction, stepFlow)
            previousNode = stepFlow
        }
    }
    
    return flow
}
```

## Testing Nested Flows

Test nested flows in isolation:

```go
func TestNestedFlow(t *testing.T) {
    // Test sub-flow independently
    subFlow := createSubFlow()
    subShared := flyt.NewSharedStore()
    subShared.Set("test_input", "data")
    
    err := subFlow.Run(context.Background(), subShared)
    assert.NoError(t, err)
    
    // Test main flow with mocked sub-flow
    mockSubFlow := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            return "mocked_result", nil
        }),
    )
    
    mainFlow := flyt.NewFlow(startNode)
    mainFlow.Connect(startNode, flyt.DefaultAction, mockSubFlow)
    
    err = mainFlow.Run(context.Background(), flyt.NewSharedStore())
    assert.NoError(t, err)
}
```

## Best Practices

1. **Keep Flows Focused**: Each flow should have a single, clear purpose
2. **Minimize Coupling**: Flows should communicate through well-defined interfaces
3. **Document Dependencies**: Clearly document what each nested flow expects
4. **Test in Isolation**: Test nested flows independently
5. **Avoid Deep Nesting**: Too many levels make debugging difficult
6. **Use Meaningful Names**: Name flows based on their business function

## Next Steps

- [Flow as Node](/advanced/flow-as-node) - Flows implementing Node interface
- [Batch Flows](/advanced/batch-flows) - Running flows in batches
- [Flows](/concepts/flows) - Flow fundamentals


================================================
FILE: www/docs/pages/advanced/utilities.mdx
================================================
# Utilities

Helper functions and utilities to simplify common tasks in Flyt workflows.

## ToSlice

Convert various types to slices for batch processing:

```go
// Convert different types to []any
stringSlice := flyt.ToSlice([]string{"a", "b", "c"})
intSlice := flyt.ToSlice([]int{1, 2, 3})
singleItem := flyt.ToSlice("single item") // Returns []any{"single item"}
nilValue := flyt.ToSlice(nil) // Returns empty []any{}

// Useful for batch processing
shared.Set("items", flyt.ToSlice(data))
```

### Implementation Details

```go
func ToSlice(v any) []any {
    if v == nil {
        return []any{}
    }
    
    rv := reflect.ValueOf(v)
    if rv.Kind() == reflect.Slice {
        result := make([]any, rv.Len())
        for i := 0; i < rv.Len(); i++ {
            result[i] = rv.Index(i).Interface()
        }
        return result
    }
    
    // Single item
    return []any{v}
}
```

## Custom Utility Functions

Create your own utilities:

### Retry Helper

```go
func RetryOperation(operation func() error, maxRetries int, backoff time.Duration) error {
    var lastErr error
    
    for i := 0; i < maxRetries; i++ {
        if err := operation(); err == nil {
            return nil
        } else {
            lastErr = err
            if i < maxRetries-1 {
                time.Sleep(backoff * time.Duration(i+1))
            }
        }
    }
    
    return fmt.Errorf("operation failed after %d retries: %w", maxRetries, lastErr)
}

// Usage in node
func (n *MyNode) Exec(ctx context.Context, prepResult any) (any, error) {
    var result any
    
    err := RetryOperation(func() error {
        var err error
        result, err = callAPI(prepResult)
        return err
    }, 3, time.Second)
    
    return result, err
}
```

### Parallel Map

```go
func ParallelMap[T any, R any](items []T, fn func(T) R, workers int) []R {
    results := make([]R, len(items))
    
    var wg sync.WaitGroup
    semaphore := make(chan struct{}, workers)
    
    for i, item := range items {
        wg.Add(1)
        go func(index int, data T) {
            defer wg.Done()
            
            semaphore <- struct{}{}
            defer func() { <-semaphore }()
            
            results[index] = fn(data)
        }(i, item)
    }
    
    wg.Wait()
    return results
}

// Usage
results := ParallelMap(items, processItem, 10)
```

### Type-Safe Getters

Flyt provides built-in type-safe getters:

```go
// Built-in type-safe getters
userID := shared.GetInt("user_id")           // Returns 0 if not found
name := shared.GetString("name")              // Returns "" if not found
enabled := shared.GetBool("enabled")          // Returns false if not found

// With custom defaults
userID = shared.GetIntOr("user_id", -1)
name = shared.GetStringOr("name", "anonymous")
enabled = shared.GetBoolOr("enabled", true)

// For complex types, use Bind
var config Config
err := shared.Bind("config", &config)
```

### Chunk Slice

```go
func ChunkSlice[T any](slice []T, chunkSize int) [][]T {
    var chunks [][]T
    
    for i := 0; i < len(slice); i += chunkSize {
        end := i + chunkSize
        if end > len(slice) {
            end = len(slice)
        }
        chunks = append(chunks, slice[i:end])
    }
    
    return chunks
}

// Usage in batch processing
chunks := ChunkSlice(items, 100)
for _, chunk := range chunks {
    processChunk(chunk)
}
```

### Merge Maps

```go
func MergeMaps(maps ...map[string]any) map[string]any {
    result := make(map[string]any)
    
    for _, m := range maps {
        for k, v := range m {
            result[k] = v
        }
    }
    
    return result
}

// Usage
config := MergeMaps(defaultConfig, userConfig, overrides)
```

### Filter Slice

```go
func FilterSlice[T any](slice []T, predicate func(T) bool) []T {
    result := make([]T, 0)
    
    for _, item := range slice {
        if predicate(item) {
            result = append(result, item)
        }
    }
    
    return result
}

// Usage
validItems := FilterSlice(items, func(item Item) bool {
    return item.IsValid()
})
```

### Timeout Wrapper

```go
func WithTimeout[T any](ctx context.Context, timeout time.Duration, fn func(context.Context) (T, error)) (T, error) {
    ctx, cancel := context.WithTimeout(ctx, timeout)
    defer cancel()
    
    type result struct {
        value T
        err   error
    }
    
    done := make(chan result, 1)
    
    go func() {
        value, err := fn(ctx)
        done <- result{value, err}
    }()
    
    select {
    case res := <-done:
        return res.value, res.err
    case <-ctx.Done():
        var zero T
        return zero, ctx.Err()
    }
}

// Usage
result, err := WithTimeout(ctx, 5*time.Second, func(ctx context.Context) (string, error) {
    return fetchData(ctx)
})
```

### Pipeline Builder

```go
type Pipeline[T any] struct {
    stages []func(T) T
}

func NewPipeline[T any]() *Pipeline[T] {
    return &Pipeline[T]{
        stages: make([]func(T) T, 0),
    }
}

func (p *Pipeline[T]) Add(stage func(T) T) *Pipeline[T] {
    p.stages = append(p.stages, stage)
    return p
}

func (p *Pipeline[T]) Execute(input T) T {
    result := input
    for _, stage := range p.stages {
        result = stage(result)
    }
    return result
}

// Usage
pipeline := NewPipeline[string]().
    Add(strings.TrimSpace).
    Add(strings.ToLower).
    Add(func(s string) string {
        return strings.ReplaceAll(s, " ", "_")
    })

result := pipeline.Execute("  Hello World  ")
// Result: "hello_world"
```

### Error Aggregator

```go
type ErrorAggregator struct {
    errors []error
    mu     sync.Mutex
}

func (e *ErrorAggregator) Add(err error) {
    if err == nil {
        return
    }
    
    e.mu.Lock()
    e.errors = append(e.errors, err)
    e.mu.Unlock()
}

func (e *ErrorAggregator) Error() error {
    e.mu.Lock()
    defer e.mu.Unlock()
    
    if len(e.errors) == 0 {
        return nil
    }
    
    if len(e.errors) == 1 {
        return e.errors[0]
    }
    
    return fmt.Errorf("multiple errors (%d): %v", len(e.errors), e.errors)
}

// Usage
aggregator := &ErrorAggregator{}

for _, item := range items {
    if err := processItem(item); err != nil {
        aggregator.Add(err)
    }
}

if err := aggregator.Error(); err != nil {
    return nil, err
}
```

### Context Values Helper

```go
type ContextKey string

const (
    RequestIDKey ContextKey = "request_id"
    UserIDKey    ContextKey = "user_id"
)

func WithRequestID(ctx context.Context, requestID string) context.Context {
    return context.WithValue(ctx, RequestIDKey, requestID)
}

func GetRequestID(ctx context.Context) (string, bool) {
    id, ok := ctx.Value(RequestIDKey).(string)
    return id, ok
}

// Usage in nodes
func (n *LoggingNode) Exec(ctx context.Context, prepResult any) (any, error) {
    requestID, _ := GetRequestID(ctx)
    log.Printf("[%s] Processing: %v", requestID, prepResult)
    
    return process(prepResult)
}
```

### Debounce Function

```go
func Debounce(fn func(), delay time.Duration) func() {
    var timer *time.Timer
    var mu sync.Mutex
    
    return func() {
        mu.Lock()
        defer mu.Unlock()
        
        if timer != nil {
            timer.Stop()
        }
        
        timer = time.AfterFunc(delay, fn)
    }
}

// Usage
saveDebounced := Debounce(func() {
    saveToDatabase()
}, 5*time.Second)

// Call multiple times, only last one executes
saveDebounced()
saveDebounced()
saveDebounced()
```

## Testing Utilities

### Mock SharedStore

```go
type MockSharedStore struct {
    data map[string]any
    mu   sync.RWMutex
}

func NewMockSharedStore(initial map[string]any) *MockSharedStore {
    return &MockSharedStore{
        data: initial,
    }
}

func (m *MockSharedStore) Get(key string) (any, bool) {
    m.mu.RLock()
    defer m.mu.RUnlock()
    val, ok := m.data[key]
    return val, ok
}

func (m *MockSharedStore) Set(key string, value any) {
    m.mu.Lock()
    defer m.mu.Unlock()
    m.data[key] = value
}
```

### Test Node Builder

```go
func TestNode(execFn func(context.Context, any) (any, error)) flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(execFn),
    )
}

// Usage in tests
node := TestNode(func(ctx context.Context, input any) (any, error) {
    return "test_result", nil
})
```

## Best Practices

1. **Keep Utilities Generic**: Make them reusable across projects
2. **Document Usage**: Provide clear examples
3. **Test Thoroughly**: Utilities should be well-tested
4. **Handle Edge Cases**: Consider nil values and empty inputs
5. **Use Type Parameters**: Leverage Go generics where appropriate
6. **Thread Safety**: Ensure utilities are safe for concurrent use

## Next Steps

- [Custom Nodes](/advanced/custom-nodes) - Build sophisticated nodes
- [Best Practices](/best-practices) - General guidelines
- [Examples](https://github.com/mark3labs/flyt/tree/main/cookbook) - See utilities in action


================================================
FILE: www/docs/pages/advanced/worker-pool.mdx
================================================
# Worker Pool

Manage concurrent task execution with fine-grained control using the WorkerPool utility.

## Basic Worker Pool

Create and use a worker pool:

```go
// Create a pool with 10 workers
pool := flyt.NewWorkerPool(10)

// Submit tasks
for i := 0; i < 100; i++ {
    taskID := i
    pool.Submit(func() {
        // Process task
        result := processTask(taskID)
        fmt.Printf("Task %d completed: %v\n", taskID, result)
    })
}

// Wait for all tasks to complete
pool.Wait()

// Clean up
pool.Close()
```

## Worker Pool with Results

Collect results from worker pool:

```go
type ResultCollector struct {
    mu      sync.Mutex
    results []Result
}

func processWithWorkerPool(items []Item) []Result {
    pool := flyt.NewWorkerPool(5)
    collector := &ResultCollector{
        results: make([]Result, len(items)),
    }
    
    for i, item := range items {
        index := i
        data := item
        
        pool.Submit(func() {
            result := processItem(data)
            
            collector.mu.Lock()
            collector.results[index] = result
            collector.mu.Unlock()
        })
    }
    
    pool.Wait()
    pool.Close()
    
    return collector.results
}
```

## Dynamic Worker Scaling

Adjust worker count based on load:

```go
type DynamicWorkerPool struct {
    minWorkers int
    maxWorkers int
    pool       *flyt.WorkerPool
    load       int32
    mu         sync.RWMutex
}

func NewDynamicWorkerPool(min, max int) *DynamicWorkerPool {
    return &DynamicWorkerPool{
        minWorkers: min,
        maxWorkers: max,
        pool:       flyt.NewWorkerPool(min),
    }
}

func (p *DynamicWorkerPool) Submit(task func()) {
    currentLoad := atomic.AddInt32(&p.load, 1)
    
    // Scale up if needed
    if currentLoad > int32(p.getCurrentWorkers()*2) {
        p.scaleUp()
    }
    
    p.pool.Submit(func() {
        task()
        
        newLoad := atomic.AddInt32(&p.load, -1)
        
        // Scale down if idle
        if newLoad < int32(p.getCurrentWorkers()/2) {
            p.scaleDown()
        }
    })
}

func (p *DynamicWorkerPool) scaleUp() {
    p.mu.Lock()
    defer p.mu.Unlock()
    
    current := p.getCurrentWorkers()
    if current < p.maxWorkers {
        // Create new pool with more workers
        newPool := flyt.NewWorkerPool(min(current*2, p.maxWorkers))
        p.pool.Close()
        p.pool = newPool
    }
}
```

## Rate-Limited Worker Pool

Control processing rate:

```go
func createRateLimitedPool(workers int, rps int) *RateLimitedPool {
    limiter := rate.NewLimiter(rate.Limit(rps), 1)
    pool := flyt.NewWorkerPool(workers)
    
    return &RateLimitedPool{
        pool:    pool,
        limiter: limiter,
    }
}

type RateLimitedPool struct {
    pool    *flyt.WorkerPool
    limiter *rate.Limiter
}

func (p *RateLimitedPool) Submit(ctx context.Context, task func()) error {
    // Wait for rate limit
    if err := p.limiter.Wait(ctx); err != nil {
        return err
    }
    
    p.pool.Submit(task)
    return nil
}
```

## Priority Queue Worker Pool

Process tasks by priority:

```go
type PriorityTask struct {
    Priority int
    Task     func()
    ID       string
}

type PriorityWorkerPool struct {
    workers int
    queue   *PriorityQueue
    pool    *flyt.WorkerPool
    running bool
    mu      sync.Mutex
}

func NewPriorityWorkerPool(workers int) *PriorityWorkerPool {
    p := &PriorityWorkerPool{
        workers: workers,
        queue:   NewPriorityQueue(),
        pool:    flyt.NewWorkerPool(workers),
        running: true,
    }
    
    // Start dispatcher
    go p.dispatch()
    
    return p
}

func (p *PriorityWorkerPool) Submit(priority int, task func()) {
    p.queue.Push(PriorityTask{
        Priority: priority,
        Task:     task,
        ID:       generateID(),
    })
}

func (p *PriorityWorkerPool) dispatch() {
    for p.running {
        task := p.queue.Pop() // Blocks until task available
        if task != nil {
            p.pool.Submit(task.Task)
        }
    }
}
```

## Worker Pool with Timeout

Handle task timeouts:

```go
func createTimeoutPool(workers int, timeout time.Duration) *TimeoutPool {
    return &TimeoutPool{
        pool:    flyt.NewWorkerPool(workers),
        timeout: timeout,
    }
}

type TimeoutPool struct {
    pool    *flyt.WorkerPool
    timeout time.Duration
}

func (p *TimeoutPool) Submit(task func() error) error {
    errChan := make(chan error, 1)
    
    p.pool.Submit(func() {
        done := make(chan error, 1)
        
        go func() {
            done <- task()
        }()
        
        select {
        case err := <-done:
            errChan <- err
        case <-time.After(p.timeout):
            errChan <- fmt.Errorf("task timeout after %v", p.timeout)
        }
    })
    
    return <-errChan
}
```

## Worker Pool in Nodes

Use worker pools within nodes:

```go
type ParallelProcessingNode struct {
    *flyt.BaseNode
    pool *flyt.WorkerPool
}

func NewParallelProcessingNode(workers int) *ParallelProcessingNode {
    return &ParallelProcessingNode{
        BaseNode: flyt.NewBaseNode(),
        pool:     flyt.NewWorkerPool(workers),
    }
}

func (n *ParallelProcessingNode) Exec(ctx context.Context, prepResult any) (any, error) {
    items := prepResult.([]Item)
    results := make([]Result, len(items))
    errors := make([]error, len(items))
    
    var wg sync.WaitGroup
    
    for i, item := range items {
        wg.Add(1)
        index := i
        data := item
        
        n.pool.Submit(func() {
            defer wg.Done()
            
            result, err := processItem(data)
            results[index] = result
            errors[index] = err
        })
    }
    
    // Wait with context
    done := make(chan struct{})
    go func() {
        wg.Wait()
        close(done)
    }()
    
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    case <-done:
        // Check for errors
        for _, err := range errors {
            if err != nil {
                return results, fmt.Errorf("processing failed: %w", err)
            }
        }
        return results, nil
    }
}

func (n *ParallelProcessingNode) Close() {
    n.pool.Close()
}
```

## Batch Processing with Worker Pool

Process batches efficiently:

```go
func processBatchesWithPool(items []Item, batchSize int, workers int) []Result {
    pool := flyt.NewWorkerPool(workers)
    results := make([]Result, len(items))
    
    // Process in batches
    for i := 0; i < len(items); i += batchSize {
        end := min(i+batchSize, len(items))
        batch := items[i:end]
        batchStart := i
        
        pool.Submit(func() {
            batchResults := processBatch(batch)
            
            // Store results
            for j, result := range batchResults {
                results[batchStart+j] = result
            }
        })
    }
    
    pool.Wait()
    pool.Close()
    
    return results
}
```

## Monitoring Worker Pool

Track pool performance:

```go
type MonitoredPool struct {
    pool      *flyt.WorkerPool
    submitted int64
    completed int64
    failed    int64
    totalTime int64
}

func (p *MonitoredPool) Submit(task func() error) {
    atomic.AddInt64(&p.submitted, 1)
    
    p.pool.Submit(func() {
        start := time.Now()
        
        err := task()
        
        duration := time.Since(start)
        atomic.AddInt64(&p.totalTime, int64(duration))
        
        if err != nil {
            atomic.AddInt64(&p.failed, 1)
        } else {
            atomic.AddInt64(&p.completed, 1)
        }
    })
}

func (p *MonitoredPool) GetStats() map[string]int64 {
    return map[string]int64{
        "submitted":     atomic.LoadInt64(&p.submitted),
        "completed":     atomic.LoadInt64(&p.completed),
        "failed":        atomic.LoadInt64(&p.failed),
        "avg_time_ms":   p.getAverageTime(),
        "pending":       p.getPendingCount(),
    }
}
```

## Circuit Breaker Pool

Prevent overload with circuit breaker:

```go
type CircuitBreakerPool struct {
    pool        *flyt.WorkerPool
    failures    int32
    threshold   int32
    resetTime   time.Duration
    lastFailure time.Time
    mu          sync.RWMutex
}

func (p *CircuitBreakerPool) Submit(task func() error) error {
    if p.isOpen() {
        return fmt.Errorf("circuit breaker open")
    }
    
    p.pool.Submit(func() {
        err := task()
        
        if err != nil {
            failures := atomic.AddInt32(&p.failures, 1)
            
            if failures >= p.threshold {
                p.mu.Lock()
                p.lastFailure = time.Now()
                p.mu.Unlock()
            }
        } else {
            // Reset on success
            atomic.StoreInt32(&p.failures, 0)
        }
    })
    
    return nil
}

func (p *CircuitBreakerPool) isOpen() bool {
    p.mu.RLock()
    defer p.mu.RUnlock()
    
    if atomic.LoadInt32(&p.failures) >= p.threshold {
        if time.Since(p.lastFailure) < p.resetTime {
            return true
        }
        // Reset after timeout
        atomic.StoreInt32(&p.failures, 0)
    }
    
    return false
}
```

## Best Practices

1. **Size Appropriately**: Set worker count based on workload and resources
2. **Handle Panics**: Recover from panics in worker goroutines
3. **Clean Up**: Always close pools when done
4. **Monitor Performance**: Track metrics for optimization
5. **Avoid Blocking**: Don't block workers with long waits
6. **Test Concurrency**: Test with various worker counts and loads

## Next Steps

- [Batch Processing](/advanced/batch-processing) - High-level batch operations
- [Custom Nodes](/advanced/custom-nodes) - Build nodes with worker pools
- [Best Practices](/best-practices) - General guidelines


================================================
FILE: www/docs/pages/concepts/actions.mdx
================================================
# Actions

Actions are strings returned by a node's Post phase that determine the next step in a workflow. They provide dynamic, runtime control over flow execution.

## How Actions Work

When a node completes, its Post phase returns an action:

```go
func (n *MyNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if success {
        return "continue", nil
    }
    return "retry", nil
}
```

The flow then routes to the node connected with that action:

```go
flow := flyt.NewFlow(startNode)
flow.Connect(startNode, "continue", processNode)
flow.Connect(startNode, "retry", retryNode)
```

## Default Action

The most common action is `flyt.DefaultAction`:

```go
// Using the constant
return flyt.DefaultAction, nil  // Returns "default"

// In flow connections
flow.Connect(node1, flyt.DefaultAction, node2)
```

## Action-Based Routing

### Simple Branching

```go
validationNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        data := prepResult.(string)
        return len(data) > 0, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        if execResult.(bool) {
            return "valid", nil
        }
        return "invalid", nil
    }),
)

flow := flyt.NewFlow(validationNode)
flow.Connect(validationNode, "valid", processNode)
flow.Connect(validationNode, "invalid", errorNode)
```

### Multi-Way Branching

```go
categoryNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        value := prepResult.(int)
        if value < 10 {
            return "small", nil
        } else if value < 100 {
            return "medium", nil
        }
        return "large", nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        return flyt.Action(execResult.(string)), nil
    }),
)

flow := flyt.NewFlow(categoryNode)
flow.Connect(categoryNode, "small", smallHandler)
flow.Connect(categoryNode, "medium", mediumHandler)
flow.Connect(categoryNode, "large", largeHandler)
```

## Flow Termination

If no connection exists for an action, the flow terminates:

```go
flow := flyt.NewFlow(node1)
flow.Connect(node1, "continue", node2)
// If node1 returns "stop", flow ends (no connection for "stop")
```

Explicitly terminate by connecting to nil:

```go
flow.Connect(finalNode, "done", nil)
```

## Common Patterns

### Success/Failure Pattern

```go
func makeDecisionPost(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if err := execResult.(error); err != nil {
        return "failure", nil
    }
    return "success", nil
}
```

### Retry Pattern

```go
func retryablePost(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    count := shared.GetInt("attempts")
    
    if execResult == nil && count < 3 {
        shared.Set("attempts", count + 1)
        return "retry", nil
    }
    return "continue", nil
}
```

### State Machine Pattern

```go
func statePost(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    currentState := shared.GetString("state")
    
    switch currentState {
    case "init":
        shared.Set("state", "processing")
        return "process", nil
    case "processing":
        shared.Set("state", "complete")
        return "finalize", nil
    default:
        return "done", nil
    }
}
```

## Dynamic Actions

Actions can be computed at runtime:

```go
func dynamicPost(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    result := execResult.(map[string]any)
    nextAction := result["next_action"].(string)
    return flyt.Action(nextAction), nil
}
```

## Best Practices

1. **Use Descriptive Names**: Actions should clearly indicate their purpose
2. **Document Actions**: List all possible actions a node can return
3. **Handle All Cases**: Ensure all possible actions have connections or intentionally terminate
4. **Consistent Naming**: Use a consistent naming scheme across your application
5. **Avoid Magic Strings**: Define action constants for reusability

```go
const (
    ActionValidate = flyt.Action("validate")
    ActionProcess  = flyt.Action("process")
    ActionComplete = flyt.Action("complete")
    ActionError    = flyt.Action("error")
)
```

## Next Steps

- [Flows](/concepts/flows) - Connect nodes with actions
- [Conditional Branching](/patterns/branching) - Advanced routing patterns
- [Nested Flows](/advanced/nested-flows) - Compose complex workflows


================================================
FILE: www/docs/pages/concepts/flows.mdx
================================================
# Flows

Flows connect nodes together to create workflows. They define the execution path based on actions returned by nodes.

## Creating Flows

Start with a single node and build connections:

```go
// Create nodes
startNode := createStartNode()
processNode := createProcessNode()
endNode := createEndNode()

// Build flow
flow := flyt.NewFlow(startNode)
flow.Connect(startNode, flyt.DefaultAction, processNode)
flow.Connect(processNode, flyt.DefaultAction, endNode)
```

## Running Flows

Execute a flow with a context and SharedStore:

```go
ctx := context.Background()
shared := flyt.NewSharedStore()

// Add initial data
shared.Set("input", "data to process")

// Run the flow
err := flow.Run(ctx, shared)
if err != nil {
    log.Fatal(err)
}

// Get results
result := shared.GetString("output")
```

## Flow Connections

### Linear Flow

Simple sequential execution:

```go
flow := flyt.NewFlow(node1)
flow.Connect(node1, flyt.DefaultAction, node2)
flow.Connect(node2, flyt.DefaultAction, node3)
flow.Connect(node3, flyt.DefaultAction, nil) // Terminate
```

### Branching Flow

Multiple paths based on actions:

```go
flow := flyt.NewFlow(decisionNode)
flow.Connect(decisionNode, "path_a", nodeA)
flow.Connect(decisionNode, "path_b", nodeB)
flow.Connect(nodeA, flyt.DefaultAction, mergeNode)
flow.Connect(nodeB, flyt.DefaultAction, mergeNode)
```

### Loop Flow

Create cycles for retry or iteration:

```go
flow := flyt.NewFlow(startNode)
flow.Connect(startNode, flyt.DefaultAction, processNode)
flow.Connect(processNode, "retry", startNode)    // Loop back
flow.Connect(processNode, "success", endNode)
```

## Flow as Node

Flows implement the Node interface and can be used as nodes:

```go
// Create a sub-flow
subFlow := flyt.NewFlow(validateNode)
subFlow.Connect(validateNode, flyt.DefaultAction, transformNode)

// Use sub-flow in main flow
mainFlow := flyt.NewFlow(fetchNode)
mainFlow.Connect(fetchNode, flyt.DefaultAction, subFlow)
mainFlow.Connect(subFlow, flyt.DefaultAction, saveNode)
```

## Complex Flow Patterns

### Diamond Pattern

Split and merge execution paths:

```go
flow := flyt.NewFlow(splitNode)
flow.Connect(splitNode, "path1", process1)
flow.Connect(splitNode, "path2", process2)
flow.Connect(process1, flyt.DefaultAction, mergeNode)
flow.Connect(process2, flyt.DefaultAction, mergeNode)
```

### Error Handling Flow

Centralized error handling:

```go
flow := flyt.NewFlow(startNode)
flow.Connect(startNode, "error", errorHandler)
flow.Connect(startNode, flyt.DefaultAction, processNode)
flow.Connect(processNode, "error", errorHandler)
flow.Connect(processNode, flyt.DefaultAction, saveNode)
flow.Connect(saveNode, "error", errorHandler)
```

### Pipeline Pattern

Data transformation pipeline:

```go
flow := flyt.NewFlow(fetchNode)
flow.Connect(fetchNode, flyt.DefaultAction, validateNode)
flow.Connect(validateNode, "valid", transformNode)
flow.Connect(validateNode, "invalid", rejectNode)
flow.Connect(transformNode, flyt.DefaultAction, enrichNode)
flow.Connect(enrichNode, flyt.DefaultAction, saveNode)
```

## Flow Composition

Build complex flows from simpler ones:

```go
func createValidationFlow() *flyt.Flow {
    checkFormat := createFormatChecker()
    checkBusiness := createBusinessRules()
    
    flow := flyt.NewFlow(checkFormat)
    flow.Connect(checkFormat, "valid", checkBusiness)
    return flow
}

func createMainFlow() *flyt.Flow {
    fetch := createFetchNode()
    validation := createValidationFlow()
    process := createProcessNode()
    
    flow := flyt.NewFlow(fetch)
    flow.Connect(fetch, flyt.DefaultAction, validation)
    flow.Connect(validation, flyt.DefaultAction, process)
    return flow
}
```

## Debugging Flows

Add logging nodes for debugging:

```go
func createLoggingNode(name string) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            log.Printf("[%s] Prep: SharedStore keys: %v", name, shared.GetAll())
            return nil, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            log.Printf("[%s] Exec", name)
            return prepResult, nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            log.Printf("[%s] Post: Result: %v", name, execResult)
            return flyt.DefaultAction, nil
        }),
    )
}

// Insert between nodes for debugging
flow.Connect(node1, flyt.DefaultAction, createLoggingNode("debug"))
flow.Connect(createLoggingNode("debug"), flyt.DefaultAction, node2)
```

## Best Practices

1. **Start Simple**: Build flows incrementally, testing as you go
2. **Name Nodes**: Give nodes descriptive names for easier debugging
3. **Document Flows**: Create diagrams or comments explaining flow logic
4. **Reuse Flows**: Extract common patterns into reusable sub-flows
5. **Test Flows**: Write tests for different execution paths

## Visualizing Flows

Document your flows with clear structure:

```go
// Flow structure:
// Start -> Validate -> Process -> Save
//              └─> Error (on invalid)

flow := flyt.NewFlow(startNode)
flow.Connect(startNode, flyt.DefaultAction, validateNode)
flow.Connect(validateNode, "valid", processNode)
flow.Connect(validateNode, "invalid", errorNode)
flow.Connect(processNode, flyt.DefaultAction, saveNode)
```

## Next Steps

- [Shared Store](/concepts/shared-store) - Share data between nodes
- [Nested Flows](/advanced/nested-flows) - Advanced composition
- [Batch Flows](/advanced/batch-flows) - Process multiple inputs


================================================
FILE: www/docs/pages/concepts/nodes.mdx
================================================
# Nodes

Nodes are the fundamental building blocks of Flyt workflows. Each node represents a single unit of work with a well-defined lifecycle.

## Node Lifecycle

Every node has three phases that execute in order:

### 1. Prep Phase

The preparation phase reads from the SharedStore and prepares data for execution.

```go
func (n *MyNode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    // Read data using type-safe getters
    userID := shared.GetInt("user_id")
    apiKey := shared.GetString("api_key")
    
    // Or bind complex types
    var config Config
    if err := shared.Bind("config", &config); err != nil {
        return nil, err
    }
    
    // Prepare and return data for Exec phase
    return map[string]any{
        "userID": userID,
        "apiKey": apiKey,
        "config": config,
    }, nil
}
```

### 2. Exec Phase

The execution phase performs the main work. This phase can be retried on failure.

```go
func (n *MyNode) Exec(ctx context.Context, prepResult any) (any, error) {
    data := prepResult.(map[string]any)
    
    // Perform the main operation
    result, err := processData(data["input"])
    if err != nil {
        return nil, err // Will trigger retry if configured
    }
    
    return result, nil
}
```

### 3. Post Phase

The post-processing phase handles results and determines the next action.

```go
func (n *MyNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    // Store results
    shared.Set("output", execResult)
    
    // Determine next action based on results
    if isValid(execResult) {
        return "success", nil
    }
    return "failure", nil
}
```

## Creating Nodes

### Using Helper Functions

The simplest way to create a node:

```go
node := flyt.NewNode(
    flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
        // Use type-safe getters
        message := shared.GetString("message")
        retryCount := shared.GetIntOr("retry_count", 0)
        
        return map[string]any{
            "message": message,
            "retry": retryCount,
        }, nil
    }),
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        data := prepResult.(map[string]any)
        // Process the data
        return processMessage(data["message"].(string)), nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        // Store result and determine action
        shared.Set("result", execResult)
        
        if shared.GetInt("retry_count") > 3 {
            return "max_retries", nil
        }
        return flyt.DefaultAction, nil
    }),
)
```

### Custom Node Types

For complex nodes with state:

```go
type DatabaseNode struct {
    *flyt.BaseNode
    db *sql.DB
}

func NewDatabaseNode(db *sql.DB) *DatabaseNode {
    return &DatabaseNode{
        BaseNode: flyt.NewBaseNode(),
        db: db,
    }
}

func (n *DatabaseNode) Exec(ctx context.Context, prepResult any) (any, error) {
    query := prepResult.(string)
    rows, err := n.db.QueryContext(ctx, query)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    // Process rows...
    return results, nil
}
```

## Node Options

Configure node behavior with options:

```go
node := flyt.NewNode(
    flyt.WithExecFunc(execFunc),
    flyt.WithMaxRetries(3),        // Retry up to 3 times
    flyt.WithWait(time.Second * 2), // Wait 2 seconds between retries
)
```

## BaseNode

The `BaseNode` provides default implementations:

```go
type MyNode struct {
    *flyt.BaseNode
    // Add custom fields
}

func NewMyNode() *MyNode {
    return &MyNode{
        BaseNode: flyt.NewBaseNode(
            flyt.WithMaxRetries(5),
            flyt.WithWait(time.Second),
        ),
    }
}

// Override only the methods you need
func (n *MyNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Custom exec logic
    return result, nil
}
```

## Thread Safety

Nodes should be thread-safe if used in concurrent batch operations:

```go
type SafeNode struct {
    *flyt.BaseNode
    mu      sync.Mutex
    counter int
}

func (n *SafeNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.mu.Lock()
    n.counter++
    count := n.counter
    n.mu.Unlock()
    
    return fmt.Sprintf("Execution #%d", count), nil
}
```

## Best Practices

1. **Single Responsibility**: Each node should do one thing well
2. **Idempotency**: Design nodes to be safely retryable
3. **Context Handling**: Always respect context cancellation
4. **Error Handling**: Return clear, actionable errors
5. **Resource Management**: Clean up resources in defer blocks

## Next Steps

- [Actions](/concepts/actions) - Control flow with actions
- [Flows](/concepts/flows) - Connect nodes into workflows
- [Custom Node Types](/advanced/custom-nodes) - Advanced node patterns


================================================
FILE: www/docs/pages/concepts/shared-store.mdx
================================================
# Shared Store

The SharedStore provides thread-safe data sharing between nodes in a flow. It acts as a key-value store that persists throughout flow execution with type-safe helpers for common operations.

## Creating a SharedStore

```go
shared := flyt.NewSharedStore()
```

## Basic Operations

### Set and Get

Store and retrieve individual values with the original API:

```go
// Set a value
shared.Set("user_id", 123)
shared.Set("config", map[string]any{"timeout": 30})

// Type-safe getter (recommended)
userID := shared.GetInt("user_id")
fmt.Printf("User ID: %d\n", userID)
```

### Type-Safe Getters

Use type-specific getters to avoid manual type assertions:

```go
// Type-safe getters (return zero values if not found or wrong type)
userID := shared.GetInt("user_id")           // Returns 0 if not found
name := shared.GetString("name")              // Returns "" if not found
price := shared.GetFloat64("price")           // Returns 0.0 if not found
enabled := shared.GetBool("enabled")          // Returns false if not found
items := shared.GetSlice("items")             // Returns nil if not found
config := shared.GetMap("config")             // Returns nil if not found

// Type-safe getters with custom defaults
userID = shared.GetIntOr("user_id", -1)              // Returns -1 if not found
name = shared.GetStringOr("name", "anonymous")       // Returns "anonymous" if not found
price = shared.GetFloat64Or("price", 99.99)          // Returns 99.99 if not found
enabled = shared.GetBoolOr("enabled", true)          // Returns true if not found
```

The type-safe getters handle numeric conversions automatically:
- `GetInt()` converts from int8, int16, int32, int64, uint variants, and float types
- `GetFloat64()` converts from all numeric types including int and float32

### Bind Method

Bind complex types directly to structs (similar to Echo framework):

```go
// Define your struct
type User struct {
    ID       int      `json:"id"`
    Name     string   `json:"name"`
    Email    string   `json:"email"`
    Tags     []string `json:"tags"`
}

// Store as map
shared.Set("user", map[string]any{
    "id":    123,
    "name":  "Alice",
    "email": "alice@example.com",
    "tags":  []string{"admin", "developer"},
})

// Bind to struct
var user User
err := shared.Bind("user", &user)  // Automatically converts map to struct
if err != nil {
    // Handle error
}

// Or use MustBind (panics on failure - use for required data)
var config Config
shared.MustBind("config", &config)
```

### Utility Methods

Additional helper methods for store management:

```go
// Check if key exists
if shared.Has("user_id") {
    // Key exists
}

// Delete a key
shared.Delete("temp_data")

// Get all keys
keys := shared.Keys()  // Returns []string

// Get number of items
count := shared.Len()

// Clear all items
shared.Clear()
```

### GetAll

Get a copy of all stored data:

```go
allData := shared.GetAll()
for key, value := range allData {
    fmt.Printf("%s: %v\n", key, value)
}
```

### Merge

Merge multiple values at once:

```go
shared.Merge(map[string]any{
    "status": "active",
    "timestamp": time.Now(),
    "metadata": map[string]string{
        "version": "1.0",
        "env": "production",
    },
})
```

## Thread Safety

SharedStore is safe for concurrent access:

```go
var wg sync.WaitGroup

// Multiple goroutines can safely access
for i := 0; i < 10; i++ {
    wg.Add(1)
    go func(id int) {
        defer wg.Done()
        shared.Set(fmt.Sprintf("worker_%d", id), "done")
    }(i)
}

wg.Wait()
```

## Common Patterns

### Configuration Storage

Store configuration that multiple nodes need:

```go
// Define configuration struct
type APIConfig struct {
    BaseURL string `json:"base_url"`
    APIKey  string `json:"api_key"`
    Timeout string `json:"timeout"`
}

// In main or initial node
shared.Set("api_config", APIConfig{
    BaseURL: "https://api.example.com",
    APIKey:  os.Getenv("API_KEY"),
    Timeout: "30s",
})

// In any node - using Bind
func (n *APINode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    var config APIConfig
    if err := shared.Bind("api_config", &config); err != nil {
        return nil, err
    }
    return config, nil
}

// Or using GetMap for simple access
func (n *APINode) Prep(ctx context.Context, shared *flyt.SharedStore) (any, error) {
    config := shared.GetMap("api_config")
    return config, nil
}
```

### Accumulating Results

Collect results from multiple nodes:

```go
// Node 1 - Using type-safe getters
func (n *Node1) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    // GetSlice returns nil if not found, perfect for initialization
    results := shared.GetSlice("results")
    if results == nil {
        results = []any{}
    }
    
    results = append(results, execResult)
    shared.Set("results", results)
    
    return flyt.DefaultAction, nil
}
```

### State Management

Track workflow state with type safety:

```go
// Initialize state
shared.Set("workflow_state", "initialized")
shared.Set("retry_count", 0)
shared.Set("start_time", time.Now())

// Update state in nodes with increment
func incrementRetry(shared *flyt.SharedStore) int {
    count := shared.GetInt("retry_count")
    count++
    shared.Set("retry_count", count)
    shared.Set("last_retry", time.Now())
    return count
}

// Check state
func checkState(shared *flyt.SharedStore) string {
    return shared.GetStringOr("workflow_state", "unknown")
}
```

### Error Context

Store error information for debugging:

```go
func (n *ErrorHandler) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if err := execResult.(error); err != nil {
        shared.Set("last_error", map[string]any{
            "error": err.Error(),
            "node": "ProcessNode",
            "timestamp": time.Now(),
            "input": prepResult,
        })
        return "error", nil
    }
    return flyt.DefaultAction, nil
}
```

## Batch Processing

SharedStore in batch operations:

```go
// Store items to process
shared.Set("items", []string{"item1", "item2", "item3"})

// Store batch configuration
shared.Set("batch_config", map[string]any{
    "batch_size": 10,
    "concurrent": true,
    "timeout": 60,
})

// After batch processing
results := shared.GetSlice("results")
errors := shared.GetSlice("errors")
```

## Isolation in Batch Flows

Each flow in a batch has its own SharedStore:

```go
batchFunc := func(ctx context.Context, shared *flyt.SharedStore) ([]flyt.FlowInputs, error) {
    // This shared is from the parent
    baseConfig := shared.GetMap("base_config")
    
    return []flyt.FlowInputs{
        {"id": 1, "config": baseConfig}, // Each gets own SharedStore
        {"id": 2, "config": baseConfig},
    }, nil
}
```

## Best Practices

### 1. Type Safety

Use type-safe getters to avoid manual assertions:

```go
// Type-safe getter (recommended)
count := shared.GetInt("count")  // Returns 0 if not found or wrong type

// Or with custom default
count := shared.GetIntOr("count", -1)  // Returns -1 if not found

// For complex types, use Bind
var userData UserData
if err := shared.Bind("user_data", &userData); err != nil {
    // Handle error
}
```

### 2. Key Naming

Use consistent, descriptive keys:

```go
const (
    KeyUserID     = "user_id"
    KeyAuthToken  = "auth_token"
    KeyResults    = "processing_results"
    KeyErrorCount = "error_count"
)
```

### 3. Data Structure

Store structured data for clarity:

```go
type WorkflowContext struct {
    RequestID string
    UserID    int
    StartTime time.Time
    Metadata  map[string]string
}

shared.Set("context", WorkflowContext{
    RequestID: "req-123",
    UserID:    456,
    StartTime: time.Now(),
    Metadata:  map[string]string{"source": "api"},
})
```

### 4. Cleanup

Clear sensitive data when done:

```go
defer func() {
    // Clear sensitive data
    shared.Set("auth_token", nil)
    shared.Set("api_key", nil)
}()
```

### 5. Documentation

Document expected keys:

```go
// SharedStore keys used by this flow:
// - "input_file": string - Path to input file
// - "output_dir": string - Output directory path
// - "processed_count": int - Number of processed items
// - "errors": []error - Collection of errors
```

## Debugging

Use GetAll for debugging:

```go
func debugSharedStore(shared *flyt.SharedStore) {
    data := shared.GetAll()
    fmt.Println("=== SharedStore Contents ===")
    for k, v := range data {
        fmt.Printf("%s: %T = %v\n", k, v, v)
    }
    fmt.Println("===========================")
}
```

## Next Steps

- [Nodes](/concepts/nodes) - Use SharedStore in node lifecycle
- [Batch Processing](/advanced/batch-processing) - SharedStore in batch operations
- [Best Practices](/best-practices) - General Flyt best practices


================================================
FILE: www/docs/pages/getting-started/installation.mdx
================================================
# Installation

Flyt requires Go 1.21 or later.

## Install with go get

```bash
go get github.com/mark3labs/flyt
```

## Import in your code

```go
import "github.com/mark3labs/flyt"
```

## Verify installation

Create a simple test file to verify the installation:

```go
package main

import (
    "fmt"
    "github.com/mark3labs/flyt"
)

func main() {
    shared := flyt.NewSharedStore()
    shared.Set("test", "success")
    
    val := shared.GetString("test")
    fmt.Printf("Flyt installed successfully! Value: %s\n", val)
}
```

Run it:

```bash
go run main.go
```

You should see:
```
Flyt installed successfully! Value: success
```

## Next Steps

- [Quick Start Guide](/getting-started/quick-start) - Build your first workflow
- [Project Template](/getting-started/template) - Start with a pre-configured project
- [Core Concepts](/concepts/nodes) - Understand the fundamentals


================================================
FILE: www/docs/pages/getting-started/quick-start.mdx
================================================
# Quick Start

This guide will help you build your first Flyt workflow in 5 minutes.

## Your First Node

Let's start with a simple node that processes data:

```go
package main

import (
    "context"
    "fmt"
    "github.com/mark3labs/flyt"
)

func main() {
    // Create a node with just an Exec function
    node := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            fmt.Println("Processing data...")
            return "Hello, Flyt!", nil
        }),
    )

    // Create shared store and context
    shared := flyt.NewSharedStore()
    ctx := context.Background()

    // Run the node
    action, err := flyt.Run(ctx, node, shared)
    if err != nil {
        panic(err)
    }
    
    fmt.Printf("Completed with action: %s\n", action)
}
```

## Building a Flow

Now let's create a simple workflow with multiple nodes:

```go
package main

import (
    "context"
    "fmt"
    "github.com/mark3labs/flyt"
)

func main() {
    // Create nodes
    fetchNode := flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            fmt.Println("Fetching data...")
            return map[string]string{"data": "important info"}, nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            shared.Set("fetched_data", execResult)
            return flyt.DefaultAction, nil
        }),
    )

    processNode := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Use GetMap for type-safe access
            data := shared.GetMap("fetched_data")
            return data, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            data := prepResult.(map[string]any)
            fmt.Printf("Processing: %v\n", data["data"])
            return "processed: " + fmt.Sprint(data["data"]), nil
        }),
    )

    // Build the flow
    flow := flyt.NewFlow(fetchNode)
    flow.Connect(fetchNode, flyt.DefaultAction, processNode)

    // Run the flow
    shared := flyt.NewSharedStore()
    ctx := context.Background()
    
    err := flow.Run(ctx, shared)
    if err != nil {
        panic(err)
    }
    
    fmt.Println("Flow completed successfully!")
}
```

## Adding Error Handling

Let's add retry logic and error handling:

```go
func createRobustNode() flyt.Node {
    attempts := 0
    
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            attempts++
            fmt.Printf("Attempt %d...\n", attempts)
            
            // Simulate flaky operation
            if attempts < 2 {
                return nil, fmt.Errorf("temporary failure")
            }
            
            return "Success!", nil
        }),
        flyt.WithMaxRetries(3),
        flyt.WithWait(time.Second),
    )
}
```

## Using Shared Store

The SharedStore allows nodes to communicate:

```go
func main() {
    shared := flyt.NewSharedStore()
    
    // Set initial data
    shared.Set("config", map[string]any{
        "timeout": 30,
        "retries": 3,
    })
    
    node := flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            config := shared.GetMap("config")
            return config, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            config := prepResult.(map[string]any)
            fmt.Printf("Using config: %v\n", config)
            return "configured", nil
        }),
    )
    
    ctx := context.Background()
    flyt.Run(ctx, node, shared)
}
```

## Next Steps

Now that you've built your first workflow, explore:

- [Nodes](/concepts/nodes) - Deep dive into node lifecycle
- [Actions](/concepts/actions) - Control flow with actions
- [Error Handling](/patterns/error-handling) - Build resilient workflows
- [Examples](https://github.com/mark3labs/flyt/tree/main/cookbook) - Real-world use cases


================================================
FILE: www/docs/pages/getting-started/template.mdx
================================================
# Project Template

The fastest way to start a new Flyt project is using the official template.

## Quick Setup

```bash
# Clone the template
git clone https://github.com/mark3labs/flyt-project-template my-flyt-project
cd my-flyt-project

# Remove template git history
rm -rf .git
git init

# Install dependencies
go mod tidy

# Run the example
go run main.go
```

## What's Included

The template provides:

### Project Structure

```
my-flyt-project/
├── main.go           # Entry point with example workflow
├── nodes/            # Custom node implementations
│   ├── fetch.go      # Example fetch node
│   ├── process.go    # Example processing node
│   └── validate.go   # Example validation node
├── flows/            # Reusable flow definitions
│   └── example.go    # Example flow composition
├── go.mod            # Go module file
└── README.md         # Project documentation
```

### Example Code

The template includes a working example that demonstrates:

- Creating custom nodes
- Building flows
- Using the SharedStore
- Error handling with retries
- Action-based routing

### main.go

```go
package main

import (
    "context"
    "log"
    
    "github.com/mark3labs/flyt"
    "myproject/flows"
)

func main() {
    // Create shared store with initial data
    shared := flyt.NewSharedStore()
    shared.Set("api_key", "your-api-key")
    shared.Set("base_url", "https://api.example.com")
    
    // Create and run the example flow
    flow := flows.CreateExampleFlow()
    
    ctx := context.Background()
    if err := flow.Run(ctx, shared); err != nil {
        log.Fatal(err)
    }
    
    // Get results
    result := shared.GetString("final_result")
    if result != "" {
        log.Printf("Success! Result: %s\n", result)
    }
}
```

## Customizing the Template

### Adding New Nodes

Create a new file in the `nodes/` directory:

```go
// nodes/custom.go
package nodes

import (
    "context"
    "github.com/mark3labs/flyt"
)

func CreateCustomNode() flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Your custom logic here
            return "custom result", nil
        }),
    )
}
```

### Creating New Flows

Add flows to the `flows/` directory:

```go
// flows/custom.go
package flows

import (
    "github.com/mark3labs/flyt"
    "myproject/nodes"
)

func CreateCustomFlow() *flyt.Flow {
    // Create nodes
    startNode := nodes.CreateCustomNode()
    processNode := nodes.CreateProcessNode()
    
    // Build flow
    flow := flyt.NewFlow(startNode)
    flow.Connect(startNode, flyt.DefaultAction, processNode)
    
    return flow
}
```

## Best Practices

When using the template:

1. **Organize by Feature**: Group related nodes and flows together
2. **Use Configuration**: Store config in SharedStore or environment variables
3. **Add Tests**: Create `*_test.go` files for your nodes and flows
4. **Document Your Nodes**: Add comments explaining what each node does
5. **Version Control**: Initialize git and commit regularly

## Deployment

The template is ready for deployment:

```bash
# Build the binary
go build -o myapp

# Run in production
./myapp

# Or use Docker
docker build -t myapp .
docker run myapp
```

## Next Steps

- [Core Concepts](/concepts/nodes) - Understand Flyt fundamentals
- [Patterns](/patterns/closures) - Learn common patterns
- [Examples](https://github.com/mark3labs/flyt/tree/main/cookbook) - See real-world implementations


================================================
FILE: www/docs/pages/patterns/branching.mdx
================================================
# Conditional Branching

Control flow execution dynamically based on runtime conditions using action-based routing.

## Simple Binary Branching

Make yes/no decisions:

```go
validationNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        data := prepResult.(string)
        isValid := len(data) > 0 && len(data) < 100
        return isValid, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        if execResult.(bool) {
            return "valid", nil
        }
        return "invalid", nil
    }),
)

flow := flyt.NewFlow(validationNode)
flow.Connect(validationNode, "valid", processNode)
flow.Connect(validationNode, "invalid", errorNode)
```

## Multi-Way Branching

Route to multiple paths:

```go
categoryNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        value := prepResult.(float64)
        
        switch {
        case value < 10:
            return "small", nil
        case value < 100:
            return "medium", nil
        case value < 1000:
            return "large", nil
        default:
            return "xlarge", nil
        }
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        return flyt.Action(execResult.(string)), nil
    }),
)

flow := flyt.NewFlow(categoryNode)
flow.Connect(categoryNode, "small", smallHandler)
flow.Connect(categoryNode, "medium", mediumHandler)
flow.Connect(categoryNode, "large", largeHandler)
flow.Connect(categoryNode, "xlarge", xlargeHandler)
```

## State Machine Pattern

Implement state transitions:

```go
type StateMachine struct {
    *flyt.BaseNode
}

func (n *StateMachine) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    state := shared.GetStringOr("state", "init")
    event := execResult.(string)
    
    // State transition logic
    nextState := n.transition(state, event)
    shared.Set("state", nextState)
    
    // Return action based on new state
    return flyt.Action(nextState), nil
}

func (n *StateMachine) transition(state, event string) string {
    transitions := map[string]map[string]string{
        "init": {
            "start": "processing",
            "cancel": "cancelled",
        },
        "processing": {
            "complete": "done",
            "error": "failed",
            "pause": "paused",
        },
        "paused": {
            "resume": "processing",
            "cancel": "cancelled",
        },
    }
    
    if stateTransitions, ok := transitions[state]; ok {
        if nextState, ok := stateTransitions[event]; ok {
            return nextState
        }
    }
    
    return state // No transition
}
```

## Dynamic Routing

Route based on external configuration:

```go
type DynamicRouter struct {
    *flyt.BaseNode
    routes map[string]string
}

func NewDynamicRouter(configPath string) *DynamicRouter {
    // Load routing configuration
    data, _ := os.ReadFile(configPath)
    var routes map[string]string
    json.Unmarshal(data, &routes)
    
    return &DynamicRouter{
        BaseNode: flyt.NewBaseNode(),
        routes:   routes,
    }
}

func (n *DynamicRouter) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    result := execResult.(string)
    
    // Look up route in configuration
    if action, ok := n.routes[result]; ok {
        return flyt.Action(action), nil
    }
    
    // Default route
    return flyt.DefaultAction, nil
}
```

## Weighted Routing

Distribute load across paths:

```go
type LoadBalancer struct {
    *flyt.BaseNode
    weights  map[string]int
    counter  int
    mu       sync.Mutex
}

func NewLoadBalancer(weights map[string]int) *LoadBalancer {
    return &LoadBalancer{
        BaseNode: flyt.NewBaseNode(),
        weights:  weights,
    }
}

func (n *LoadBalancer) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    n.mu.Lock()
    defer n.mu.Unlock()
    
    n.counter++
    
    // Calculate total weight
    totalWeight := 0
    for _, weight := range n.weights {
        totalWeight += weight
    }
    
    // Determine which path based on counter
    position := n.counter % totalWeight
    currentWeight := 0
    
    for action, weight := range n.weights {
        currentWeight += weight
        if position < currentWeight {
            return flyt.Action(action), nil
        }
    }
    
    return flyt.DefaultAction, nil
}

// Usage
balancer := NewLoadBalancer(map[string]int{
    "server1": 3,  // 30% of traffic
    "server2": 5,  // 50% of traffic
    "server3": 2,  // 20% of traffic
})
```

## Conditional Loops

Create loops with exit conditions:

```go
retryNode := flyt.NewNode(
    flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
        attempts := shared.GetInt("attempts")
        return attempts, nil
    }),
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        attempts := prepResult.(int)
        
        // Try operation
        result, err := performOperation()
        if err != nil {
            return map[string]any{
                "success": false,
                "attempts": attempts + 1,
                "error": err.Error(),
            }, nil
        }
        
        return map[string]any{
            "success": true,
            "result": result,
        }, nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        result := execResult.(map[string]any)
        
        if result["success"].(bool) {
            return "success", nil
        }
        
        attempts := result["attempts"].(int)
        shared.Set("attempts", attempts)
        
        if attempts < 3 {
            return "retry", nil  // Loop back
        }
        
        return "failed", nil  // Exit loop
    }),
)

flow := flyt.NewFlow(retryNode)
flow.Connect(retryNode, "retry", retryNode)  // Loop back to self
flow.Connect(retryNode, "success", successNode)
flow.Connect(retryNode, "failed", failureNode)
```

## Pipeline Branching

Branch and merge pipelines:

```go
// Split node decides which pipeline(s) to execute
splitNode := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        data := prepResult.(map[string]any)
        
        needsValidation := data["validate"].(bool)
        needsEnrichment := data["enrich"].(bool)
        
        if needsValidation && needsEnrichment {
            return "both", nil
        } else if needsValidation {
            return "validate_only", nil
        } else if needsEnrichment {
            return "enrich_only", nil
        }
        return "skip", nil
    }),
    flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
        return flyt.Action(execResult.(string)), nil
    }),
)

// Build flow with different pipelines
flow := flyt.NewFlow(splitNode)

// Both pipelines
flow.Connect(splitNode, "both", validateNode)
flow.Connect(validateNode, flyt.DefaultAction, enrichNode)
flow.Connect(enrichNode, flyt.DefaultAction, mergeNode)

// Validation only
flow.Connect(splitNode, "validate_only", validateNode)
flow.Connect(validateNode, "skip_enrich", mergeNode)

// Enrichment only
flow.Connect(splitNode, "enrich_only", enrichNode)
flow.Connect(enrichNode, "skip_validate", mergeNode)

// Skip both
flow.Connect(splitNode, "skip", mergeNode)
```

## Feature Flags

Control flow with feature toggles:

```go
type FeatureFlagNode struct {
    *flyt.BaseNode
    flags map[string]bool
}

func (n *FeatureFlagNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    feature := execResult.(string)
    
    // Check if feature is enabled
    if enabled, ok := n.flags[feature]; ok && enabled {
        return flyt.Action(feature + "_enabled"), nil
    }
    
    return flyt.Action(feature + "_disabled"), nil
}

// Usage
flagNode := &FeatureFlagNode{
    BaseNode: flyt.NewBaseNode(),
    flags: map[string]bool{
        "new_algorithm": true,
        "beta_feature": false,
        "experimental": true,
    },
}

flow := flyt.NewFlow(flagNode)
flow.Connect(flagNode, "new_algorithm_enabled", newAlgorithmNode)
flow.Connect(flagNode, "new_algorithm_disabled", oldAlgorithmNode)
```

## A/B Testing

Route based on experiment groups:

```go
func createABTestNode(testName string, distribution map[string]int) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            userID := shared.GetString("user_id")
            return userID, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            userID := prepResult.(string)
            
            // Hash user ID for consistent assignment
            h := fnv.New32a()
            h.Write([]byte(userID + testName))
            hash := h.Sum32()
            
            // Determine variant based on distribution
            bucket := int(hash % 100)
            cumulative := 0
            
            for variant, percentage := range distribution {
                cumulative += percentage
                if bucket < cumulative {
                    return variant, nil
                }
            }
            
            return "control", nil
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            variant := execResult.(string)
            shared.Set("ab_variant", variant)
            return flyt.Action(variant), nil
        }),
    )
}

// Usage
abNode := createABTestNode("checkout_flow", map[string]int{
    "variant_a": 33,  // 33% of users
    "variant_b": 33,  // 33% of users
    "control":   34,  // 34% of users
})
```

## Best Practices

1. **Clear Action Names**: Use descriptive action names that indicate the path
2. **Document Branches**: Comment all possible branches and their conditions
3. **Handle All Cases**: Ensure all possible actions have connections
4. **Avoid Deep Nesting**: Keep branching logic simple and readable
5. **Test All Paths**: Write tests for each branch condition
6. **Monitor Branch Usage**: Track which paths are taken most frequently

## Next Steps

- [Actions](/concepts/actions) - Deep dive into action system
- [Flows](/concepts/flows) - Building complex workflows
- [State Machines](/patterns/branching#state-machine-pattern) - Advanced state management


================================================
FILE: www/docs/pages/patterns/closures.mdx
================================================
# Configuration via Closures

Use closures to create configurable, reusable nodes with encapsulated state and configuration.

## Basic Closure Pattern

Pass configuration to nodes using closures:

```go
func createAPINode(apiKey string, baseURL string) flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // apiKey and baseURL are captured in the closure
            url := fmt.Sprintf("%s/data", baseURL)
            req, _ := http.NewRequest("GET", url, nil)
            req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))
            
            client := &http.Client{Timeout: 30 * time.Second}
            resp, err := client.Do(req)
            if err != nil {
                return nil, err
            }
            defer resp.Body.Close()
            
            var data map[string]any
            json.NewDecoder(resp.Body).Decode(&data)
            return data, nil
        }),
    )
}

// Usage
apiNode := createAPINode("secret-key-123", "https://api.example.com")
```

## Stateful Nodes

Maintain state across executions:

```go
func createCounterNode() flyt.Node {
    count := 0
    mu := &sync.Mutex{}
    
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            mu.Lock()
            count++
            current := count
            mu.Unlock()
            
            return fmt.Sprintf("Execution #%d", current), nil
        }),
    )
}
```

## Configuration Objects

Use structs for complex configuration:

```go
type DatabaseConfig struct {
    Host     string
    Port     int
    User     string
    Password string
    Database string
    MaxConns int
}

func createDatabaseNode(config DatabaseConfig) flyt.Node {
    // Create connection pool once
    dsn := fmt.Sprintf("%s:%s@tcp(%s:%d)/%s",
        config.User, config.Password, config.Host, config.Port, config.Database)
    
    db, _ := sql.Open("mysql", dsn)
    db.SetMaxOpenConns(config.MaxConns)
    
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            query := prepResult.(string)
            rows, err := db.QueryContext(ctx, query)
            if err != nil {
                return nil, err
            }
            defer rows.Close()
            
            var results []map[string]any
            // Process rows...
            return results, nil
        }),
    )
}

// Usage
dbNode := createDatabaseNode(DatabaseConfig{
    Host:     "localhost",
    Port:     3306,
    User:     "app",
    Password: "secret",
    Database: "myapp",
    MaxConns: 10,
})
```

## Factory Functions

Create specialized node variants:

```go
func createHTTPNode(method string, headers map[string]string) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            url := shared.GetString("url")
            body := shared.GetMap("body")
            return map[string]any{"url": url, "body": body}, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            data := prepResult.(map[string]any)
            url := data["url"].(string)
            
            var bodyReader io.Reader
            if body, ok := data["body"]; ok {
                bodyBytes, _ := json.Marshal(body)
                bodyReader = bytes.NewReader(bodyBytes)
            }
            
            req, _ := http.NewRequest(method, url, bodyReader)
            
            // Apply configured headers
            for key, value := range headers {
                req.Header.Set(key, value)
            }
            
            client := &http.Client{}
            resp, err := client.Do(req)
            if err != nil {
                return nil, err
            }
            defer resp.Body.Close()
            
            var result map[string]any
            json.NewDecoder(resp.Body).Decode(&result)
            return result, nil
        }),
    )
}

// Create specialized nodes
getNode := createHTTPNode("GET", map[string]string{
    "Accept": "application/json",
})

postNode := createHTTPNode("POST", map[string]string{
    "Content-Type": "application/json",
    "Accept": "application/json",
})
```

## Resource Management

Manage shared resources:

```go
func createFileProcessorNode(bufferSize int) flyt.Node {
    // Pre-allocate buffer
    buffer := make([]byte, bufferSize)
    
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            filePath := prepResult.(string)
            
            file, err := os.Open(filePath)
            if err != nil {
                return nil, err
            }
            defer file.Close()
            
            // Reuse buffer
            n, err := file.Read(buffer)
            if err != nil && err != io.EOF {
                return nil, err
            }
            
            // Process buffer[:n]
            return processData(buffer[:n]), nil
        }),
    )
}
```

## Middleware Pattern

Wrap nodes with additional behavior:

```go
func withLogging(name string, node flyt.Node) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            log.Printf("[%s] Starting prep", name)
            return node.Prep(ctx, shared)
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            start := time.Now()
            result, err := node.Exec(ctx, prepResult)
            log.Printf("[%s] Exec took %v", name, time.Since(start))
            return result, err
        }),
        flyt.WithPostFunc(func(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
            action, err := node.Post(ctx, shared, prepResult, execResult)
            log.Printf("[%s] Returning action: %s", name, action)
            return action, err
        }),
    )
}

// Usage
processNode := withLogging("processor", createProcessNode())
```

## Dynamic Configuration

Load configuration at runtime:

```go
func createConfigurableNode(configPath string) flyt.Node {
    return flyt.NewNode(
        flyt.WithPrepFunc(func(ctx context.Context, shared *flyt.SharedStore) (any, error) {
            // Load config file
            data, err := os.ReadFile(configPath)
            if err != nil {
                return nil, err
            }
            
            var config map[string]any
            json.Unmarshal(data, &config)
            return config, nil
        }),
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            config := prepResult.(map[string]any)
            // Use configuration
            return processWithConfig(config), nil
        }),
    )
}
```

## Dependency Injection

Inject dependencies through closures:

```go
type Dependencies struct {
    DB       *sql.DB
    Cache    *redis.Client
    Logger   *log.Logger
    Metrics  *prometheus.Registry
}

func createServiceNode(deps Dependencies) flyt.Node {
    return flyt.NewNode(
        flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
            // Use injected dependencies
            deps.Logger.Println("Processing request")
            
            // Check cache
            if cached, err := deps.Cache.Get(ctx, "key").Result(); err == nil {
                deps.Metrics.Inc("cache_hits")
                return cached, nil
            }
            
            // Query database
            result, err := queryDB(deps.DB, prepResult)
            if err != nil {
                deps.Logger.Printf("DB error: %v", err)
                return nil, err
            }
            
            // Update cache
            deps.Cache.Set(ctx, "key", result, time.Hour)
            
            return result, nil
        }),
    )
}
```

## Best Practices

1. **Immutable Configuration**: Don't modify captured variables after node creation
2. **Thread Safety**: Use mutexes for shared state in concurrent scenarios
3. **Resource Cleanup**: Ensure resources are properly closed
4. **Error Handling**: Handle configuration errors gracefully
5. **Documentation**: Document required configuration clearly

## Next Steps

- [Error Handling](/patterns/error-handling) - Build resilient nodes
- [Custom Node Types](/advanced/custom-nodes) - Advanced node patterns
- [Best Practices](/best-practices) - General guidelines


================================================
FILE: www/docs/pages/patterns/error-handling.mdx
================================================
# Error Handling & Retries

Build resilient workflows with proper error handling and retry strategies.

## Basic Retry Configuration

Configure retries at the node level:

```go
node := flyt.NewNode(
    flyt.WithExecFunc(func(ctx context.Context, prepResult any) (any, error) {
        // This will be retried up to 3 times
        return callFlakeyAPI()
    }),
    flyt.WithMaxRetries(3),
    flyt.WithWait(time.Second), // Wait 1 second between retries
    flyt.WithExecFallbackFunc(func(prepResult any, err error) (any, error) {
        // Called after all retries fail
        log.Printf("API failed after retries: %v", err)
        return nil, nil // Return nil to handle in Post
    }),
)
```

## Exponential Backoff

Implement exponential backoff with RetryableNode:

```go
type BackoffNode struct {
    *flyt.BaseNode
    attempt int
}

func (n *BackoffNode) GetMaxRetries() int {
    return 5
}

func (n *BackoffNode) GetWait() time.Duration {
    // Exponential backoff: 1s, 2s, 4s, 8s, 16s
    return time.Duration(math.Pow(2, float64(n.attempt))) * time.Second
}

func (n *BackoffNode) Exec(ctx context.Context, prepResult any) (any, error) {
    n.attempt++
    result, err := callAPI()
    if err != nil {
        log.Printf("Attempt %d failed: %v", n.attempt, err)
        return nil, err
    }
    n.attempt = 0 // Reset on success
    return result, nil
}
```

## Circuit Breaker Pattern

Prevent cascading failures:

```go
type CircuitBreakerNode struct {
    *flyt.BaseNode
    failures    int
    lastFailure time.Time
    threshold   int
    timeout     time.Duration
}

func NewCircuitBreakerNode() *CircuitBreakerNode {
    return &CircuitBreakerNode{
        BaseNode:  flyt.NewBaseNode(),
        threshold: 5,
        timeout:   30 * time.Second,
    }
}

func (n *CircuitBreakerNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Check if circuit is open
    if n.failures >= n.threshold {
        if time.Since(n.lastFailure) < n.timeout {
            return nil, fmt.Errorf("circuit breaker open")
        }
        // Reset after timeout
        n.failures = 0
    }
    
    result, err := callService()
    if err != nil {
        n.failures++
        n.lastFailure = time.Now()
        return nil, err
    }
    
    n.failures = 0 // Reset on success
    return result, nil
}
```

## Fallback on Failure

Implement the FallbackNode interface for graceful degradation:

```go
type CachedAPINode struct {
    *flyt.BaseNode
    cache sync.Map
}

func (n *CachedAPINode) Exec(ctx context.Context, prepResult any) (any, error) {
    key := prepResult.(string)
    
    // Try to fetch fresh data
    data, err := fetchFromAPI(key)
    if err == nil {
        // Cache successful result
        n.cache.Store(key, data)
        return data, nil
    }
    
    return nil, err
}

func (n *CachedAPINode) ExecFallback(prepResult any, err error) (any, error) {
    key := prepResult.(string)
    
    // Return cached data on failure
    if cached, ok := n.cache.Load(key); ok {
        log.Printf("Returning cached data for %s due to error: %v", key, err)
        return cached, nil
    }
    
    // Return default if no cache
    return map[string]any{
        "status": "unavailable",
        "cached": false,
    }, nil
}
```

## Error Aggregation

Collect errors from batch operations:

```go
func processBatch(ctx context.Context, items []Item) error {
    var errs []error
    
    for i, item := range items {
        if err := processItem(item); err != nil {
            errs = append(errs, fmt.Errorf("item %d: %w", i, err))
        }
    }
    
    if len(errs) > 0 {
        return &flyt.BatchError{
            Errors: errs,
            Message: fmt.Sprintf("%d/%d items failed", len(errs), len(items)),
        }
    }
    
    return nil
}
```

## Retry with Jitter

Add randomization to prevent thundering herd:

```go
func (n *JitterNode) GetWait() time.Duration {
    base := time.Second * time.Duration(n.attempt)
    jitter := time.Duration(rand.Intn(1000)) * time.Millisecond
    return base + jitter
}
```

## Selective Retry

Only retry specific errors:

```go
func (n *SelectiveRetryNode) Exec(ctx context.Context, prepResult any) (any, error) {
    result, err := callAPI()
    if err != nil {
        // Only retry on network errors
        if isNetworkError(err) {
            return nil, err // Will be retried
        }
        // Don't retry business logic errors
        return nil, fmt.Errorf("permanent error: %w", err)
    }
    return result, nil
}

func (n *SelectiveRetryNode) GetMaxRetries() int {
    // Check error type from last execution
    if n.lastError != nil && !isRetryable(n.lastError) {
        return 0 // Don't retry
    }
    return 3
}
```

## Error Context

Provide context for debugging:

```go
type ErrorContext struct {
    Node      string
    Action    string
    Input     any
    Error     error
    Timestamp time.Time
    Attempts  int
}

func (n *DetailedErrorNode) Post(ctx context.Context, shared *flyt.SharedStore, prepResult, execResult any) (flyt.Action, error) {
    if err, ok := execResult.(error); ok && err != nil {
        errorCtx := ErrorContext{
            Node:      "DetailedErrorNode",
            Action:    "process",
            Input:     prepResult,
            Error:     err,
            Timestamp: time.Now(),
            Attempts:  n.attempts,
        }
        
        shared.Set("last_error", errorCtx)
        
        if n.attempts < n.maxRetries {
            return "retry", nil
        }
        return "error", nil
    }
    
    return flyt.DefaultAction, nil
}
```

## Timeout Handling

Prevent hanging operations:

```go
func (n *TimeoutNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Create timeout context
    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)
    defer cancel()
    
    resultChan := make(chan any)
    errChan := make(chan error)
    
    go func() {
        result, err := longRunningOperation()
        if err != nil {
            errChan <- err
        } else {
            resultChan <- result
        }
    }()
    
    select {
    case result := <-resultChan:
        return result, nil
    case err := <-errChan:
        return nil, err
    case <-ctx.Done():
        return nil, fmt.Errorf("operation timed out: %w", ctx.Err())
    }
}
```

## Best Practices

1. **Identify Transient vs Permanent Errors**: Only retry transient failures
2. **Set Reasonable Limits**: Don't retry indefinitely
3. **Use Backoff**: Avoid overwhelming failing services
4. **Log Failures**: Track retry attempts for debugging
5. **Provide Fallbacks**: Gracefully degrade when possible
6. **Monitor Retry Rates**: High retry rates indicate problems

## Next Steps

- [Fallback on Failure](/patterns/fallback) - Graceful degradation
- [Batch Error Handling](/advanced/batch-processing#batch-error-handling) - Handle batch failures
- [Best Practices](/best-practices) - General guidelines


================================================
FILE: www/docs/pages/patterns/fallback.mdx
================================================
# Fallback on Failure

Implement graceful degradation when operations fail, ensuring your workflows remain resilient and provide the best possible user experience even during failures.

## FallbackNode Interface

The `FallbackNode` interface allows custom fallback behavior:

```go
type FallbackNode interface {
    Node
    ExecFallback(prepResult any, err error) (any, error)
}
```

## Basic Fallback

Return default values on failure:

```go
type DefaultValueNode struct {
    *flyt.BaseNode
}

func (n *DefaultValueNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Try primary operation
    result, err := fetchFromPrimarySource()
    if err != nil {
        return nil, err // Will trigger fallback
    }
    return result, nil
}

func (n *DefaultValueNode) ExecFallback(prepResult any, err error) (any, error) {
    log.Printf("Primary source failed: %v, returning default", err)
    
    // Return safe default value
    return map[string]any{
        "status": "degraded",
        "data": "default_value",
        "error": err.Error(),
    }, nil
}
```

## Cached Fallback

Use cached data when fresh data is unavailable:

```go
type CachedAPINode struct {
    *flyt.BaseNode
    cache map[string]CacheEntry
    mu    sync.RWMutex
}

type CacheEntry struct {
    Data      any
    Timestamp time.Time
}

func (n *CachedAPINode) Exec(ctx context.Context, prepResult any) (any, error) {
    key := prepResult.(string)
    
    // Try to fetch fresh data
    data, err := fetchFromAPI(key)
    if err == nil {
        // Update cache on success
        n.mu.Lock()
        n.cache[key] = CacheEntry{
            Data:      data,
            Timestamp: time.Now(),
        }
        n.mu.Unlock()
        return data, nil
    }
    
    return nil, err
}

func (n *CachedAPINode) ExecFallback(prepResult any, err error) (any, error) {
    key := prepResult.(string)
    
    n.mu.RLock()
    entry, exists := n.cache[key]
    n.mu.RUnlock()
    
    if exists {
        age := time.Since(entry.Timestamp)
        log.Printf("Returning cached data (age: %v) due to error: %v", age, err)
        
        // Add metadata about cache usage
        return map[string]any{
            "data":       entry.Data,
            "cached":     true,
            "cache_age":  age.Seconds(),
            "error":      err.Error(),
        }, nil
    }
    
    // No cache available
    return nil, fmt.Errorf("no fallback available: %w", err)
}
```

## Multi-Level Fallback

Try multiple fallback strategies:

```go
type MultiLevelFallbackNode struct {
    *flyt.BaseNode
    primaryURL   string
    secondaryURL string
    cache        sync.Map
}

func (n *MultiLevelFallbackNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Try primary source
    data, err := fetchFromURL(n.primaryURL)
    if err == nil {
        n.cache.Store("last_good", data)
        return data, nil
    }
    
    return nil, err
}

func (n *MultiLevelFallbackNode) ExecFallback(prepResult any, primaryErr error) (any, error) {
    // Level 1: Try secondary source
    data, err := fetchFromURL(n.secondaryURL)
    if err == nil {
        log.Printf("Using secondary source due to primary error: %v", primaryErr)
        return data, nil
    }
    
    // Level 2: Try cache
    if cached, ok := n.cache.Load("last_good"); ok {
        log.Printf("Using cached data due to all sources failing")
        return cached, nil
    }
    
    // Level 3: Return minimal default
    log.Printf("All fallbacks exhausted, returning minimal response")
    return map[string]any{
        "status": "unavailable",
        "message": "Service temporarily unavailable",
    }, nil
}
```

## Partial Fallback

Return partial results when complete processing fails:

```go
type BatchProcessorNode struct {
    *flyt.BaseNode
    results []Result
    errors  []error
}

func (n *BatchProcessorNode) Exec(ctx context.Context, prepResult any) (any, error) {
    items := prepResult.([]Item)
    n.results = make([]Result, 0, len(items))
    n.errors = make([]error, 0)
    
    for _, item := range items {
        result, err := processItem(item)
        if err != nil {
            n.errors = append(n.errors, err)
            continue
        }
        n.results = append(n.results, result)
    }
    
    if len(n.errors) > 0 {
        return nil, fmt.Errorf("processing failed: %d errors", len(n.errors))
    }
    
    return n.results, nil
}

func (n *BatchProcessorNode) ExecFallback(prepResult any, err error) (any, error) {
    // Return partial results
    return map[string]any{
        "partial_results": n.results,
        "success_count":   len(n.results),
        "error_count":     len(n.errors),
        "errors":          n.errors,
        "status":          "partial_success",
    }, nil
}
```

## Circuit Breaker Fallback

Prevent cascading failures:

```go
type CircuitBreakerNode struct {
    *flyt.BaseNode
    failures    int
    lastFailure time.Time
    threshold   int
    timeout     time.Duration
    fallbackMsg string
}

func (n *CircuitBreakerNode) Exec(ctx context.Context, prepResult any) (any, error) {
    // Check if circuit is open
    if n.isCircuitOpen() {
        return nil, fmt.Errorf("circuit breaker open")
    }
    
    result, err := callService(prepResult)
    if err != nil {
        n.recordFailure()
        return nil, err
    }
    
    n.reset()
    return result, nil
}

func (n *CircuitBreakerNode) ExecFallback(prepResult any, err error) (any, error) {
    if n.isCircuitOpen() {
        // Return cached or default response immediately
        return map[string]any{
            "status": "circuit_open",
            "message": n.fallbackMsg,
            "retry_after": n.timeout - time.Since(n.lastFailure),
        }, nil
    }
    
    // Circuit not open, but request failed
    return map[string]any{
        "status": "degraded",
        "message": "Service temporarily unavailable",
    }, nil
}

func (n *CircuitBreakerNode) isCircuitOpen() bool {
    return n.failures >= n.threshold && 
           time.Since(n.lastFailure) < n.timeout
}

func (n *CircuitBreakerNode) recordFailure() {
    n.failures++
    n.lastFailure = time.Now()
}

func (n *CircuitBreakerNode) reset() {
    n.failures = 0
}
```

## Fallback with Metrics

Track fallback usage:

```go
type MetricsFallbackNode struct {
    *flyt.BaseNode
    primaryCalls   int64
    fallbackCalls  int64
    lastFallback   time.Time
}

func (n *MetricsFallbackNode) ExecFallback(prepResult any, err error) (any, error) {
    atomic.AddInt64(&n.fallbackCalls, 1)
    n.lastFallback = time.Now()
    
    // Log metrics
    total := atomic.LoadInt64(&n.primaryCalls) + atomic.LoadInt64(&n.fallbackCalls)
    fallbackRate := float64(n.fallbackCalls) / float64(total) * 100
    
    log.Printf("Fallback metrics - Rate: %.2f%%, Total fallbacks: %d", 
        fallbackRate, n.fallbackCalls)
    
    // Return fallback data
    return getDefaultResponse(), nil
}
```

## Conditional Fallback

Different fallbacks based on error type:

```go
func (n *ConditionalFallbackNode) ExecFallback(prepResult any, err error) (any, error) {
    switch {
    case errors.Is(err, ErrTimeout):
        // For timeouts, return cached data
        return n.getCachedResponse(), nil
        
    case errors.Is(err, ErrRateLimit):
        // For rate limits, return throttled message
        return map[string]any{
            "error": "rate_limited",
            "retry_after": 60,
        }, nil
        
    case errors.Is(err, ErrNotFound):
        // For not found, return empty result
        return map[string]any{
            "found": false,
            "data": nil,
        }, nil
        
    default:
        // Generic fallback
        return map[string]any{
            "status": "error",
            "message": "Service unavailable",
        }, nil
    }
}
```

## Best Practices

1. **Log Fallback Usage**: Track when and why fallbacks are triggered
2. **Monitor Fallback Rates**: High rates indicate system issues
3. **Set Appropriate Timeouts**: Don't wait too long before falling back
4. **Provide Meaningful Defaults**: Fallback data should be useful
5. **Document Fallback Behavior**: Make it clear what happens during failures
6. **Test Fallback Paths**: Ensure fallbacks work correctly
7. **Consider User Experience**: Degraded service is better than no service

## Next Steps

- [Error Handling](/patterns/error-handling) - Comprehensive error strategies
- [Conditional Branching](/patterns/branching) - Dynamic flow control
- [Circuit Breaker Pattern](/patterns/error-handling#circuit-breaker-pattern) - Prevent cascading failures


================================================
FILE: www/docs/public/site.webmanifest
================================================
{"name":"","short_name":"","icons":[{"src":"/android-chrome-192x192.png","sizes":"192x192","type":"image/png"},{"src":"/android-chrome-512x512.png","sizes":"512x512","type":"image/png"}],"theme_color":"#ffffff","background_color":"#ffffff","display":"standalone"}


================================================
FILE: .github/workflows/pages.yml
================================================
name: Build and Deploy to GitHub Pages

on:
  push:
    branches: [ main ]  # or your default branch
  workflow_dispatch:  # Allows manual triggering

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest  # or specify a version like '1.0.0'

      - name: Install Dependencies
        working-directory: ./www
        run: bun install

      - name: Setup uv
        uses: astral-sh/setup-uv@v3

      - name: Generate Full Documentation
        run: uvx gitingest -e cookbook -o www/docs/public/full-docs.txt

      - name: Build
        working-directory: ./www
        run: bun run build

      - name: Deploy to GitHub Pages
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          folder: www/docs/dist  # Your build output directory
          branch: gh-pages  # The branch the action should deploy to


================================================
FILE: .github/workflows/release.yml
================================================
name: "Create Release on Tag Push"
on:
  push:
    tags:
      - '*'  
jobs:
  release:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Create GitHub Release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ github.ref }}
          release_name: Release ${{ github.ref }}
          draft: false
          prerelease: false


================================================
FILE: .github/workflows/test.yml
================================================
name: go
on:
  push:
    branches:
      - main
  pull_request:
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-go@v5
      with:
        go-version-file: 'go.mod'
    - run: go test ./... -race

